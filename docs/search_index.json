[["index.html", "Readings for MTH250 - Data Wrangling Preface Package Needs", " Readings for MTH250 - Data Wrangling Derek H. Ogle 12 Aug 2021 Preface XXX However, there are likely still errors or descriptions that dont make sense. Please feel free to ask questions or post errors on the appropriate channel of the course MS Team. The book highlights definitions and tips in special boxes. Definition: This is a definition. This is a tip. R Code and results are also shown in special boxes. Code in the R box can be copied verbatim from the box with the icon that appears when you hover over the upper right corner of the code box. dat &lt;- c(3,4,5,2,8) mean(dat) #R&gt; [1] 4.4 The material presented in this book can be challenging to master. Please dont hesitate to ask me questions as you have them! Package Needs library(tidyverse) "],["preparation.html", "Module 1 Preparation", " Module 1 Preparation XXX "],["data-structures.html", "Module 2 Data Structures 2.1 Vectors 2.2 Data Classes 2.3 Data Frames 2.4 Tidy Data", " Module 2 Data Structures 2.1 Vectors The vector is the primary unit for storing data in R. You can think of a vector as a set of similar items. Vectors are created in R by combining or concatenating together the individual items into a single set with c(). For example, the code below creates a vector of county names stored in an object called cn (perhaps, short for county names). cn &lt;- c(&quot;Ashland&quot;,&quot;Bayfield&quot;,&quot;Douglas&quot;,&quot;Iron&quot;) Similarly the code below creates a vector of the population size in four counties stored in an object called pop. pop &lt;- c(15512,15056,43164,5687) Vector: The variable thought to depend upon, be explained by, or be predicted by other variables.   Individual items in a vector can be accessed by following the vectors object name with square brackets that contain the numeric position of the item. For example, the second county in cn and the third population size in pop are extracted below. cn[2] #R&gt; [1] &quot;Bayfield&quot; pop[3] #R&gt; [1] 43164 Multiple items can be accessed by combining their position indices into a vector. cn[c(2,3)] #R&gt; [1] &quot;Bayfield&quot; &quot;Douglas&quot; 2.2 Data Classes Vectors must contain the same type or class of items. There are four main classes of data in R. numeric: Numbers that may have decimals; e.g., 12.3. integer: Numbers that do not have decimals; e.g., 12. character: Words; e.g., Bayfield. logical: Logical that must be either TRUE or FALSE. The primary difference between numeric and integer classes is how the data are stored in memory. For most of our purposes this will be irrelevant, so there is no practical difference between these two classes for our work. However, integer values are entered into a vector by appending the value with an L. nabors &lt;- c(4L,3L,3L,3L) The values in a logical vector must be either TRUE or FALSE. Make sure to note that both of these values are in all capital letters. cheqbay &lt;- c(TRUE,TRUE,FALSE,FALSE)   The class (i.e., type) of data in a vector is found with class(). class(cn) #R&gt; [1] &quot;character&quot; class(pop) #R&gt; [1] &quot;numeric&quot; class(nabors) #R&gt; [1] &quot;integer&quot; class(cheqbay) #R&gt; [1] &quot;logical&quot; A factor is a special class of data where character items are specifically classified as representing groups or levels of items. A vector can be converted to a factor class with factor(). fcn &lt;- factor(cn) fcn #R&gt; [1] Ashland Bayfield Douglas Iron #R&gt; Levels: Ashland Bayfield Douglas Iron class(fcn) #R&gt; [1] &quot;factor&quot; Factors have useful properties that will be discussed in more detail in Module 10. As stated above, a vector should consist of items of the same class type. For example, this code does not make sense in most instances. huh &lt;- c(&quot;Ashland&quot;,15512,TRUE,3.65) However, this will not produce an error, though it likely will not be what you want it to be. For example, examine the class of this object. class(huh) #R&gt; [1] &quot;character&quot; R uses hierarchical rules to assign a class for these odd situations. Rather than focusing on these rules it is more beneficial to remember that each vector should be of the same class type. Items in vectors should all be the same class type. 2.3 Data Frames Vectors are useful for small numbers of items that have a single purpose. However, a data frame is more useful if you have multiple types of items (e.g., variables) recorded on a large number of individuals. Here we explore small data frames; larger data frames will be imported from external data sources in Module 3. A data frame is a rectangular data structure where columns are vectors of the same class that represent variables recorded on individuals which are represented in rows. Simple data frames can be constructed with data.frame() with named arguments set equal to vectors of data. For example, the following code produces a data frame object called counties that has three variables called name, pop, and party. counties &lt;- data.frame(name=c(&quot;Ashland&quot;,&quot;Bayfield&quot;,&quot;Douglas&quot;,&quot;Iron&quot;,&quot;Sawyer&quot;), pop=c(15512,15056,43164,5687,16746), party=c(&quot;Dem&quot;,&quot;Dem&quot;,&quot;Dem&quot;,&quot;Rep&quot;,&quot;Rep&quot;)) Type the name of the data frame object to see its contents. counties #R&gt; name pop party #R&gt; 1 Ashland 15512 Dem #R&gt; 2 Bayfield 15056 Dem #R&gt; 3 Douglas 43164 Dem #R&gt; 4 Iron 5687 Rep #R&gt; 5 Sawyer 16746 Rep Columns of data frames correspond to variables whereas rows correspond to individuals. Use str() to examine the structure of the data frame object, which will show that the object is a data.frame, show the number of individuals (label as obs for observations) and variables, and show the name of each column/variable along with its class type abbreviation and a snapshot of the first few items in each row. str(counties) #R&gt; &#39;data.frame&#39;: 5 obs. of 3 variables: #R&gt; $ name : chr &quot;Ashland&quot; &quot;Bayfield&quot; &quot;Douglas&quot; &quot;Iron&quot; ... #R&gt; $ pop : num 15512 15056 43164 5687 16746 #R&gt; $ party: chr &quot;Dem&quot; &quot;Dem&quot; &quot;Dem&quot; &quot;Rep&quot; ... As data frames are rectangular, individual items are accessed by using both the row and column positions within square brackets after the data frame object name. counties[1,2] # first row, second column #R&gt; [1] 15512 counties[3,1] # third row, first column #R&gt; [1] &quot;Douglas&quot; Entire rows or columns are accessed by providing the numerical position of the row or column and leaving the other indice blank. counties[1,] # First row #R&gt; name pop party #R&gt; 1 Ashland 15512 Dem counties[,1] # First column #R&gt; [1] &quot;Ashland&quot; &quot;Bayfield&quot; &quot;Douglas&quot; &quot;Iron&quot; &quot;Sawyer&quot; Note that choosing rows or more than one column will return a data frame as it will likely have data of different classes. class(counties[1,]) # one row is a data frame #R&gt; [1] &quot;data.frame&quot; class(counties[,c(1,2)]) # two columns is a data frame #R&gt; [1] &quot;data.frame&quot; However, choosing one column will return a vector of items all of the same class. class(counties[,1]) # one column is a vector #R&gt; [1] &quot;character&quot; As columns are named we can also use the name to access a specific column. counties[,&quot;pop&quot;] #R&gt; [1] 15512 15056 43164 5687 16746 This same column can be accessed by separating the data frame object name from the column name with a $. counties$pop #R&gt; [1] 15512 15056 43164 5687 16746 Again a column is simply a vector so you access single items in this vector in the usual way. counties$pop[3] #R&gt; [1] 43164 A $ is only used to separate a data frame name from the variable name within that data frame. 2.3.1 Tibbles Tibbles are a special form of data frame that was introduced as part of the tidyverse. Tibbles are created using tibble() in the same way that we used data.frame() previously. counties2 &lt;- tibble(name=c(&quot;Ashland&quot;,&quot;Bayfield&quot;,&quot;Douglas&quot;,&quot;Iron&quot;,&quot;Sawyer&quot;), pop=c(15512,15056,43164,5687,16746), party=c(&quot;Dem&quot;,&quot;Dem&quot;,&quot;Dem&quot;,&quot;Rep&quot;,&quot;Rep&quot;)) For most of our purposes a tibble will behave exactly as a data frame. For example, counties2 #R&gt; # A tibble: 5 x 3 #R&gt; name pop party #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 Ashland 15512 Dem #R&gt; 2 Bayfield 15056 Dem #R&gt; 3 Douglas 43164 Dem #R&gt; 4 Iron 5687 Rep #R&gt; 5 Sawyer 16746 Rep counties2$pop #R&gt; [1] 15512 15056 43164 5687 16746 There are, however, differences between tibbles and data frames as described in this introduction to tibbles. The primary difference that you will notice in this course is that when you examine the contents of a tibble with a larger number of rows, columns, or both. For example the code below converts a data frame from the FSA package into a tibble. tibex &lt;- as_tibble(FSA::WhitefishLC) However, when you try to display the data in this tibble you can see that only first 10 rows and as many columns as will fit on the width of your display are shown. In this case, 141 rows and one variable are not shown as seen in the note at the bottom. tibex #R&gt; # A tibble: 151 x 11 #R&gt; fishID tl scale1 scale2 scaleC finray1 finray2 finrayC otolith1 otolith2 #R&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; #R&gt; 1 1 345 3 3 3 3 3 3 3 3 #R&gt; 2 2 334 4 3 4 3 3 3 3 3 #R&gt; 3 3 348 7 5 6 3 3 3 3 3 #R&gt; 4 4 300 4 3 4 3 2 3 3 3 #R&gt; 5 5 330 3 3 3 4 3 4 3 3 #R&gt; 6 6 316 4 4 4 2 3 3 6 5 #R&gt; 7 7 508 6 7 7 6 6 6 9 10 #R&gt; 8 8 475 4 5 5 9 9 9 11 12 #R&gt; 9 9 340 3 3 3 2 3 3 3 4 #R&gt; 10 10 173 1 1 1 2 1 1 1 1 #R&gt; # ... with 141 more rows, and 1 more variable: otolithC &lt;int&gt; We will encounter tibbles in subsequent modules as some tidyverse functions return tibbles by default. A tibble can be converted to a data frame with as.data.frame(). 2.4 Tidy Data Tidy Data was a term introduced here in 2011 to describe a strict data organization that leads to consistency and efficiencies in data analyses. Tidy data is described in more detail here. Data can be organized in different ways. For example, below is the simple data frame from Section 2.3. #R&gt; name pop party #R&gt; 1 Ashland 15512 Dem #R&gt; 2 Bayfield 15056 Dem #R&gt; 3 Douglas 43164 Dem #R&gt; 4 Iron 5687 Rep #R&gt; 5 Sawyer 16746 Rep However, these same data could be organized as below (among other possible organizations). #R&gt; county variable value #R&gt; 1 Ashland pop 15512 #R&gt; 2 Ashland party Dem #R&gt; 3 Bayfield pop 15056 #R&gt; 4 Bayfield party Dem #R&gt; 5 Douglas pop 43164 #R&gt; 6 Douglas party Dem #R&gt; 7 Iron pop 5687 #R&gt; 8 Iron party Rep #R&gt; 9 Sawyer pop 16746 #R&gt; 10 Sawyer party Rep This second data frame is not tidy and is much more difficult to use. Tidy data frames follow three simple rules (Figure 2.1): Each variable must have its own column. Each observation must have its own row. Each value must have its own cell. The original data frame above is tidy.   Figure 2.1: Schematic illustration the structure of tidy data (from RStudio Data Wrangling Cheat Sheet)   A common challenge when entering data in a tidy format occurs when data is recorded on individuals in separate groups. For example, the following data are methyl mercury levels recorded in mussels from two locations labeled as impacted and reference. impacted 0.011 0.054 0.056 0.095 0.051 0.077 reference 0.031 0.040 0.029 0.066 0.018 0.042 0.044 In this case, you must realize that one observation is a methyl mercury measurement on a mussel AND to which group the mussel belongs. Thus, each observation results in the recording of two variables. For example, the first mussel had a methyl mercury level of 0.011 AND it was at the impacted site. With this understanding these data are entered in a tidy format as follows. mussels &lt;- tibble(loc=c(&quot;impacted&quot;,&quot;impacted&quot;,&quot;impacted&quot;,&quot;impacted&quot;,&quot;impacted&quot;,&quot;impacted&quot;, &quot;reference&quot;,&quot;reference&quot;,&quot;reference&quot;,&quot;reference&quot;, &quot;reference&quot;,&quot;reference&quot;,&quot;reference&quot;), merc=c(0.011,0.054,0.056,0.095,0.051,0.077, 0.031,0.040,0.029,0.066,0.018,0.042,0.044)) mussels #R&gt; # A tibble: 13 x 2 #R&gt; loc merc #R&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 impacted 0.011 #R&gt; 2 impacted 0.054 #R&gt; 3 impacted 0.056 #R&gt; 4 impacted 0.095 #R&gt; 5 impacted 0.051 #R&gt; 6 impacted 0.077 #R&gt; 7 reference 0.031 #R&gt; 8 reference 0.04 #R&gt; 9 reference 0.029 #R&gt; 10 reference 0.066 #R&gt; 11 reference 0.018 #R&gt; 12 reference 0.042 #R&gt; 13 reference 0.044 Tidy data will facilitate data wrangling in subsequent modules and data analysis and graphing in other courses. "],["read-external-data-files.html", "Module 3 Read External Data Files 3.1 Entering Data 3.2 Saving the External File 3.3 Reading the External File", " Module 3 Read External Data Files Most realistic data has more than a few individuals and is, thus, not easily entered using data.frame() or tibble() as shown in Section 2.3. Rather these data are often entered and stored in a spreadsheet or database that is external to R and, thus, needs to be read or loaded into R. This module describes how data should be entered into a spreadsheet and then how that data is read into R. 3.1 Entering Data Tidy data (see Section 2.4) is often read into a spreadsheet program such as Microsoft Excel or Google Sheets. The spreadsheet should be organized with variables in columns and individuals in rows, with the exception that the first row should contain variable names. The example spreadsheet below shows the length (cm), weight (kg), and capture location data for a small sample of Black Bears.   Variable names should NOT contain spaces. For example, dont use total length or length (cm). If you feel the need to have longer variable names, then separate the parts with a period (e.g., length.cm) or an underscore (e.g., length_cm). Variable names can NOT start with numbers or contain special characters such as ~, ! &amp;, @, etc. Furthermore, numerical measurements should NOT include units (e.g., dont use 7 cm). Finally, for categorical data, make sure that all categories are consistent (e.g., do not use both bayfield and Bayfield). When entering data make sure to follow the three rules of tidy data (see Section 2.4). For example, the following data are methyl mercury levels recorded in mussels captured from impacted and reference locations. impacted 0.011 0.054 0.056 0.095 0.051 0.077 reference 0.031 0.040 0.029 0.066 0.018 0.042 0.044 As described in Section 2.4, one observation (i.e., row) is a methyl mercury measurement on a mussel AND which group the mussel belongs. The rules for tidy data dictate two columns (one for each of the two variables recorded) and 13 rows (one for each observation of a mussel). format as follows. Thus, these data would be entered into the spreadsheet as shown below.   3.2 Saving the External File The spreadsheet may be saved in the format of the spreadsheet program (e.g., as an Excel file) to be read into R. However, it is also common to save the file as a comma separated values (CSV) file to be read into R. The advantage of a CSV file is that these files are small and, because they do not require any special software (e.g., Excel) to read, they are very likely to always be able to be read into R. 3.2.1 Excel An Excel worksheet is saved as a CSV file by selecting the File..Save As menu item, which will produce the dialog box below. In this dialog box, change Save as type to CSV (Comma delimited),1, provide a file name (do not put any periods in the name), select a location to save the file (this should be the same location as your assignment template file), and press Save. Two warning dialog boxes may then appear  select OK for the first and YES for the second. You can now close the spreadsheet file.2 3.2.2 Google Sheets A Google Sheet can be made available as a CSV file with the following steps by selecting the File menu, Share submenu, and Publish to web submenu. In the ensuing dialog box, change Entire Document to name of the sheet you want to publish and Web Page to Comma-separated values (.csv) under the Link tab. Then press the Publish button and press OK when asked to confirm publishing. Finally, select and copy (CTRL-C or CMD-C) the entire link shown in the box above. This link will be used as described in the next section. 3.3 Reading the External File 3.3.1 CSV Files CSV files may be read with read.csv() from base R or read_csv() from tidyverse. For most of our applications there will be little functional difference between these two functions. However, read_csv() is faster than read.csv() and can be a little smarter about the way it imports certain columns.3 In addition, it is a bit more transparent about what it is doing. For those reasons, we will use read_csv() in this course. An object saved from read_csv() will be a tibble. The first argument to read_csv() is the filename. This file must exist in your working directory, include be a partial path relative to your working directory or a full path to the file, or be a valid URL. For example, the code below reads Bears.csv from the data folder in my working directory and stores the result in the bears object. Here, I used file.path() to combine the folder names in the partial path with the filename because file.path() creates at path that will be correct for your operating system.4 bears &lt;- read_csv(file.path(&quot;data&quot;,&quot;Bears.csv&quot;)) bears #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas The filename argument could also be the link to the published Google Sheet (from above). bears &lt;- read_csv(&quot;https://docs.google.com/spreadsheets/d/e/2PACX-1vQaxD9tvwL29MydISlYw4bVXrw6-rvkEbT_2qFGxw7HuYX6M3h83aIYT4eZ-mrrEfJf8y5Q8p1Rkn4Z/pub?gid=522647677&amp;single=true&amp;output=csv&quot;) bears #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas The URL does not have to be from the published Google Sheet. For example, the following reads a CSV from this page that lists information about every player who has played in the National Basketball Association (NBA). players &lt;- read_csv(&quot;https://sports-statistics.com/database/basketball-data/nba/NBA-playerlist.csv&quot;) players #R&gt; # A tibble: 4,393 x 15 #R&gt; X1 DISPLAY_FIRST_LAST DISPLAY_LAST_COMMA_FIRST FROM_YEAR GAMES_PLAYED_FL~ #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 0 Alaa Abdelnaby Abdelnaby, Alaa 1990 Y #R&gt; 2 1 Zaid Abdul-Aziz Abdul-Aziz, Zaid 1968 Y #R&gt; 3 2 Kareem Abdul-Jabbar Abdul-Jabbar, Kareem 1969 Y #R&gt; 4 3 Mahmoud Abdul-Rauf Abdul-Rauf, Mahmoud 1990 Y #R&gt; 5 4 Tariq Abdul-Wahad Abdul-Wahad, Tariq 1997 Y #R&gt; 6 5 Shareef Abdur-Rahim Abdur-Rahim, Shareef 1996 Y #R&gt; 7 6 Tom Abernethy Abernethy, Tom 1976 Y #R&gt; 8 7 Forest Able Able, Forest 1956 Y #R&gt; 9 8 John Abramovic Abramovic, John 1946 Y #R&gt; 10 9 Alex Abrines Abrines, Alex 2016 Y #R&gt; # ... with 4,383 more rows, and 10 more variables: #R&gt; # OTHERLEAGUE_EXPERIENCE_CH &lt;chr&gt;, PERSON_ID &lt;dbl&gt;, PLAYERCODE &lt;chr&gt;, #R&gt; # ROSTERSTATUS &lt;dbl&gt;, TEAM_ABBREVIATION &lt;chr&gt;, TEAM_CITY &lt;chr&gt;, #R&gt; # TEAM_CODE &lt;chr&gt;, TEAM_ID &lt;dbl&gt;, TEAM_NAME &lt;chr&gt;, TO_YEAR &lt;dbl&gt;   The read_csv() function provides a variety of options that will help you correctly load CSV files that may be quirky in some respects. Use skip.lines= to skip, for example, the first two lines in a CSV file that do not contain data (perhaps they hold comments). tmp &lt;- read_csv(file.path(&quot;data&quot;,&quot;Bears_SkipLines.csv&quot;),skip=2) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas Alternatively, use comment= to identify leading characters that identify lines in the data file that are comments and should not be read as data. tmp &lt;- read_csv(file.path(&quot;data&quot;,&quot;Bears_Comment.csv&quot;),comment=&quot;#&quot;) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas Often data may be missing. By default, R treats NA in the data frame as missing data. If all missing data is coded with NA then read_csv() will handle this properly. For example, note the NAs in the second and eighth rows below. tmp &lt;- read_csv(file.path(&quot;data&quot;,&quot;Bears_Missing1.csv&quot;)) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 NA 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 &lt;NA&gt; However, some researcher may denote missing data with other codes. For example, the data file read below used - denote missing data. In cases like this, use na= to dictate which codes should be missing and converted to NA in the data frame object. tmp &lt;- read_csv(file.path(&quot;data&quot;,&quot;Bears_Missing2.csv&quot;),na=&quot;-&quot;) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 NA 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 &lt;NA&gt; In other instances, the research may have sloppily used multiple codes for missing data. In these instances, set na= to a vector of all codes to be converted to NA in the data frame object. tmp &lt;- read_csv(file.path(&quot;data&quot;,&quot;Bears_Missing3.csv&quot;),na=c(&quot;NA&quot;,&quot;NAN&quot;,&quot;-&quot;)) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 &lt;NA&gt; #R&gt; 2 NA 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 NA 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 &lt;NA&gt;   The examples above will serve you well for most files read in this class, with the possible exception of files that contain variables with dates. Handling dates is discussed in Module 9. 3.3.2 Excel Files Some researchers prefer to save data entered in Excel as an Excel workbook rather than a CSV file. The main argument here is that saving to a CSV often results in two files  an Excel workbook file and a CSV file. It is generally bad practice to have your data in two files as you may update the Excel file and forget to save it to the CSV file or you may update the CSV file and forget to also update the Excel file. Regardless of the reason, data can generally be read from an Excel file into R. The read_excel() function from the readxl package provides a coherent process for reading data from an Excel workbook. The first argument to read_excel() is the name of the Excel file, possibly with path information. By default read_excel() reads the first sheet in the Excel workbook. The example below reads the first sheet of the DataExamples.xlsx workbook in the data folder.5 tmp &lt;- readxl::read_excel(file.path(&quot;data&quot;,&quot;DataExamples.xlsx&quot;)) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas Data on specific sheets can be read by including the sheet name in sheet=. Additionally, lines at the top of the sheet can be skipped with skip= as described for read_csv(). For example, the code below reads the data after the first two lines in the Bears_SkipLines worksheet in the same Excel workbook. tmp &lt;- readxl::read_excel(file.path(&quot;data&quot;,&quot;DataExamples.xlsx&quot;), sheet=&quot;Bears_SkipLines&quot;,skip=2) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas Missing data is handled exactly as described for read_csv(). tmp &lt;- readxl::read_excel(file.path(&quot;data&quot;,&quot;DataExamples.xlsx&quot;), sheet=&quot;Bears_Missing3&quot;,na=c(&quot;NA&quot;,&quot;NAN&quot;,&quot;-&quot;)) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 &lt;NA&gt; #R&gt; 2 NA 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 NA 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 &lt;NA&gt;   In general, read_excel() works best if the data are arranged in a rectangle starting in cell A1. However, read_excel() can handle different organizations of data in the worksheet as described here. Researchers may also use multiple header rows in their Excel worksheet; e.g., variables names in the first row, variable units in the second row. This provides a strategy for reading data arranged in such a way. The examples above will serve you well for most files read in this class, with the possible exception of files that contain variables with dates. Handling dates is discussed XXXXXX. 3.3.3 Google Sheets It is also possible to read a file directly from Google Sheets using functions in the googlesheets4 package as described here. Using this package to read directly from Google Sheets requires you to authorize R to access your Google Sheets. 3.3.4 Other Formats Data may be stored in other, less common formats. A rew examples of functions to read these other formats are listed below. read_csv2() (from tidyverse) for fields separated by semi-colons (rather than commas) as is common in Europe. read_tsv() (from tidyverse) for fields separated by tabs (rather than commas). read_fwf() (from tidyverse) for fields that are a fixed width. read_sav() (from haven) for .sav files from SPSS. read_sas() (from haven) for .sas7bdat and .sas7bcat files from SAS. read_dta() (from haven) for .dta files from Stata. There are several choices for CSV files here; do NOT choose the one with UTF-8 in the name. You may be asked to save changes  you should say No. How read_csv() identifies the class of data in a column is described here Windows and Mac OS handle paths differently; this function avoids that complication. I use the readxl::read_excel() construct here rather than loading the readxl package and then simply using read_excel() because this is the only function that I will use from readxl. Thus, I am not loading unneeded functions into my work environment. "],["relational-data.html", "Module 4 Relational Data 4.1 Join Concepts 4.2 Joins in R 4.3 Examples With Context", " Module 4 Relational Data Some situations will have multiple data frames with related data. A particular analysis may require combining these data frames into a single data frame. If the data in the separate data frames are connected by a key variable then the data are said to be relational  i.e., they relate to each other through a common variable (or variables). As an example a college may have the following four data frames with respect to its students. Personal information (hometown, age, etc.) Financial aid information (family income, Pell Grant aid amount, etc.) Academic information (standing, major, gpa, etc.) Current course information (i.e., which courses a students is registered for) Each of these data frames would also contain a student ID variable so that a students personal information can be connect with the students financial aid, academic, or course information. This student ID variable is the key variable for these relational data frames. Data from related data frames can be joined in a variety of ways. This module will explain several types of joins and how to accomplish those joins in R. 4.1 Join Concepts To illustrate the various joins, suppose that a simple data frame x exists that has an id key variable and a val1 measurement variable.6 id val1 101 x1 102 x2 102 x3 103 x4 Further suppose that a second data frame y has the same id key variable and different val2 and val3 measurement variables.7 id val2 val3 101 y1 z1 102 y2 z2 104 y3 z3 104 y4 z4 It is instructive when learning about joins to visualize all combinations of observations in the two data frames.8 As some key variable values may be missing in the data frames we also consider combinations with a missing key variable value (and the measurement variables set to NA), All combinations of the rows in x and y with the missing key values are shown on the left for each join type in the subsections below. 4.1.1 Inner Join An inner join is the simplest join. It returns values from both data frames where the key variable(s) match in both data frames. In our simple data frames an inner join returns the rows from all combinations of rows (see left below) where the id variables (i.e., colors) from x and y match (see center below). The final result is these rows with the duplicated id key variable removed (see right below). All combinations from x and y id.x val1 id.y val2 val3 101 x1 101 y1 z1 101 x1 102 y2 z2 101 x1 104 y3 z3 101 x1 104 y4 z4 101 x1 NA NA 102 x2 101 y1 z1 102 x2 102 y2 z2 102 x2 104 y3 z3 102 x2 104 y4 z4 102 x2 NA NA 102 x3 101 y1 z1 102 x3 102 y2 z2 102 x3 104 y3 z3 102 x3 104 y4 z4 102 x3 NA NA 103 x4 101 y1 z1 103 x4 102 y2 z2 103 x4 104 y3 z3 103 x4 104 y4 z4 103 x4 NA NA NA 101 y1 z1 NA 102 y2 z2 NA 104 y3 z3 NA 104 y4 z4 Retained for inner join id.x val1 id.y val2 val3 101 x1 101 y1 z1 101 x1 102 y2 z2 101 x1 104 y3 z3 101 x1 104 y4 z4 101 x1 NA NA 102 x2 101 y1 z1 102 x2 102 y2 z2 102 x2 104 y3 z3 102 x2 104 y4 z4 102 x2 NA NA 102 x3 101 y1 z1 102 x3 102 y2 z2 102 x3 104 y3 z3 102 x3 104 y4 z4 102 x3 NA NA 103 x4 101 y1 z1 103 x4 102 y2 z2 103 x4 104 y3 z3 103 x4 104 y4 z4 103 x4 NA NA NA 101 y1 z1 NA 102 y2 z2 NA 104 y3 z3 NA 104 y4 z4 Final inner join result id val1 val2 val3 101 x1 y1 z1 102 x2 y2 z2 102 x3 y2 z2 Inner Join: Rows from both data frames where the key variable columns match. 4.1.2 Left Join A left join returns the same rows as an inner join (i.e., all rows where the key variables match) AND all rows from the first data frame that dont have a key variable match in the second data frame. The values for the variables in the second data frame for key values in the first data frame without a match are replaced with NAs. So, a left join will include rows for all key variables from the first data frame, but only rows from the second data frame that had a key variable match with the first data frame. All combinations from x and y id.x val1 id.y val2 val3 101 x1 101 y1 z1 101 x1 102 y2 z2 101 x1 104 y3 z3 101 x1 104 y4 z4 101 x1 NA NA 102 x2 101 y1 z1 102 x2 102 y2 z2 102 x2 104 y3 z3 102 x2 104 y4 z4 102 x2 NA NA 102 x3 101 y1 z1 102 x3 102 y2 z2 102 x3 104 y3 z3 102 x3 104 y4 z4 102 x3 NA NA 103 x4 101 y1 z1 103 x4 102 y2 z2 103 x4 104 y3 z3 103 x4 104 y4 z4 103 x4 NA NA NA 101 y1 z1 NA 102 y2 z2 NA 104 y3 z3 NA 104 y4 z4 Retained for left join id.x val1 id.y val2 val3 101 x1 101 y1 z1 101 x1 102 y2 z2 101 x1 104 y3 z3 101 x1 104 y4 z4 101 x1 NA NA 102 x2 101 y1 z1 102 x2 102 y2 z2 102 x2 104 y3 z3 102 x2 104 y4 z4 102 x2 NA NA 102 x3 101 y1 z1 102 x3 102 y2 z2 102 x3 104 y3 z3 102 x3 104 y4 z4 102 x3 NA NA 103 x4 101 y1 z1 103 x4 102 y2 z2 103 x4 104 y3 z3 103 x4 104 y4 z4 103 x4 NA NA NA 101 y1 z1 NA 102 y2 z2 NA 104 y3 z3 NA 104 y4 z4 Final left join result id val1 val2 val3 101 x1 y1 z1 102 x2 y2 z2 102 x3 y2 z2 103 x4 NA NA Left Join: All rows from the first data frame with variables from the second data frame where the key variable columns match (NA otherwise). 4.1.3 Right Join A right join works just like a left join except that the result will include all rows from the second data frame that dont have a key variable match in the first data frame. A right join can also be accomplished with a left join by reversing the order of the two data frames. Right Join: All rows from the second data frame with variables from the first data frame where the key variable columns match (NA otherwise). 4.1.4 Full Join A full join returns the same rows as an inner join (i.e., all rows where the key variable match) AND all rows from each data frame that dont have a key variable match in the other data frame. So a full join will include rows for all key variables from both data frames. All combinations from x and y id.x val1 id.y val2 val3 101 x1 101 y1 z1 101 x1 102 y2 z2 101 x1 104 y3 z3 101 x1 104 y4 z4 101 x1 NA NA 102 x2 101 y1 z1 102 x2 102 y2 z2 102 x2 104 y3 z3 102 x2 104 y4 z4 102 x2 NA NA 102 x3 101 y1 z1 102 x3 102 y2 z2 102 x3 104 y3 z3 102 x3 104 y4 z4 102 x3 NA NA 103 x4 101 y1 z1 103 x4 102 y2 z2 103 x4 104 y3 z3 103 x4 104 y4 z4 103 x4 NA NA NA 101 y1 z1 NA 102 y2 z2 NA 104 y3 z3 NA 104 y4 z4 Retained for full join id.x val1 id.y val2 val3 101 x1 101 y1 z1 101 x1 102 y2 z2 101 x1 104 y3 z3 101 x1 104 y4 z4 101 x1 NA NA 102 x2 101 y1 z1 102 x2 102 y2 z2 102 x2 104 y3 z3 102 x2 104 y4 z4 102 x2 NA NA 102 x3 101 y1 z1 102 x3 102 y2 z2 102 x3 104 y3 z3 102 x3 104 y4 z4 102 x3 NA NA 103 x4 101 y1 z1 103 x4 102 y2 z2 103 x4 104 y3 z3 103 x4 104 y4 z4 103 x4 NA NA NA 101 y1 z1 NA 102 y2 z2 NA 104 y3 z3 NA 104 y4 z4 Final full join result id val1 val2 val3 101 x1 y1 z1 102 x2 y2 z2 102 x3 y2 z2 103 x4 NA NA 104 NA y3 z3 104 NA y4 z4 Full Join: All rows from both data frame with variables from the other data frame where the key variable columns match (NA otherwise). 4.1.5 Semi Join In a semi join only values from the first data frame that have a key variable match in the second data frame are retained. Thus, the final result will only have variables from the first data frame for rows that had a key variable match in the second data frame. This is the same result as an inner join but without including the variables from the second data frame. All combinations from x and y id.x val1 id.y val2 val3 101 x1 101 y1 z1 101 x1 102 y2 z2 101 x1 104 y3 z3 101 x1 104 y4 z4 101 x1 NA NA 102 x2 101 y1 z1 102 x2 102 y2 z2 102 x2 104 y3 z3 102 x2 104 y4 z4 102 x2 NA NA 102 x3 101 y1 z1 102 x3 102 y2 z2 102 x3 104 y3 z3 102 x3 104 y4 z4 102 x3 NA NA 103 x4 101 y1 z1 103 x4 102 y2 z2 103 x4 104 y3 z3 103 x4 104 y4 z4 103 x4 NA NA NA 101 y1 z1 NA 102 y2 z2 NA 104 y3 z3 NA 104 y4 z4 Retained for semi join id.x val1 id.y val2 val3 101 x1 101 y1 z1 101 x1 102 y2 z2 101 x1 104 y3 z3 101 x1 104 y4 z4 101 x1 NA NA 102 x2 101 y1 z1 102 x2 102 y2 z2 102 x2 104 y3 z3 102 x2 104 y4 z4 102 x2 NA NA 102 x3 101 y1 z1 102 x3 102 y2 z2 102 x3 104 y3 z3 102 x3 104 y4 z4 102 x3 NA NA 103 x4 101 y1 z1 103 x4 102 y2 z2 103 x4 104 y3 z3 103 x4 104 y4 z4 103 x4 NA NA NA 101 y1 z1 NA 102 y2 z2 NA 104 y3 z3 NA 104 y4 z4 Final semi join result id val1 101 x1 102 x2 102 x3 Semi Join: All variables from the first data frame for rows where the key variable column has a match in the second data frame. 4.1.6 Anti Join In an anti join only values from the first data frame that DO NOT have a key variable match in the second data frame are retained. Thus, the final result will only have variables from the first data frame for rows without a key variable match in the second data frame. All combinations from x and y id.x val1 id.y val2 val3 101 x1 101 y1 z1 101 x1 102 y2 z2 101 x1 104 y3 z3 101 x1 104 y4 z4 101 x1 NA NA 102 x2 101 y1 z1 102 x2 102 y2 z2 102 x2 104 y3 z3 102 x2 104 y4 z4 102 x2 NA NA 102 x3 101 y1 z1 102 x3 102 y2 z2 102 x3 104 y3 z3 102 x3 104 y4 z4 102 x3 NA NA 103 x4 101 y1 z1 103 x4 102 y2 z2 103 x4 104 y3 z3 103 x4 104 y4 z4 103 x4 NA NA NA 101 y1 z1 NA 102 y2 z2 NA 104 y3 z3 NA 104 y4 z4 Retained for anti join id.x val1 id.y val2 val3 101 x1 101 y1 z1 101 x1 102 y2 z2 101 x1 104 y3 z3 101 x1 104 y4 z4 101 x1 NA NA 102 x2 101 y1 z1 102 x2 102 y2 z2 102 x2 104 y3 z3 102 x2 104 y4 z4 102 x2 NA NA 102 x3 101 y1 z1 102 x3 102 y2 z2 102 x3 104 y3 z3 102 x3 104 y4 z4 102 x3 NA NA 103 x4 101 y1 z1 103 x4 102 y2 z2 103 x4 104 y3 z3 103 x4 104 y4 z4 103 x4 NA NA NA 101 y1 z1 NA 102 y2 z2 NA 104 y3 z3 NA 104 y4 z4 Final anti join result id val1 103 x4 Anti Join: All variables from the first data frame for rows where the key variable column does NOT have a match in the second data frame.   4.2 Joins in R Performing the joins described in the previous section is straightforward with dplyr (part of the tidyverse) using, conveniently enough, inner_join(), left_join(), right_join(), full_join(), semi_join(), and anti_join(). The first two arguments to each of these functions are the two data frames to join. In addition, the name of the key variable should be given, in quotes, to by=.9 The two data frames used in the previous section are created below as objects in R. x &lt;- data.frame(id=c(101,102,102,103),val1=paste0(&quot;x&quot;,1:4)) x #R&gt; id val1 #R&gt; 1 101 x1 #R&gt; 2 102 x2 #R&gt; 3 102 x3 #R&gt; 4 103 x4 y &lt;- data.frame(id=c(101,102,104,104),val2=paste0(&quot;y&quot;,1:4),val3=paste0(&quot;z&quot;,1:4)) y #R&gt; id val2 val3 #R&gt; 1 101 y1 z1 #R&gt; 2 102 y2 z2 #R&gt; 3 104 y3 z3 #R&gt; 4 104 y4 z4   The six joins discussed in the previous section are completed below. You should compare the results here to the visual results above. ij &lt;- inner_join(x,y,by=&quot;id&quot;) ij #R&gt; id val1 val2 val3 #R&gt; 1 101 x1 y1 z1 #R&gt; 2 102 x2 y2 z2 #R&gt; 3 102 x3 y2 z2 lj &lt;- left_join(x,y,by=&quot;id&quot;) lj #R&gt; id val1 val2 val3 #R&gt; 1 101 x1 y1 z1 #R&gt; 2 102 x2 y2 z2 #R&gt; 3 102 x3 y2 z2 #R&gt; 4 103 x4 &lt;NA&gt; &lt;NA&gt; rj &lt;- right_join(x,y,by=&quot;id&quot;) rj #R&gt; id val1 val2 val3 #R&gt; 1 101 x1 y1 z1 #R&gt; 2 102 x2 y2 z2 #R&gt; 3 102 x3 y2 z2 #R&gt; 4 104 &lt;NA&gt; y3 z3 #R&gt; 5 104 &lt;NA&gt; y4 z4 rj2 &lt;- left_join(y,x,by=&quot;id&quot;) # right_join as left_join with x &amp; y reversed rj2 #R&gt; id val2 val3 val1 #R&gt; 1 101 y1 z1 x1 #R&gt; 2 102 y2 z2 x2 #R&gt; 3 102 y2 z2 x3 #R&gt; 4 104 y3 z3 &lt;NA&gt; #R&gt; 5 104 y4 z4 &lt;NA&gt; fj &lt;- full_join(x,y,by=&quot;id&quot;) fj #R&gt; id val1 val2 val3 #R&gt; 1 101 x1 y1 z1 #R&gt; 2 102 x2 y2 z2 #R&gt; 3 102 x3 y2 z2 #R&gt; 4 103 x4 &lt;NA&gt; &lt;NA&gt; #R&gt; 5 104 &lt;NA&gt; y3 z3 #R&gt; 6 104 &lt;NA&gt; y4 z4 sj &lt;- semi_join(x,y,by=&quot;id&quot;) sj #R&gt; id val1 #R&gt; 1 101 x1 #R&gt; 2 102 x2 #R&gt; 3 102 x3 aj &lt;- anti_join(x,y,by=&quot;id&quot;) aj #R&gt; id val1 #R&gt; 1 103 x4   4.3 Examples With Context The following examples demonstrate different types of joins within fictitious, but realistic, contexts. Please examine each data frame and the joined results carefully to help further understand what each type of join does. 4.3.1 Student Data (One-to-One) In large institutions or in complicated data environments, data about specific individuals may be housed in a variety of departments each of which maintains its own database. Preferably these data sources can be related via a primary key variable, such as a unique student ID number. As an example, suppose that a colleges admissions office maintains a database of personal information about every student at the college. For example it might look like that below for a fictitious five students. personal &lt;- data.frame(studentID=c(34535,45423,73424,89874,98222), first_nm=c(&quot;Rolando&quot;,&quot;Catherine&quot;,&quot;James&quot;,&quot;Rachel&quot;,&quot;Esteban&quot;), last_nm=c(&quot;Blackman&quot;,&quot;Johnson&quot;,&quot;Carmichael&quot;,&quot;Brown&quot;,&quot;Perez&quot;), hometown=c(&quot;Windsor&quot;,&quot;Eden Prairie&quot;,&quot;Marion&quot;,&quot;Milwaukee&quot;,&quot;El Paso&quot;), homestate=c(&quot;MI&quot;,&quot;MN&quot;,&quot;IA&quot;,&quot;WI&quot;,&quot;TX&quot;)) personal #R&gt; studentID first_nm last_nm hometown homestate #R&gt; 1 34535 Rolando Blackman Windsor MI #R&gt; 2 45423 Catherine Johnson Eden Prairie MN #R&gt; 3 73424 James Carmichael Marion IA #R&gt; 4 89874 Rachel Brown Milwaukee WI #R&gt; 5 98222 Esteban Perez El Paso TX In addition the financial aid office may have a database of financial aid information. finaid &lt;- data.frame(studentID=c(34535,45423,73424,89874,98222), income_cat=c(4,5,3,2,3), pell_elig=c(TRUE,FALSE,TRUE,TRUE,TRUE), work_study=c(TRUE,FALSE,FALSE,FALSE,TRUE)) finaid #R&gt; studentID income_cat pell_elig work_study #R&gt; 1 34535 4 TRUE TRUE #R&gt; 2 45423 5 FALSE FALSE #R&gt; 3 73424 3 TRUE FALSE #R&gt; 4 89874 2 TRUE FALSE #R&gt; 5 98222 3 TRUE TRUE Furthermore the registrars office has a database of academic information. academics &lt;- data.frame(studentID=c(34535,45423,73424,89874,98222), standing=c(&quot;FY&quot;,&quot;FY&quot;,&quot;SO&quot;,&quot;SR&quot;,&quot;JR&quot;), major=c(&quot;undecided&quot;,&quot;NRS&quot;,&quot;Biology&quot;,&quot;SCD&quot;,&quot;SCD&quot;), cum_gpa=c(0,0,3.12,3.67,2.89)) academics #R&gt; studentID standing major cum_gpa #R&gt; 1 34535 FY undecided 0.00 #R&gt; 2 45423 FY NRS 0.00 #R&gt; 3 73424 SO Biology 3.12 #R&gt; 4 89874 SR SCD 3.67 #R&gt; 5 98222 JR SCD 2.89 Note how each of these databases has the studentID variable that will serve as the key variable to connect each students information across each of the databases. These databases form what is called a one-to-one relationship because as each observation record in each database can be connected to one and only one observation record in the other databases. In this example, each database would ideally have an entry for every student. These data frames can generally be joined with inner, left, or right joins depending on the purpose. For example, an institutional researcher may want to examine whether student gpa differed between students that were eligible for a Pell Grant or not. In this case, the researcher would join the finaid and academics data frames so that the pell_elig and cum_gpa variables would be in one data frame. tmp &lt;- inner_join(finaid,academics,by=&quot;studentID&quot;) tmp #R&gt; studentID income_cat pell_elig work_study standing major cum_gpa #R&gt; 1 34535 4 TRUE TRUE FY undecided 0.00 #R&gt; 2 45423 5 FALSE FALSE FY NRS 0.00 #R&gt; 3 73424 3 TRUE FALSE SO Biology 3.12 #R&gt; 4 89874 2 TRUE FALSE SR SCD 3.67 #R&gt; 5 98222 3 TRUE TRUE JR SCD 2.89 An inner join was used here because the researcher only wants to include students that are in both databases (i.e., would likely have an entry for both pell_elig and cum_gpa). Note, however, that a left join or a right join would accomplish the same task as long as both databases had entries for every student (i.e., the databases have the same set of students).   Further suppose that academic advisors would like to have the students names attached to these records so that they could reach out to students who could use some help academically. tmp &lt;- inner_join(personal,tmp,by=&quot;studentID&quot;) tmp #R&gt; studentID first_nm last_nm hometown homestate income_cat pell_elig #R&gt; 1 34535 Rolando Blackman Windsor MI 4 TRUE #R&gt; 2 45423 Catherine Johnson Eden Prairie MN 5 FALSE #R&gt; 3 73424 James Carmichael Marion IA 3 TRUE #R&gt; 4 89874 Rachel Brown Milwaukee WI 2 TRUE #R&gt; 5 98222 Esteban Perez El Paso TX 3 TRUE #R&gt; work_study standing major cum_gpa #R&gt; 1 TRUE FY undecided 0.00 #R&gt; 2 FALSE FY NRS 0.00 #R&gt; 3 FALSE SO Biology 3.12 #R&gt; 4 FALSE SR SCD 3.67 #R&gt; 5 TRUE JR SCD 2.89   Continuing with this example, suppose that the registrars office also maintains a database that contains each students current class schedule. schedules &lt;- tibble(studentID=c(34535,34535,34535,34535, 45423,45423,45423,45423,45423, 73424,73424,73424,73424, 89874,89874,89874, 98222,98222,98222,98222), course=c(&quot;MTH107&quot;,&quot;BIO115&quot;,&quot;CHM110&quot;,&quot;IDS101&quot;, &quot;SCD110&quot;,&quot;PSY110&quot;,&quot;MTH140&quot;,&quot;OED212&quot;,&quot;IDS101&quot;, &quot;BIO234&quot;,&quot;CHM220&quot;,&quot;BIO370&quot;,&quot;SCD110&quot;, &quot;SCD440&quot;,&quot;PSY370&quot;,&quot;IDS490&quot;, &quot;SCD440&quot;,&quot;SCD330&quot;,&quot;SOC480&quot;,&quot;ART220&quot;)) schedules #R&gt; # A tibble: 20 x 2 #R&gt; studentID course #R&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 34535 MTH107 #R&gt; 2 34535 BIO115 #R&gt; 3 34535 CHM110 #R&gt; 4 34535 IDS101 #R&gt; 5 45423 SCD110 #R&gt; 6 45423 PSY110 #R&gt; 7 45423 MTH140 #R&gt; 8 45423 OED212 #R&gt; 9 45423 IDS101 #R&gt; 10 73424 BIO234 #R&gt; 11 73424 CHM220 #R&gt; 12 73424 BIO370 #R&gt; 13 73424 SCD110 #R&gt; 14 89874 SCD440 #R&gt; 15 89874 PSY370 #R&gt; 16 89874 IDS490 #R&gt; 17 98222 SCD440 #R&gt; 18 98222 SCD330 #R&gt; 19 98222 SOC480 #R&gt; 20 98222 ART220 The registrars office also maintains a database of information about every course taught at the college. A partial example of such a database is shown below.10 courses &lt;- tibble(course=c(&quot;ART220&quot;,&quot;ART330&quot;,&quot;BIO115&quot;,&quot;BIO234&quot;,&quot;BIO370&quot;,&quot;BIO490&quot;, &quot;CHM110&quot;,&quot;CHM220&quot;,&quot;CHM360&quot;,&quot;IDS101&quot;,&quot;IDS490&quot;,&quot;MTH107&quot;, &quot;MTH140&quot;,&quot;MTH230&quot;,&quot;OED212&quot;,&quot;OED330&quot;,&quot;OED360&quot;,&quot;PSY110&quot;, &quot;PSY370&quot;,&quot;SCD110&quot;,&quot;SCD330&quot;,&quot;SCD440&quot;,&quot;SOC111&quot;,&quot;SOC480&quot;), credits=c(3,3,4,4,4,4,4,4,4,3,4,4,4,4,3,3,3,4,4,3,3,4,4,4), instructor=c(&quot;Duffy&quot;,&quot;Terry&quot;,&quot;Johnson&quot;,&quot;Goyke&quot;,&quot;Anich&quot;,&quot;Anich&quot;, &quot;Carlson&quot;,&quot;Robertson&quot;,&quot;Carlson&quot;,&quot;Goyke&quot;,&quot;Hannickel&quot;,&quot;Ogle&quot;, &quot;Jensen&quot;,&quot;Jensen&quot;,&quot;Andre&quot;,&quot;Andre&quot;,&quot;Coulson&quot;,&quot;Sneyd&quot;, &quot;Sneyd&quot;,&quot;Tochterman&quot;,&quot;Tochterman&quot;,&quot;Foster&quot;, &quot;Schanning&quot;,&quot;Schanning&quot;)) courses #R&gt; # A tibble: 24 x 3 #R&gt; course credits instructor #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 ART220 3 Duffy #R&gt; 2 ART330 3 Terry #R&gt; 3 BIO115 4 Johnson #R&gt; 4 BIO234 4 Goyke #R&gt; 5 BIO370 4 Anich #R&gt; 6 BIO490 4 Anich #R&gt; 7 CHM110 4 Carlson #R&gt; 8 CHM220 4 Robertson #R&gt; 9 CHM360 4 Carlson #R&gt; 10 IDS101 3 Goyke #R&gt; # ... with 14 more rows These two data frames are related via the common course variable. This type of database organization is particularly useful because the information about any one course only needs to be entered once in courses even though the actual course may appear many times in schedules. This helps save time and reduces data entry errors. It is easy to add the specific course information (credits and instructor) from courses to the students course information in schedules with a left_join(). schedules2 &lt;- left_join(schedules,courses,by=&quot;course&quot;) schedules2 #R&gt; # A tibble: 20 x 4 #R&gt; studentID course credits instructor #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 34535 MTH107 4 Ogle #R&gt; 2 34535 BIO115 4 Johnson #R&gt; 3 34535 CHM110 4 Carlson #R&gt; 4 34535 IDS101 3 Goyke #R&gt; 5 45423 SCD110 3 Tochterman #R&gt; 6 45423 PSY110 4 Sneyd #R&gt; 7 45423 MTH140 4 Jensen #R&gt; 8 45423 OED212 3 Andre #R&gt; 9 45423 IDS101 3 Goyke #R&gt; 10 73424 BIO234 4 Goyke #R&gt; 11 73424 CHM220 4 Robertson #R&gt; 12 73424 BIO370 4 Anich #R&gt; 13 73424 SCD110 3 Tochterman #R&gt; 14 89874 SCD440 4 Foster #R&gt; 15 89874 PSY370 4 Sneyd #R&gt; 16 89874 IDS490 4 Hannickel #R&gt; 17 98222 SCD440 4 Foster #R&gt; 18 98222 SCD330 3 Tochterman #R&gt; 19 98222 SOC480 4 Schanning #R&gt; 20 98222 ART220 3 Duffy Note here that if we consider schedules as the primary data frame of interest then this relationship is still a one-to-one relationship because each course in schedules can be connected to only one course record in courses.   The students personal information can also be added to these results with a left_join() but now using the studentID key variable. schedules2A &lt;- left_join(personal,schedules2,by=&quot;studentID&quot;) schedules2A #R&gt; studentID first_nm last_nm hometown homestate course credits #R&gt; 1 34535 Rolando Blackman Windsor MI MTH107 4 #R&gt; 2 34535 Rolando Blackman Windsor MI BIO115 4 #R&gt; 3 34535 Rolando Blackman Windsor MI CHM110 4 #R&gt; 4 34535 Rolando Blackman Windsor MI IDS101 3 #R&gt; 5 45423 Catherine Johnson Eden Prairie MN SCD110 3 #R&gt; 6 45423 Catherine Johnson Eden Prairie MN PSY110 4 #R&gt; 7 45423 Catherine Johnson Eden Prairie MN MTH140 4 #R&gt; 8 45423 Catherine Johnson Eden Prairie MN OED212 3 #R&gt; 9 45423 Catherine Johnson Eden Prairie MN IDS101 3 #R&gt; 10 73424 James Carmichael Marion IA BIO234 4 #R&gt; 11 73424 James Carmichael Marion IA CHM220 4 #R&gt; 12 73424 James Carmichael Marion IA BIO370 4 #R&gt; 13 73424 James Carmichael Marion IA SCD110 3 #R&gt; 14 89874 Rachel Brown Milwaukee WI SCD440 4 #R&gt; 15 89874 Rachel Brown Milwaukee WI PSY370 4 #R&gt; 16 89874 Rachel Brown Milwaukee WI IDS490 4 #R&gt; 17 98222 Esteban Perez El Paso TX SCD440 4 #R&gt; 18 98222 Esteban Perez El Paso TX SCD330 3 #R&gt; 19 98222 Esteban Perez El Paso TX SOC480 4 #R&gt; 20 98222 Esteban Perez El Paso TX ART220 3 #R&gt; instructor #R&gt; 1 Ogle #R&gt; 2 Johnson #R&gt; 3 Carlson #R&gt; 4 Goyke #R&gt; 5 Tochterman #R&gt; 6 Sneyd #R&gt; 7 Jensen #R&gt; 8 Andre #R&gt; 9 Goyke #R&gt; 10 Goyke #R&gt; 11 Robertson #R&gt; 12 Anich #R&gt; 13 Tochterman #R&gt; 14 Foster #R&gt; 15 Sneyd #R&gt; 16 Hannickel #R&gt; 17 Foster #R&gt; 18 Tochterman #R&gt; 19 Schanning #R&gt; 20 Duffy These data frames represents a one-to-many relationship because studentID in personal is connected to many studentID records in schedules2 (one for each course the student is enrolled in).   4.3.2 Resource Sampling Data (One-to-Many Relationship) In sampling of natural resources it is common to have one database for information about the unit of sampling and another database specific to items within that sampling unit. For example, in fisheries we may have one database to record information about a particular net (e.g., where it is located, the date it was set) and a second database that records the species of fish caught and number of the species caught. You may be tempted to do this all in one database with a separate field for each fish species but this is inefficient as you may not know which species you may catch. Thus, every time you catch a new species you would need to add a new field or column to your database. In addition, this would be highly inefficient if you were to record information about individual fish (e.g., length and weight) as the amount of this information may vary from net to net. In this simple example, information about five specific settings of a net is stored in nets, which has a unique identifier for each net setting called net_num. nets &lt;- data.frame(net_num=1:5, lake=c(&quot;Eagle&quot;,&quot;Hart&quot;,&quot;Hart&quot;,&quot;Eagle&quot;,&quot;Millicent&quot;), date=c(&quot;3-Jul-21&quot;,&quot;3-Jul-21&quot;,&quot;5-Jul-21&quot;,&quot;6-Jul-21&quot;,&quot;6-Jul-21&quot;)) nets #R&gt; net_num lake date #R&gt; 1 1 Eagle 3-Jul-21 #R&gt; 2 2 Hart 3-Jul-21 #R&gt; 3 3 Hart 5-Jul-21 #R&gt; 4 4 Eagle 6-Jul-21 #R&gt; 5 5 Millicent 6-Jul-21 In a separate data frame the researchers recorded the species and number of each species caught in each net. Here there is a separate row for each species and its number caught with each row indexed to the specific net with the net_num key variable. catch &lt;- data.frame(net_num=c(1,1,2,2,2,4,4,5), species=c(&quot;Bluegill&quot;,&quot;Largemouth Bass&quot;, &quot;Bluegill&quot;,&quot;Largemouth Bass&quot;,&quot;Bluntnose Minnow&quot;, &quot;Bluegill&quot;,&quot;Largemouth Bass&quot;, &quot;Largemouth Bass&quot;), number=c(7,3,19,2,56,3,6,3)) catch #R&gt; net_num species number #R&gt; 1 1 Bluegill 7 #R&gt; 2 1 Largemouth Bass 3 #R&gt; 3 2 Bluegill 19 #R&gt; 4 2 Largemouth Bass 2 #R&gt; 5 2 Bluntnose Minnow 56 #R&gt; 6 4 Bluegill 3 #R&gt; 7 4 Largemouth Bass 6 #R&gt; 8 5 Largemouth Bass 3 These data frames illustrate a one-to-many relationship as each record in nets may be connected to multiple records in catch. The catch data will be joined to the net data using a left_join() because it is important to keep track of nets that also did not catch fish. An inner_join() would only return nets where some fish were caught. fishcatch &lt;- left_join(nets,catch,by=&quot;net_num&quot;) fishcatch #R&gt; net_num lake date species number #R&gt; 1 1 Eagle 3-Jul-21 Bluegill 7 #R&gt; 2 1 Eagle 3-Jul-21 Largemouth Bass 3 #R&gt; 3 2 Hart 3-Jul-21 Bluegill 19 #R&gt; 4 2 Hart 3-Jul-21 Largemouth Bass 2 #R&gt; 5 2 Hart 3-Jul-21 Bluntnose Minnow 56 #R&gt; 6 3 Hart 5-Jul-21 &lt;NA&gt; NA #R&gt; 7 4 Eagle 6-Jul-21 Bluegill 3 #R&gt; 8 4 Eagle 6-Jul-21 Largemouth Bass 6 #R&gt; 9 5 Millicent 6-Jul-21 Largemouth Bass 3 The visualizations in this section are modified from https://twitter.com/hadleywickham/status/684407629259526148/photo/1. In this treatment, the unique id values are also uniquely color coded to help track individual observations in the descriptions below. Finding all combinations, however, is not needed to actually join two data frames. If by= is not explicitly set by the user then the two data frames will be joined using the variable(s) that the two data frames have in common for by=. A message will be displayed about which variable(s) was used; check this message carefully to make sure you are joining by the variables that you want to join by. I switched to using tibble() in the last two data frams only so that they may potentially print in a more concise manner. "],["pivot.html", "Module 5 Pivot 5.1 Data Formats 5.2 Pivoting Concepts 5.3 Pivoting in R 5.4 Examples with Context", " Module 5 Pivot Three rules of tidy data were introduced in Section 2.4. Each variable must have its own column. Each observation must have its own row. Each value must have its own cell. There are a wide variety of ways to enter data. Some data will not be tidy because, for instance, it may be easier to enter data in a non-tidy format. For example, the data shown below is the number of positive confirmed COVID cases in Ashland, Bayfield, and Douglas counties in 2021 (through June).   County Jan_2021 Feb_2021 Mar_2021 Apr_2021 May_2021 Jun_2021 Ashland 139 27 31 41 45 3 Bayfield 100 33 28 54 36 15 Douglas 470 89 119 227 148 32   Data for future months can be easily entered by simply appending a new month on the right. These data are also easy to examine in this table, but in this format they are difficult to graph and can be difficult to summarize. Thus, these data need to be converted to a different format for some simple analyses.11 The objective of this module is to describe and demonstrate concepts and methods for converting data betwen different formats.   5.1 Data Formats Consider a situation with one measurement variable, x, recorded on four individuals at two times. These eight measurements could be entered in either the W or L data frames shown below.   W data.frame id x1 x2 A 1 5 B 2 6 C 3 7 D 4 8 L data.frame id time x A 1 1 A 2 5 B 1 2 B 2 6 C 1 3 C 2 7 D 1 4 D 2 8   In this case, a measurement of x on an individual at a single point in time is an observation; thus, each row should correspond to one measurement (value of x) on one individual. The W data frame is not tidy because multiple observations of x appear in each row of the data frame (i.e., the single measurement variable, x, is dispersed across two columns). The L data frame is tidy because each row corresponds to one observation (i.e., a unique combination of id and time) and the single measurement variable, x, now appears in only one column. Consider a similar example where two measurements (the variables x and y) were made (at the same time) on four individuals. These data may be entered as in V and Z below.   V data.frame id x y A 1 5 B 2 6 C 3 7 D 4 8 Z data.frame id variable value A x 1 A y 5 B x 2 B y 6 C x 3 C y 7 D x 4 D y 8   In this case V is tidy because each row corresponds to one observation (defined only by id) and each measurement variable (x and y) is in its own column. On the other hand Z is not tidy because observations are split into two rows and values of the two different measurement variables are lumped into the same column.   As you can see it can be difficult to identify the format that you want for your data. You cannot tell simply by the shape of the data  there will be times when you need the data to be longer (as in the first example above) and other times when you need the data to be wider (as in the second example above). As a general rule you should strive for your data to be tidy. For this start by identifying an observation is, which variables define the observations, and what the measurement variables are. Then determine if each row corresponds to one observation and if each measurement variable is in one column by itself. If the data do not meet these requirements then you likely need to convert it to a different format as described in the next sections.   5.2 Pivoting Concepts Each set of data described in the previous section could be entered in two formats. These formats are loosely called wider and longer based on their shapes relative to each other. converting between wider and longer format data is called A pivot. 5.2.1 Pivot Longer Pivot Longer is the conversion from a wider to a longer format. Pivotig to a longer format is usually needed if multiple observations of the same variable are recorded on individuals but are stored in separate columns of the data frame. This was the case with W above and also with the COVID data in the module introduction. To pivot from a wider to a longer format you must identify the variables in the wider format frame that contain the multiple measurements of the same variable. This was x1 and x2 in W. All other variables in the data frame are considered to represent a unique individual. In this case only the id variable is needed for this purpose. In addition, you must define names for variables in what will be the new longer format. The first name is for the variable that will identify the multiple measurements on the same individual. In this example the multiple measurements were taken at different times, so it seems logical to call the new variable time. The second name is for the variable that will hold the values of the measurement variable. Here the use of x1 and x2 in the original wider data frame suggest that this variable should be called x. The process of pivoting the wider W to a longer data frame is illustrated below.   5.2.2 Pivot Wider Pivot Wider is the conversion from a longer to a wider format. Pivoting to a wider format is most common when multiple measurement variables are recorded as one variable in the long format data frame. This was the case with Z from above. To pivot from a longer to a wider format you must identify the variable in the longer data frame that contains what will be names of variables in the wider data. The wider data frame that will be created from Z should have x and y has names of variables; thus, this variable in Z is variable. In addition, you must identify the variable in the long data frame that has the values of the measurement variable that will be separated into columns in the new data frame. In Z this variale is value. The process of pivoting the longer Z to a wider data frame is illustrated below.     5.3 Pivoting in R Pivoting W to a longer format and Z to a wider format in R are demonstrated in this section. These two data frames are created in R below. W &lt;- data.frame(id=c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;),x1=1:4,x2=5:8) W #R&gt; id x1 x2 #R&gt; 1 A 1 5 #R&gt; 2 B 2 6 #R&gt; 3 C 3 7 #R&gt; 4 D 4 8 Z &lt;- data.frame(id=rep(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;),each=2), variable=rep(c(&quot;x&quot;,&quot;y&quot;),times=4), value=c(1,5,2,6,3,7,4,8)) Z #R&gt; id variable value #R&gt; 1 A x 1 #R&gt; 2 A y 5 #R&gt; 3 B x 2 #R&gt; 4 B y 6 #R&gt; 5 C x 3 #R&gt; 6 C y 7 #R&gt; 7 D x 4 #R&gt; 8 D y 8 5.3.1 Pivot Longer Pivoting to a longer data frame is accomplished with pivot_longer() from tidyr (which is part of tidyverse). The first argument is the name of the wider data frame. The following three arguments are also typically used. The variables in the wider data frame that represent multiple measurements of the same variable must be given in cols=. Note that these variables do NOT need to be in quotes because they exist in the wider data frame. There are multiple ways to select these variables in most situations; here are several for this situation.12 cols=x1:x2 will select all variables contiguous from between x1 to x2. cols=c(x1,x2) will select only variables x1 and x2. cols=starts_with(\"x\") will select all variables with names that begin with x. cols=-id will select all variables not named id. The name for the variable in the new longer data frame that will hold the index for multiple measurements on the same individual in the longer data frame is given in names_to=. The name for the variable that will hold the values of the measurement variable in the new longer data frame is given in values_to. Note that the variable names in names_to= and values_to= must be in quotes because they do not appear in an (as of yet) existing data frame. Given the definitions of these items in the previous section, the following code is used to pivot W to a longer format data frame, L. L &lt;- pivot_longer(W,cols=x1:x2,names_to=&quot;time&quot;,values_to=&quot;value&quot;) L #R&gt; # A tibble: 8 x 3 #R&gt; id time value #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #R&gt; 1 A x1 1 #R&gt; 2 A x2 5 #R&gt; 3 B x1 2 #R&gt; 4 B x2 6 #R&gt; 5 C x1 3 #R&gt; 6 C x2 7 #R&gt; 7 D x1 4 #R&gt; 8 D x2 8 Note, however, that the time variable in L contains x1 and x2 rather than 1 and 2. By default pivot_longer() uses the names of the variables you supplied in cols= in this variable. If these variables have a common pattern  as in they all start with x and end with the number that we want  then the portion of the pattern to remove can be given in names_prefix=.13 L &lt;- pivot_longer(W,cols=x1:x2,names_to=&quot;time&quot;,names_prefix=&quot;x&quot;,values_to=&quot;x&quot;) L #R&gt; # A tibble: 8 x 3 #R&gt; id time x #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; #R&gt; 1 A 1 1 #R&gt; 2 A 2 5 #R&gt; 3 B 1 2 #R&gt; 4 B 2 6 #R&gt; 5 C 1 3 #R&gt; 6 C 2 7 #R&gt; 7 D 1 4 #R&gt; 8 D 2 8   A reminder that all variables not given in cols= will be considered as identifying with the individuals in the data frame. Suppose for example that W had more columns that looked like this data frame called W2. #R&gt; id fname lname years x1 x2 #R&gt; 1 A Derek Ogle 25 1 5 #R&gt; 2 B Young Kim 32 2 6 #R&gt; 3 C Andrew Jensen 6 3 7 #R&gt; 4 D Jodi Supanich 7 4 8 The same pivot_longer() with W2 will repeat the id, fname, lname, and years values in the longer data frame L2. L2 &lt;- pivot_longer(W2,cols=x1:x2,names_to=&quot;time&quot;,names_prefix=&quot;x&quot;,values_to=&quot;value&quot;) L2 #R&gt; # A tibble: 8 x 6 #R&gt; id fname lname years time value #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; #R&gt; 1 A Derek Ogle 25 1 1 #R&gt; 2 A Derek Ogle 25 2 5 #R&gt; 3 B Young Kim 32 1 2 #R&gt; 4 B Young Kim 32 2 6 #R&gt; 5 C Andrew Jensen 6 1 3 #R&gt; 6 C Andrew Jensen 6 2 7 #R&gt; 7 D Jodi Supanich 7 1 4 #R&gt; 8 D Jodi Supanich 7 2 8   5.3.2 Pivot Wider Pivoting to a wider data frame is accomplished with pivot_wider() from tidyr. The first argument is the name of the longer data frame. The following two arguments are also typically used. The name of the variable in the longer data frame that contains what will be names of variables in the wider data frame is given in names_from=. The name of the variable in the longer data frame that has values of the measurement variable that will be separated into columns in the new data frame is given in values_from=. As both of these variables exist in the longer data frame they do NOT need to be in quotes. Given the definitions from the previous section, the following is used to pivot Z to a wider format, V. V &lt;- pivot_wider(Z,names_from=variable,values_from=value) V #R&gt; # A tibble: 4 x 3 #R&gt; id x y #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 A 1 5 #R&gt; 2 B 2 6 #R&gt; 3 C 3 7 #R&gt; 4 D 4 8   Again, you can imagine a slightly more complicated data frame (here called Z2). #R&gt; id fname lname years variable value #R&gt; 1 A Derek Ogle 25 x 1 #R&gt; 2 A Derek Ogle 25 y 5 #R&gt; 3 B Young Kim 32 x 2 #R&gt; 4 B Young Kim 32 y 6 #R&gt; 5 C Andrew Jensen 6 x 3 #R&gt; 6 C Andrew Jensen 6 y 7 #R&gt; 7 D Jodi Supanich 7 x 4 #R&gt; 8 D Jodi Supanich 7 y 8 The same pivot_wider() on Z2 will collapse the common id, fname, lname, and years variables. V2 &lt;- pivot_wider(Z2,names_from=variable,values_from=value) V2 #R&gt; # A tibble: 4 x 6 #R&gt; id fname lname years x y #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 A Derek Ogle 25 1 5 #R&gt; 2 B Young Kim 32 2 6 #R&gt; 3 C Andrew Jensen 6 3 7 #R&gt; 4 D Jodi Supanich 7 4 8   5.4 Examples with Context 5.4.1 COVID Cases by County and Month A simple data frame of COVID cases by month in three Wisconsin counties from January to June 2021 was shown in the introduction. Here consider an even wider data, covABD_W, of monthly cases for all three counties from March 2020 to June 2021. covABD_W #R&gt; # A tibble: 3 x 17 #R&gt; # Groups: County [3] #R&gt; County Mar_2020 Apr_2020 May_2020 Jun_2020 Jul_2020 Aug_2020 Sep_2020 Oct_2020 #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 Ashland 1 1 0 1 16 16 94 167 #R&gt; 2 Bayfield 3 0 0 0 16 26 71 160 #R&gt; 3 Douglas 6 3 10 11 93 133 268 316 #R&gt; # ... with 8 more variables: Nov_2020 &lt;dbl&gt;, Dec_2020 &lt;dbl&gt;, Jan_2021 &lt;dbl&gt;, #R&gt; # Feb_2021 &lt;dbl&gt;, Mar_2021 &lt;dbl&gt;, Apr_2021 &lt;dbl&gt;, May_2021 &lt;dbl&gt;, #R&gt; # Jun_2021 &lt;dbl&gt; In this case a measurement is number of COVID cases and an observation is a combination of month and county. Thus, these data are not tidy because number of COVID cases is not in one column and each row is not one combination of county and month. It would be difficult to plot number of cases by month for each county with data in this format. Thus these wider data need to be converted to longer data that are tidy. All columns except County are part of the data to pivot; thus, cols=-County is the easiest way to choose these columns. The variable names in covABD_W are the month and year of the data so I will call the names_to= variable MonYear. Finally, the measurements are of cases of COVID so I will call the values_to= variable Cases. Putting this together gives the following. covABD_L &lt;- pivot_longer(covABD_W,cols=-County,names_to=&quot;MonYear&quot;,values_to=&quot;Cases&quot;) covABD_L #R&gt; # A tibble: 48 x 3 #R&gt; # Groups: County [3] #R&gt; County MonYear Cases #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 Ashland Mar_2020 1 #R&gt; 2 Ashland Apr_2020 1 #R&gt; 3 Ashland May_2020 0 #R&gt; 4 Ashland Jun_2020 1 #R&gt; 5 Ashland Jul_2020 16 #R&gt; 6 Ashland Aug_2020 16 #R&gt; 7 Ashland Sep_2020 94 #R&gt; 8 Ashland Oct_2020 167 #R&gt; 9 Ashland Nov_2020 378 #R&gt; 10 Ashland Dec_2020 331 #R&gt; # ... with 38 more rows This worked but the MonYear variable is problematic because R does not recognize it as a date (note how it is identified as character class). It would be better to split these names on the underscore to get one variable with the months and one variale with the years. Names may be split in pivot_longer() by providing the character to split on in names_sep=. As splitting the names will produce two new variales, names_to= must be a vector with two names for these two new columns. These modifications produce the following result. covABD_L &lt;- pivot_longer(covABD_W,cols=-County, names_to=c(&quot;Month&quot;,&quot;Year&quot;),names_sep=&quot;_&quot;,values_to=&quot;Cases&quot;) covABD_L #R&gt; # A tibble: 48 x 4 #R&gt; # Groups: County [3] #R&gt; County Month Year Cases #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 Ashland Mar 2020 1 #R&gt; 2 Ashland Apr 2020 1 #R&gt; 3 Ashland May 2020 0 #R&gt; 4 Ashland Jun 2020 1 #R&gt; 5 Ashland Jul 2020 16 #R&gt; 6 Ashland Aug 2020 16 #R&gt; 7 Ashland Sep 2020 94 #R&gt; 8 Ashland Oct 2020 167 #R&gt; 9 Ashland Nov 2020 378 #R&gt; 10 Ashland Dec 2020 331 #R&gt; # ... with 38 more rows We will need an actual date variable to make a plot of COVID cases over time. The code below does this but uses functions that wont be introduced until Module 9. covABD_L &lt;- covABD_L %&gt;% mutate(Date=lubridate::mdy(paste(Month,&quot;1&quot;,Year,sep=&quot;-&quot;))) covABD_L #R&gt; # A tibble: 48 x 5 #R&gt; # Groups: County [3] #R&gt; County Month Year Cases Date #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;date&gt; #R&gt; 1 Ashland Mar 2020 1 2020-03-01 #R&gt; 2 Ashland Apr 2020 1 2020-04-01 #R&gt; 3 Ashland May 2020 0 2020-05-01 #R&gt; 4 Ashland Jun 2020 1 2020-06-01 #R&gt; 5 Ashland Jul 2020 16 2020-07-01 #R&gt; 6 Ashland Aug 2020 16 2020-08-01 #R&gt; 7 Ashland Sep 2020 94 2020-09-01 #R&gt; 8 Ashland Oct 2020 167 2020-10-01 #R&gt; 9 Ashland Nov 2020 378 2020-11-01 #R&gt; 10 Ashland Dec 2020 331 2020-12-01 #R&gt; # ... with 38 more rows Finally, these data can be graphed as shown below.   5.4.2 Abundance of Mayflies In 1990 technicians for the U.S. Geological Survey recorded the abundance of mayflies (Ephemeroptera) in 10 1 m2 quadrats in Chequamegon Bay. In 2020 they repeat the collections at the same locations. Their data are recorded in ephem as shown below. ephem #R&gt; # A tibble: 20 x 5 #R&gt; loc hab depth year abundance #R&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 101 Sand 16 1990 47 #R&gt; 2 101 Sand 16 2020 46 #R&gt; 3 102 Sand 20 1990 44 #R&gt; 4 102 Sand 20 2020 42 #R&gt; 5 103 Muck 23 1990 50 #R&gt; 6 103 Muck 23 2020 53 #R&gt; 7 104 Cobble 27 1990 54 #R&gt; 8 104 Cobble 27 2020 56 #R&gt; 9 105 Sand 15 1990 52 #R&gt; 10 105 Sand 15 2020 43 #R&gt; 11 106 Muck 21 1990 25 #R&gt; 12 106 Muck 21 2020 30 #R&gt; 13 107 Cobble 27 1990 36 #R&gt; 14 107 Cobble 27 2020 20 #R&gt; 15 108 Sand 13 1990 22 #R&gt; 16 108 Sand 13 2020 18 #R&gt; 17 109 Sand 10 1990 28 #R&gt; 18 109 Sand 10 2020 28 #R&gt; 19 110 Cobble 23 1990 40 #R&gt; 20 110 Cobble 23 2020 36 The researchers want to compute the mean change in abundance across all ten quadrats. To facilitate that calculation these data need to be converted to a wider format that will have the 1990 and 2020 data in separate columns. In this case, potential names for the variables in the new wider format are in the year variable. The values to be put in those columns are in the aboundance variable. The rest of the variables should be maintained as they identify the observation (i.e., a quadrat year combination). With these definitions these data are converted to a wider format with the following code. ephem2 &lt;- pivot_wider(ephem,names_from=year,values_from=abundance) ephem2 #R&gt; # A tibble: 10 x 5 #R&gt; loc hab depth `1990` `2020` #R&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 101 Sand 16 47 46 #R&gt; 2 102 Sand 20 44 42 #R&gt; 3 103 Muck 23 50 53 #R&gt; 4 104 Cobble 27 54 56 #R&gt; 5 105 Sand 15 52 43 #R&gt; 6 106 Muck 21 25 30 #R&gt; 7 107 Cobble 27 36 20 #R&gt; 8 108 Sand 13 22 18 #R&gt; 9 109 Sand 10 28 28 #R&gt; 10 110 Cobble 23 40 36 This accomplishes the task at hand, but the two new variables are called 1990 and 2020, which are non-standard variable names in R (i.e., they start with numbers). This issue can be avoided by providing a string to be used as a prefix to the names in names_prefix=. ephem2 &lt;- pivot_wider(ephem,names_from=year,names_prefix=&quot;year_&quot;,values_from=abundance) ephem2 #R&gt; # A tibble: 10 x 5 #R&gt; loc hab depth year_1990 year_2020 #R&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 101 Sand 16 47 46 #R&gt; 2 102 Sand 20 44 42 #R&gt; 3 103 Muck 23 50 53 #R&gt; 4 104 Cobble 27 54 56 #R&gt; 5 105 Sand 15 52 43 #R&gt; 6 106 Muck 21 25 30 #R&gt; 7 107 Cobble 27 36 20 #R&gt; 8 108 Sand 13 22 18 #R&gt; 9 109 Sand 10 28 28 #R&gt; 10 110 Cobble 23 40 36 The code below, which will not be introduced until Module XXX, creates a new variable that is the difference in abundance between the two years. ephem2 &lt;- ephem2 %&gt;% mutate(diff20_90=year_2020-year_1990) ephem2 #R&gt; # A tibble: 10 x 6 #R&gt; loc hab depth year_1990 year_2020 diff20_90 #R&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 101 Sand 16 47 46 -1 #R&gt; 2 102 Sand 20 44 42 -2 #R&gt; 3 103 Muck 23 50 53 3 #R&gt; 4 104 Cobble 27 54 56 2 #R&gt; 5 105 Sand 15 52 43 -9 #R&gt; 6 106 Muck 21 25 30 5 #R&gt; 7 107 Cobble 27 36 20 -16 #R&gt; 8 108 Sand 13 22 18 -4 #R&gt; 9 109 Sand 10 28 28 0 #R&gt; 10 110 Cobble 23 40 36 -4 These data could then be easily plotted or summarized. Converting and graphing these data will be shown in Section 5.4. There are still other ways (e.g., cols=contains(\"x\")) but these four would be the most common given the names in this data frame. There are other arguments to pivot_longer() for dealing with more complicated naming issues. "],["wrangle-columns.html", "Module 6 Wrangle Columns 6.1 dplyr verbs 6.2 Pipe 6.3 Selecting Variables 6.4 Moving Variables 6.5 Renaming Variables 6.6 Adding Variables 6.7 Examples in Context", " Module 6 Wrangle Columns Previous modules were primarily focused on reading data into R and making sure the data were tidy. In this module we will start wrangling data by manipulating columns, which with tidy data contain variables. Module 7 will further describe how to wrangle data through manipulating rows which contain observations. More complex wrangling topics will be discussed in subsequent modules Manipulating columns means you are manipulating variables. The descriptive examples below will use the bears data frame from Section 3.3.1. bears &lt;- read_csv(file.path(&quot;data&quot;,&quot;Bears.csv&quot;)) bears #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas   6.1 dplyr verbs The primary tools for manipulating data frames used in this course are verbs from the dplyr package. These functions are described in more detail in subsequent sections and modules but each function has the same following characteristics: The first argument is a data frame or tibble. Further arguments are directives explaining how to manipulate the data frame. Variables do not need to be given in quotes. A data frame or tibble is returned from the function. Thus, these verbs are used in this general format; new_df &lt;- verb(old_df,...) where new_df is a new data frame created by the verb function, verb is the name of the dplyr verb function, old_df is the old original data frame, and ... will be directive arguments. The first argument to dplyr verb functions is a data frame.   6.2 Pipe As you will see in future modules, several dplyr verbs may be used consecutively. For example, you may use verbs to select just the females in the data frame, add on a new variable that calculates body mass index, and then order the observations from lowest to highest BMI. The pipe operator, %&gt;%, allows consecutive verbs to be connected in a more efficient and readable manner. The pipe takes the data frame from in front of %&gt;% and places it into the first argument (by default) of the function after the %&gt;%. For example, the general format of a dplyr verb from above could be rewritten like this new_df &lt;- old_df %&gt;% verb(...) because %&gt;% will pipe old_df into the first argument of verb(). This may not look simpler in this case, but it allows for code like this new_df &lt;- verb1(old_df,...) new_df &lt;- verb2(new_df,...) new_df &lt;- verb3(new_df,...) to be written more efficiently and expressively like this new_df &lt;- old_df %&gt;% verb1(...) %&gt;% verb2(...) %&gt;% verb3(...) When reading this code think of replacing the pipe operator with and then. For example, the last code above could be read as a new data frame is created by starting with an old data frame and THEN applying verb1 and THEN verb2 and THEN verb3. The pipe and assign operator, %&lt;&gt;%, will also be used in this and subsequent modules. This operator takes the data frame to the left and puts it in the first argument of the function on the right AND then takes the results of the function and assigns it to the name of the data frame to the left of the pipe operator. In other words, code like old_df &lt;- old_df %&gt;% verb() can be replaced with old_df %&lt;&gt;% verb() Be careful with this operator as the old data frame will be replaced with the result of the verb. These pipe operators will be used hereafter, even for single lines of code so that you become more familiar with their use for more involved future examples.   6.3 Selecting Variables Recall from Section 2.3 that an individual variable (i.e., column) can be selected from a data frame by separating the data frame name and the variable name with a $. For example, the following selects loc from the bears data frame. bears$loc #R&gt; [1] &quot;Bayfield&quot; &quot;Bayfield&quot; &quot;Bayfield&quot; &quot;Ashland&quot; &quot;Ashland&quot; &quot;Douglas&quot; &quot;Douglas&quot; #R&gt; [8] &quot;Douglas&quot; However, in this section, we are more interested in selecting multiple variables, rather than a single variable, from a data frame to form a new data frame. Variables are selected from a data frame with select(). The directive arguments to select() indicate which variables to retain, which can be given in a wide variety of ways (Table 6.1). Multiple methods may be used to select the same variables but you may find that some ways make your code more succinct and readable.   Table 6.1: Methods to select columns from a data frame using select(). Note that numbers and variable names will be replaced with numbers and names specific to the selection process (see examples in main text). Selector Column/Variables Returned 2 2nd column c(2,3) 2nd &amp; 3rd columns 2:5 All columns between 2nd and 5th columns -2 All but the 2nd column x Column named x c(x,y) Columns named x and y x:z All columns between columns named x and z -x All but the column named x starts_with(\"x\") All columns with names that start with x starts_with(c(\"x\",\"y\")) All columns with names that start with x or y ends_with(\"x\") All columns with names that end with x contains(\"x\") All columns with names that contain an x any_of(c(\"x\",\"y\")) Any (or all) of the columns named x or y (exactly) all_of(c(\"x\",\"y\")) All columns named x or y (exactly)14 last_col() Last column everything() All columns   Below are examples of selecting variables from bears.15 Note that each resulting data frame is called tmp (for temporary) because it will not be used further here. Select first two variables. tmp &lt;- bears %&gt;% select(1:2) tmp #R&gt; # A tibble: 8 x 2 #R&gt; length.cm weight.kg #R&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 139 110 #R&gt; 2 120. 60 #R&gt; 3 149 85 #R&gt; 4 141 100 #R&gt; 5 141 95 #R&gt; 6 150 85 #R&gt; 7 130. 105 #R&gt; 8 150 110 Select the loc and length.cm variables. tmp &lt;- bears %&gt;% select(c(loc,length.cm)) tmp #R&gt; # A tibble: 8 x 2 #R&gt; loc length.cm #R&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 Bayfield 139 #R&gt; 2 Bayfield 120. #R&gt; 3 Bayfield 149 #R&gt; 4 Ashland 141 #R&gt; 5 Ashland 141 #R&gt; 6 Douglas 150 #R&gt; 7 Douglas 130. #R&gt; 8 Douglas 150 Select all variables that contain a . tmp &lt;- bears %&gt;% select(contains(&quot;.&quot;)) tmp #R&gt; # A tibble: 8 x 2 #R&gt; length.cm weight.kg #R&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 139 110 #R&gt; 2 120. 60 #R&gt; 3 149 85 #R&gt; 4 141 100 #R&gt; 5 141 95 #R&gt; 6 150 85 #R&gt; 7 130. 105 #R&gt; 8 150 110 Select all variables that start with an l. tmp &lt;- bears %&gt;% select(starts_with(&quot;l&quot;)) tmp #R&gt; # A tibble: 8 x 2 #R&gt; length.cm loc #R&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 Bayfield #R&gt; 2 120. Bayfield #R&gt; 3 149 Bayfield #R&gt; 4 141 Ashland #R&gt; 5 141 Ashland #R&gt; 6 150 Douglas #R&gt; 7 130. Douglas #R&gt; 8 150 Douglas Select all variables except loc. tmp &lt;- bears %&gt;% select(-loc) tmp #R&gt; # A tibble: 8 x 2 #R&gt; length.cm weight.kg #R&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 139 110 #R&gt; 2 120. 60 #R&gt; 3 149 85 #R&gt; 4 141 100 #R&gt; 5 141 95 #R&gt; 6 150 85 #R&gt; 7 130. 105 #R&gt; 8 150 110   6.4 Moving Variables It is not necessary that variables be in a particular order in a data frame; however, you may find it easier to work with variables in a particular order. Variables can be moved within a data frame with relocate(). By default the selected columns are moved to the beginning of the data frame. However, they can be placed before or after a particular column by using .before= and .after=. Note that columns to be moved can be selected with methods shown in Table 6.1. Below are examples of moving variables within bears. Move loc to the beginning. tmp &lt;- bears %&gt;% relocate(loc) tmp #R&gt; # A tibble: 8 x 3 #R&gt; loc length.cm weight.kg #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 Bayfield 139 110 #R&gt; 2 Bayfield 120. 60 #R&gt; 3 Bayfield 149 85 #R&gt; 4 Ashland 141 100 #R&gt; 5 Ashland 141 95 #R&gt; 6 Douglas 150 85 #R&gt; 7 Douglas 130. 105 #R&gt; 8 Douglas 150 110 Move loc to after length.cm. tmp &lt;- bears %&gt;% relocate(loc,.after=length.cm) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm loc weight.kg #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 139 Bayfield 110 #R&gt; 2 120. Bayfield 60 #R&gt; 3 149 Bayfield 85 #R&gt; 4 141 Ashland 100 #R&gt; 5 141 Ashland 95 #R&gt; 6 150 Douglas 85 #R&gt; 7 130. Douglas 105 #R&gt; 8 150 Douglas 110 Move loc to before weight.kg. tmp &lt;- bears %&gt;% relocate(loc,.before=weight.kg) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm loc weight.kg #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 139 Bayfield 110 #R&gt; 2 120. Bayfield 60 #R&gt; 3 149 Bayfield 85 #R&gt; 4 141 Ashland 100 #R&gt; 5 141 Ashland 95 #R&gt; 6 150 Douglas 85 #R&gt; 7 130. Douglas 105 #R&gt; 8 150 Douglas 110 Move length.cm to the end. tmp &lt;- bears %&gt;% relocate(length.cm,.after=last_col()) tmp #R&gt; # A tibble: 8 x 3 #R&gt; weight.kg loc length.cm #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 110 Bayfield 139 #R&gt; 2 60 Bayfield 120. #R&gt; 3 85 Bayfield 149 #R&gt; 4 100 Ashland 141 #R&gt; 5 95 Ashland 141 #R&gt; 6 85 Douglas 150 #R&gt; 7 105 Douglas 130. #R&gt; 8 110 Douglas 150 Move both length.cm and weight.kg to the beginning. tmp &lt;- bears %&gt;% relocate(contains(&quot;.&quot;)) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas   6.5 Renaming Variables Variables may be given new names with rename(). Each directive argument in rename() has the form newname=oldname where newname will be the new name for the oldname variable in the data frame. Below are examples of renaming variables in bears. Rename loc to Location. tmp &lt;- bears %&gt;% rename(Location=loc) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg Location #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas Rename both length.cm and weight.kg. tmp &lt;- bears %&gt;% rename(Length=length.cm,Weight=weight.kg) tmp #R&gt; # A tibble: 8 x 3 #R&gt; Length Weight loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas Non-standard names of variables must be included in backticks when renaming them. For example, suppose that the names of variables in bears2 looked like this (note spaces in the names of the first two variables). bears2 #R&gt; # A tibble: 8 x 3 #R&gt; `length (cm)` `weight (kg)` loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas The following code is used to sensibly rename these variables with non-standard names. tmp &lt;- bears2 %&gt;% rename(Length=`length (cm)`,Weight=`weight (kg)`) tmp #R&gt; # A tibble: 8 x 3 #R&gt; Length Weight loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas   6.6 Adding Variables New variables are added to a data frame with mutate(). The directive arguments to this function have the form newvar=XXX where newvar will be the name of the new variable and XXX will create a new variable. There are a wide variety of expressions and functions that can be used to construct a new variable. A few of these will be illustrated below with bears but it is impossible to demonstrate all possibilities. Thus, other examples will be shown in the full context examples below as well as in subsequent modules. Add a year variable that is a constant value. tmp &lt;- bears %&gt;% mutate(year=2021) tmp #R&gt; # A tibble: 8 x 4 #R&gt; length.cm weight.kg loc year #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 139 110 Bayfield 2021 #R&gt; 2 120. 60 Bayfield 2021 #R&gt; 3 149 85 Bayfield 2021 #R&gt; 4 141 100 Ashland 2021 #R&gt; 5 141 95 Ashland 2021 #R&gt; 6 150 85 Douglas 2021 #R&gt; 7 130. 105 Douglas 2021 #R&gt; 8 150 110 Douglas 2021 Add a length in inches variable derived from length.cm. tmp &lt;- bears %&gt;% mutate(length.in=length.cm/2.54) tmp #R&gt; # A tibble: 8 x 4 #R&gt; length.cm weight.kg loc length.in #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 139 110 Bayfield 54.7 #R&gt; 2 120. 60 Bayfield 47.4 #R&gt; 3 149 85 Bayfield 58.7 #R&gt; 4 141 100 Ashland 55.5 #R&gt; 5 141 95 Ashland 55.5 #R&gt; 6 150 85 Douglas 59.1 #R&gt; 7 130. 105 Douglas 51.0 #R&gt; 8 150 110 Douglas 59.1 Multiple variables can be created at one time by including more arguments to mutate(). Subsequent arguments in mutate() may use variables created previously in the same mutate(). For example, the code below adds new variables that represent the weight of the bear if it were healthy (based on its length), the difference between the observed weight and this healthy weight, and a note if the bear is more or less than the healthy weight. tmp &lt;- bears %&gt;% mutate(healthy.wt=0.1129*length.cm^1.366, rel_weight=weight.kg-healthy.wt, rel_health=ifelse(rel_weight&gt;0,&quot;more&quot;,&quot;less&quot;)) tmp #R&gt; # A tibble: 8 x 6 #R&gt; length.cm weight.kg loc healthy.wt rel_weight rel_health #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield 95.5 14.5 more #R&gt; 2 120. 60 Bayfield 78.6 -18.6 less #R&gt; 3 149 85 Bayfield 105. -20.0 less #R&gt; 4 141 100 Ashland 97.4 2.61 more #R&gt; 5 141 95 Ashland 97.4 -2.39 less #R&gt; 6 150 85 Douglas 106. -21.0 less #R&gt; 7 130. 105 Douglas 86.7 18.3 more #R&gt; 8 150 110 Douglas 106. 4.02 more In the above example ifelse() was used to create the new variable that stated whether the beath was more or less healthy based on the rel_weight varible. The ifelse() functions contains three arguments  a conditioning expression that evaluates to either TRUE or FALSE, an item to return if the expression evaluates to TRUE, and an item to return if the expression evaluates to FALSE. This ifelse() statement can be read as if the relative weight is greater than 0 then return more otherwise return less. The ifelse() function is quite powerful for converting values to binary groups. However, case_when() is more flexible when more groups will be created. The case_when() function consists of several arguments of the form condition ~ return where condition is a condition expression that evaluates to TRUE or FALSE, and return is the item that will be returned if that condition expression evaluates to TRUE. The conditions in the arguments are sequential such that the result for the first condition that evaluates to TRUE is returned. The last condition expression in case_when() should be TRUE which will always evaluate to TRUE and will thus return its if all previous conditions were not met. For example, the code below is used to create a variable that provides a more detailed description of the relative health of the bears. tmp &lt;- bears %&gt;% mutate(healthy.wt=0.1129*length.cm^1.366, rel_weight=weight.kg-healthy.wt, rel_health=case_when( rel_weight&gt;10 ~ &quot;much more&quot;, rel_weight&gt;0 ~ &quot;some more&quot;, rel_weight&gt;-10 ~ &quot;some less&quot;, TRUE ~ &quot;much less&quot; )) tmp #R&gt; # A tibble: 8 x 6 #R&gt; length.cm weight.kg loc healthy.wt rel_weight rel_health #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield 95.5 14.5 much more #R&gt; 2 120. 60 Bayfield 78.6 -18.6 much less #R&gt; 3 149 85 Bayfield 105. -20.0 much less #R&gt; 4 141 100 Ashland 97.4 2.61 some more #R&gt; 5 141 95 Ashland 97.4 -2.39 some less #R&gt; 6 150 85 Douglas 106. -21.0 much less #R&gt; 7 130. 105 Douglas 86.7 18.3 much more #R&gt; 8 150 110 Douglas 106. 4.02 some more Finally, mapvalues() from plyr can be used to efficiently convert the groups of a categorical variable to different groups in a new categorical variables. The arguments to mapvalues are the name of the first categorical variable followed by the names of the groups of this variable in from= and the new names for the groups in the new variable in to=. Note that all group names not listed in from= will simply carry-over as-is in the new variable. The plyr package is not part of tidyverse and we will not typically use any other functions from plyr; thus, when using mapvalues() you should precede it with plyr:: as demonstrated below. As an example suppose that the locations in loc need to be converted to abbreviations to save space when graphing. tmp &lt;- bears %&gt;% mutate(loc_abb=plyr::mapvalues(loc, from=c(&quot;Ashland&quot;,&quot;Bayfield&quot;,&quot;Douglas&quot;), to=c(&quot;ASH&quot;,&quot;BAY&quot;,&quot;DOU&quot;))) tmp #R&gt; # A tibble: 8 x 4 #R&gt; length.cm weight.kg loc loc_abb #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield BAY #R&gt; 2 120. 60 Bayfield BAY #R&gt; 3 149 85 Bayfield BAY #R&gt; 4 141 100 Ashland ASH #R&gt; 5 141 95 Ashland ASH #R&gt; 6 150 85 Douglas DOU #R&gt; 7 130. 105 Douglas DOU #R&gt; 8 150 110 Douglas DOU Alternatively suppose that Ashland and Bayfield need to be combined into one group for some reason. This can be accomplished by giving the combined name for counties in the positions of to= that match the two counties in from=. For example, tmp &lt;- bears %&gt;% mutate(loc_abb=plyr::mapvalues(loc, from=c(&quot;Ashland&quot;,&quot;Bayfield&quot;), to=c(&quot;Ashland/Bayfield&quot;,&quot;Ashland/Bayfield&quot;))) tmp #R&gt; # A tibble: 8 x 4 #R&gt; length.cm weight.kg loc loc_abb #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield Ashland/Bayfield #R&gt; 2 120. 60 Bayfield Ashland/Bayfield #R&gt; 3 149 85 Bayfield Ashland/Bayfield #R&gt; 4 141 100 Ashland Ashland/Bayfield #R&gt; 5 141 95 Ashland Ashland/Bayfield #R&gt; 6 150 85 Douglas Douglas #R&gt; 7 130. 105 Douglas Douglas #R&gt; 8 150 110 Douglas Douglas Note in the code above that I did not include Douglas in either from= or to= because it was not to be modified for this situation.   6.7 Examples in Context 6.7.1 NBA Players Data on every player who has ever played in the National Basketball Association was read into R in Section 3.3.1. The structure of that data frame is shown below. players &lt;- read_csv(&quot;https://sports-statistics.com/database/basketball-data/nba/NBA-playerlist.csv&quot;) str(players,give.attr=FALSE) #R&gt; spec_tbl_df [4,393 x 15] (S3: spec_tbl_df/tbl_df/tbl/data.frame) #R&gt; $ X1 : num [1:4393] 0 1 2 3 4 5 6 7 8 9 ... #R&gt; $ DISPLAY_FIRST_LAST : chr [1:4393] &quot;Alaa Abdelnaby&quot; &quot;Zaid Abdul-Aziz&quot; &quot;Kareem Abdul-Jabbar&quot; &quot;Mahmoud Abdul-Rauf&quot; ... #R&gt; $ DISPLAY_LAST_COMMA_FIRST : chr [1:4393] &quot;Abdelnaby, Alaa&quot; &quot;Abdul-Aziz, Zaid&quot; &quot;Abdul-Jabbar, Kareem&quot; &quot;Abdul-Rauf, Mahmoud&quot; ... #R&gt; $ FROM_YEAR : num [1:4393] 1990 1968 1969 1990 1997 ... #R&gt; $ GAMES_PLAYED_FLAG : chr [1:4393] &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; &quot;Y&quot; ... #R&gt; $ OTHERLEAGUE_EXPERIENCE_CH: chr [1:4393] &quot;00&quot; &quot;00&quot; &quot;00&quot; &quot;00&quot; ... #R&gt; $ PERSON_ID : num [1:4393] 76001 76002 76003 51 1505 ... #R&gt; $ PLAYERCODE : chr [1:4393] &quot;HISTADD_alaa_abdelnaby&quot; &quot;HISTADD_zaid_abdul-aziz&quot; &quot;HISTADD_kareem_abdul-jabbar&quot; &quot;mahmoud_abdul-rauf&quot; ... #R&gt; $ ROSTERSTATUS : num [1:4393] 0 0 0 0 0 0 0 0 0 0 ... #R&gt; $ TEAM_ABBREVIATION : chr [1:4393] NA NA NA NA ... #R&gt; $ TEAM_CITY : chr [1:4393] NA NA NA NA ... #R&gt; $ TEAM_CODE : chr [1:4393] NA NA NA NA ... #R&gt; $ TEAM_ID : num [1:4393] 0 0 0 0 0 0 0 0 0 0 ... #R&gt; $ TEAM_NAME : chr [1:4393] NA NA NA NA ... #R&gt; $ TO_YEAR : num [1:4393] 1994 1977 1988 2000 2003 ...   Suppose that we ultimately want to make a graph related to the length of time that players were in the NBA. To facilitate this, I am going to reduce this data frame to only the players name, the year they started, and the year they ended in the NBA; rename long variable names (and remove the capitalization); calculate the amount of time they were in the NBA by subtracting their start year from their end year; create a new variable called modern that is yes for players that ended their careers in 1980 or later and is no otherwise; and order the data from most to least years played;16 players2 &lt;- players %&gt;% select(DISPLAY_LAST_COMMA_FIRST,FROM_YEAR,TO_YEAR) %&gt;% rename(name=DISPLAY_LAST_COMMA_FIRST,start=FROM_YEAR,end=TO_YEAR) %&gt;% mutate(years_played=end-start, modern=ifelse(end&gt;=1980,&quot;yes&quot;,&quot;no&quot;)) %&gt;% arrange(desc(years_played)) players2 #R&gt; # A tibble: 4,393 x 5 #R&gt; name start end years_played modern #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 Willis, Kevin 1984 2006 22 yes #R&gt; 2 Jones, Mark 1983 2004 21 yes #R&gt; 3 Carter, Vince 1998 2018 20 yes #R&gt; 4 Garnett, Kevin 1995 2015 20 yes #R&gt; 5 Nowitzki, Dirk 1998 2018 20 yes #R&gt; 6 Parish, Robert 1976 1996 20 yes #R&gt; 7 Abdul-Jabbar, Kareem 1969 1988 19 yes #R&gt; 8 Bryant, Kobe 1996 2015 19 yes #R&gt; 9 Cousy, Bob 1950 1969 19 no #R&gt; 10 Crawford, Jamal 2000 2018 18 yes #R&gt; # ... with 4,383 more rows   For fun, this is what one plot of the results might look like.   6.7.2 Wolves and Moose of Isle Royale For a module in my Great Graphs course I wanted to demonstrate to students how to create graphs that examined the abundance of Moose and Wolves on Isle Royale over time and in relation to winter temperatures and whether an ice bridge formed between the mainland and Isle Royale. Fortunately, these data17 are available at Wolves &amp; Moose of Isle Royale. I downloaded the data file provided there and read it into R below.18 irmw &lt;- readxl::read_excel(file.path(&quot;data&quot;,&quot;Data_wolves_moose_Isle_Royale_June2019.xlsx&quot;), sheet=&quot;1. population level data&quot;,skip=1,na=c(&quot;NA&quot;,&quot;N/A&quot;)) str(irmw,give.attr=FALSE) #R&gt; tibble [61 x 33] (S3: tbl_df/tbl/data.frame) #R&gt; $ year : num [1:61] 1959 1960 1961 1962 1963 ... #R&gt; $ wolves : num [1:61] 20 22 22 23 20 26 28 26 22 22 ... #R&gt; $ moose : num [1:61] 538 564 572 579 596 ... #R&gt; $ kill rate : chr [1:61] NA NA NA NA ... #R&gt; $ predation rate : chr [1:61] NA NA NA NA ... #R&gt; $ f (wolves) : chr [1:61] NA NA NA NA ... #R&gt; $ ancestry (immigrant wolf) : num [1:61] NA NA NA NA NA NA NA NA NA NA ... #R&gt; $ Juvenile Survival : chr [1:61] NA NA NA NA ... #R&gt; $ Adult Survival : chr [1:61] NA NA NA NA ... #R&gt; $ overall survival (genetic-CR) : chr [1:61] NA NA NA NA ... #R&gt; $ overall survival (field-based estimate) : num [1:61] NA NA NA NA NA NA NA NA NA NA ... #R&gt; $ % mortality, obsolete : num [1:61] NA NA NA NA NA NA NA NA NA NA ... #R&gt; $ %recruitment, obsolete : num [1:61] NA NA NA NA NA NA NA NA NA NA ... #R&gt; $ recruitment rate, moose (aerial surveys) : chr [1:61] &quot;20&quot; &quot;14.3&quot; &quot;19.5&quot; &quot;16.5&quot; ... #R&gt; $ mean age (excluding calves) : chr [1:61] &quot;5.8211920529999999&quot; &quot;6.1446540880000002&quot; &quot;6.266666667&quot; &quot;6.1117647059999998&quot; ... #R&gt; $ proportion of moose population that are senescent: chr [1:61] &quot;6&quot; &quot;6&quot; &quot;7&quot; &quot;7&quot; ... #R&gt; $ UN:C -west : num [1:61] NA NA NA NA NA NA NA NA NA NA ... #R&gt; $ UN:C - east : num [1:61] NA NA NA NA NA NA NA NA NA NA ... #R&gt; $ GA:C - west : chr [1:61] NA NA NA NA ... #R&gt; $ GA:C - east : chr [1:61] NA NA NA NA ... #R&gt; $ proportion of diet that is fir : num [1:61] NA NA NA NA NA NA NA NA NA NA ... #R&gt; $ proportion of diet that is cedar : num [1:61] NA NA NA NA NA NA NA NA NA NA ... #R&gt; $ proportion of diet that is deciduous : num [1:61] NA NA NA NA NA NA NA NA NA NA ... #R&gt; $ ticks (mean hair loss) : chr [1:61] NA NA NA NA ... #R&gt; $ July-Sept (temp, F) : chr [1:61] &quot;61.2&quot; &quot;60.667000000000002&quot; &quot;60.966999999999999&quot; &quot;57.9&quot; ... #R&gt; $ Apr-May (temp, F) : num [1:61] 43.9 43.4 41.4 42.6 43.5 ... #R&gt; $ Jan-Feb (temp, F) : num [1:61] 1.4 8.45 9.75 2.15 -0.35 12.4 1.25 1.7 2.75 5.85 ... #R&gt; $ May-Aug (precip, inches) : chr [1:61] &quot;16.8&quot; &quot;12.08&quot; &quot;8.94&quot; &quot;16.010000000000002&quot; ... #R&gt; $ NAO (DJFM - station based) : chr [1:61] &quot;-0.37&quot; &quot;-1.54&quot; &quot;1.8&quot; &quot;-2.38&quot; ... #R&gt; $ NAO - annual : chr [1:61] &quot;1.83&quot; &quot;-1.88&quot; &quot;0.47&quot; &quot;-1.05&quot; ... #R&gt; $ snow.depth (cm) : chr [1:61] NA NA NA NA ... #R&gt; $ ice bridges (0=none, 1 = present) : num [1:61] 0 0 1 1 1 0 1 1 1 1 ... #R&gt; $ springtime growing degree days : chr [1:61] &quot;N/A yet&quot; &quot;N/A yet&quot; &quot;N/A yet&quot; &quot;N/A yet&quot; ... The structure of this file shows that there are many variables, most of which I was not interested in for this demonstration, and the variable names are non-standard (i.e., they contains spaces). Thus, to prepare the data for the graphing course, I wanted to .. reduce the data frame to only the variables that I was interested in, rename the variables to be shorter and in standard format, change the coding of the variable about ice bridges from using 0 and 1 to using the more descriptive and easier to remember no and yes, create an era variable that says early for years before 1975, middle for years between 1975 and 2000, and recent for years after 2000, move the era variable to be next to the year variable (for aesthetic reasons), and make sure the data are ordered from earliest to latest year. irmw2 &lt;- irmw %&gt;% select(year,wolves,moose,`Jan-Feb (temp, F)`,`ice bridges (0=none, 1 = present)`) %&gt;% rename(winter_temp=`Jan-Feb (temp, F)`, ice_bridges=`ice bridges (0=none, 1 = present)`) %&gt;% mutate(ice_bridges=plyr::mapvalues(ice_bridges,from=c(0,1),to=c(&quot;no&quot;,&quot;yes&quot;)), era=case_when( year&lt;1975 ~ &quot;early&quot;, year&lt;=2000 ~ &quot;middle&quot;, TRUE ~ &quot;recent&quot; )) %&gt;% relocate(era,.after=year) %&gt;% arrange(year) irmw2 #R&gt; # A tibble: 61 x 6 #R&gt; year era wolves moose winter_temp ice_bridges #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 1959 early 20 538. 1.4 no #R&gt; 2 1960 early 22 564. 8.45 no #R&gt; 3 1961 early 22 572. 9.75 yes #R&gt; 4 1962 early 23 579. 2.15 yes #R&gt; 5 1963 early 20 596. -0.35 yes #R&gt; 6 1964 early 26 620. 12.4 no #R&gt; 7 1965 early 28 634. 1.25 yes #R&gt; 8 1966 early 26 661. 1.7 yes #R&gt; 9 1967 early 22 766. 2.75 yes #R&gt; 10 1968 early 22 848. 5.85 yes #R&gt; # ... with 51 more rows If all columns do not exist in the data frame then an error will occur. These selections are likely not needed because bears is so small; however, they are used here to demonstrate the selection techniques. You will learn this in the next module Along with a wide variety of other data about Wolves and Moose on Isle Royale. You may want to review the purpose of some of these arguments to read_excel() in Section 3.3.2. "],["wrangle-rows.html", "Module 7 Wrangle Rows 7.1 Selecting Specific Rows 7.2 Filtering Rows 7.3 Arranging Rows 7.4 Appending Rows 7.5 Examples in Context", " Module 7 Wrangle Rows The previous module demonstrated methods for wrangling columns (i.e., variables) in a data frame. In this module, methods to wrangle rows, which with tidy data are observations, in a data frame are introduced. The primary method of interest here is selecting a smaller subset of rows (i.e., filtering) for further analysis. Manipulating rows means you are manipulating observations. Again the descriptive examples below will use the bears data frame from Section 3.3.1. bears &lt;- read_csv(file.path(&quot;data&quot;,&quot;Bears.csv&quot;)) bears #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas The code here will also use the pipe operator, %&gt;%, to again help you become more comfortable with its use.   7.1 Selecting Specific Rows Specific rows may be selected or omitted from a data frame using slice(). Below are four simple examples. bears %&gt;% slice(1) # First row #R&gt; # A tibble: 1 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield bears %&gt;% slice(c(1,3,5)) # First, third, and fifth rows #R&gt; # A tibble: 3 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 149 85 Bayfield #R&gt; 3 141 95 Ashland bears %&gt;% slice(-1) # All but the first row #R&gt; # A tibble: 7 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 120. 60 Bayfield #R&gt; 2 149 85 Bayfield #R&gt; 3 141 100 Ashland #R&gt; 4 141 95 Ashland #R&gt; 5 150 85 Douglas #R&gt; 6 130. 105 Douglas #R&gt; 7 150 110 Douglas bears %&gt;% slice(-c(1,3,5)) # All but the first, third, and fifth rows #R&gt; # A tibble: 5 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 120. 60 Bayfield #R&gt; 2 141 100 Ashland #R&gt; 3 150 85 Douglas #R&gt; 4 130. 105 Douglas #R&gt; 5 150 110 Douglas Rows from the beginning (i.e., the head) or end (i.e., the tail) of the data frame may also be selected with slice_head() or slice_tail(), respectively. You may select a certain number of rows with n= or an approximate proportion of rows with prop=. Below are four examples. bears %&gt;% slice_head(n=3) # First three rows #R&gt; # A tibble: 3 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield bears %&gt;% slice_head(prop=0.33) # Approx. first 33% of rows #R&gt; # A tibble: 2 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield bears %&gt;% slice_tail(n=3) # Last three rows #R&gt; # A tibble: 3 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 150 85 Douglas #R&gt; 2 130. 105 Douglas #R&gt; 3 150 110 Douglas bears %&gt;% slice_tail(prop=0.33) # Approx. last 33% of rows #R&gt; # A tibble: 2 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 130. 105 Douglas #R&gt; 2 150 110 Douglas Finally a random sample of rows from the data frame may be selected with slice_sample(), again either using n= or prop=. bears %&gt;% slice_sample(n=3) # 3 random rows #R&gt; # A tibble: 3 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 141 100 Ashland #R&gt; 2 141 95 Ashland #R&gt; 3 130. 105 Douglas bears %&gt;% slice_sample(prop=0.33) # Random approx. 33% rows. #R&gt; # A tibble: 2 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 150 110 Douglas #R&gt; 2 139 110 Bayfield Use the slice() family of functions to select specific (or random) rows from a data frame.   7.2 Filtering Rows Observations or rows can be selected from a data frame with filter(). The directive arguments to filter() are conditional expressions describing which observations from the data frame to maintain. Common operators used in these conditional expressions are in Table 7.1.   Table 7.1: Comparison operators used in filterD() and their results. Note that var generically represents a variable in the original data frame and value is a generic value or level. Both var and val would be replaced with specific items (see examples in main text). Comparison Operator Rows Returned from Original Data Frame var==value All rows where var IS equal to value var!=value All rows where var is NOT equal to value var %in% c(value1,value2) All rows where var IS IN (or one of the) vector of values19 var&gt;value All rows where var is greater than value20 var&gt;=value All rows where var is greater than or equal to value21 var&lt;value All rows where var is less than value22 var&lt;=value All rows where var is less than or equal to value23 condition1,condition2 All rows where BOTH conditions are true condition1 | condition2 All rows where ONE or BOTH conditions are true24   The following are examples of new data frames created from bears. The name of the new data frame (i.e., object left of the assignment operator) is tmp (for temporary) in each example below because there is no plan to use these data frames further. Only observations from Bayfield county. tmp &lt;- bears %&gt;% filter(loc==&quot;Bayfield&quot;) tmp #R&gt; # A tibble: 3 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield Observations from both Bayfield and Ashland counties. tmp &lt;- bears %&gt;% filter(loc %in% c(&quot;Bayfield&quot;,&quot;Ashland&quot;)) tmp #R&gt; # A tibble: 5 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland Observations NOT from Bayfield county. tmp &lt;- bears %&gt;% filter(loc != &quot;Bayfield&quot;) tmp #R&gt; # A tibble: 5 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 141 100 Ashland #R&gt; 2 141 95 Ashland #R&gt; 3 150 85 Douglas #R&gt; 4 130. 105 Douglas #R&gt; 5 150 110 Douglas Observations with a weight greater than 100 kg. tmp &lt;- bears %&gt;% filter(weight.kg&gt;100) tmp #R&gt; # A tibble: 3 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 130. 105 Douglas #R&gt; 3 150 110 Douglas Observations from Douglas County that weighed at least 110 kg. tmp &lt;- bears %&gt;% filter(loc==&quot;Douglas&quot;,weight.kg&gt;=110) tmp #R&gt; # A tibble: 1 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 150 110 Douglas The last example above illustrates that multiple conditional expressions in filter() are combined as an and operator such that both conditions must be true. Use filter() to select rows from a data frame that match a logical condition.   It is good practice to examine a data frame after filtering to be sure that the new data frame contains the observations that you want. The data frames above are so small that you can simply and easily examine the entire data frame. However, this will not be the case with more realistic larger data frames. Thus, I suggest the following methods for checking your filtering. Simply display the data frame or the structure of the data frame to identify any obvious issues. For example, the code below should return all bears from Douglas County with a weight greater than 150 kg. Showing the data frame or the structure of the data frame both show that this data frame contains no data. tmp &lt;- bears %&gt;% filter(loc==&quot;Douglas&quot;,weight.kg&gt;=150) tmp #R&gt; # A tibble: 0 x 3 #R&gt; # ... with 3 variables: length.cm &lt;dbl&gt;, weight.kg &lt;dbl&gt;, loc &lt;chr&gt; str(tmp,give.attr=FALSE) #R&gt; spec_tbl_df [0 x 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame) #R&gt; $ length.cm: num(0) #R&gt; $ weight.kg: num(0) #R&gt; $ loc : chr(0) If you filter with respect to a categorical variable then use unique() with that categorical variable to examine its levels. For example, the filter below is expected to return observations for just Ashland and Bayfield counties. The use of unique() supports that this is what is returned. tmp &lt;- bears %&gt;% filter(loc %in% c(&quot;Bayfield&quot;,&quot;Ashland&quot;)) unique(tmp$loc) #R&gt; [1] &quot;Bayfield&quot; &quot;Ashland&quot; If you filter with respect to a quantitative variable then use summary() with that quantitative variable to examine its summary statistics. For example the fitler below is expected to return observations for lengths between 130 and 145 cm. The minimum and maximum values in the summary() results support that is what is returned. tmp &lt;- bears %&gt;% filter(length.cm&gt;130,length.cm&lt;145) summary(tmp$length.cm) #R&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #R&gt; 139.0 140.0 141.0 140.3 141.0 141.0 Examine the new data frame after filtering to ensure that it contains the observations you intended.   7.3 Arranging Rows The arrange() function is used to sort rows based on values in one or more variables.25 The default is ascending order. To sort in descending order then wrap the variable name in desc(). If more than one variable is given then the rows are first sorted based on the first variable and then ties in the first variable are sorted based on the second variable. Examples of sorting are shown below. Alphabetically sort bears by location name. bears &lt;- bears %&gt;% arrange(loc) bears #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 141 100 Ashland #R&gt; 2 141 95 Ashland #R&gt; 3 139 110 Bayfield #R&gt; 4 120. 60 Bayfield #R&gt; 5 149 85 Bayfield #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas Sort bears from heaviest to lightest. bears &lt;- bears %&gt;% arrange(desc(weight.kg)) bears #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 150 110 Douglas #R&gt; 3 130. 105 Douglas #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 149 85 Bayfield #R&gt; 7 150 85 Douglas #R&gt; 8 120. 60 Bayfield Sort bears from heaviest to lightest within each location. bears &lt;- bears %&gt;% arrange(loc,desc(weight.kg)) bears #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 141 100 Ashland #R&gt; 2 141 95 Ashland #R&gt; 3 139 110 Bayfield #R&gt; 4 149 85 Bayfield #R&gt; 5 120. 60 Bayfield #R&gt; 6 150 110 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 85 Douglas sort bears by size, first by length and then by weight. bears &lt;- bears %&gt;% arrange(length.cm,weight.kg) bears #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 120. 60 Bayfield #R&gt; 2 130. 105 Douglas #R&gt; 3 139 110 Bayfield #R&gt; 4 141 95 Ashland #R&gt; 5 141 100 Ashland #R&gt; 6 149 85 Bayfield #R&gt; 7 150 85 Douglas #R&gt; 8 150 110 Douglas Use arrange() to sort rows in a data frame by the value(s) of variable(s).   7.4 Appending Rows Two data frames can be combined with bind_rows() IF they have the same column names and classes. For example suppose that two other data frames exist  bears2 has more information about bears and bobcats has similar information about bobcats. bears2 #R&gt; length.cm weight.kg loc #R&gt; 1 135 100 Iron #R&gt; 2 142 115 Iron #R&gt; 3 143 110 Iron bobcats #R&gt; length.cm weight.kg loc #R&gt; 1 75 6.2 Douglas #R&gt; 2 82 8.1 Douglas #R&gt; 3 71 7.4 Bayfield #R&gt; 4 79 7.6 Douglas The code below appends the bears2 data frame to the bottom of the bears data frame and then, for demonstration purposes, orders the bears by size. newbears &lt;- bind_rows(bears,bears2) %&gt;% arrange(length.cm,weight.kg) newbears #R&gt; # A tibble: 11 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 120. 60 Bayfield #R&gt; 2 130. 105 Douglas #R&gt; 3 135 100 Iron #R&gt; 4 139 110 Bayfield #R&gt; 5 141 95 Ashland #R&gt; 6 141 100 Ashland #R&gt; 7 142 115 Iron #R&gt; 8 143 110 Iron #R&gt; 9 149 85 Bayfield #R&gt; 10 150 85 Douglas #R&gt; 11 150 110 Douglas The same could be done with the bears and bobcats data frames but there will be no way to then tell which observations are for bears and which are for bobcats. This deficiency can be overcome by giving names to the data frames within bind_rows() and giving a variable name to .id= for the new variable that will identify the groups. For example, animals &lt;- bind_rows(&quot;bear&quot;=bears,&quot;bobcat&quot;=bobcats,.id=&quot;animal&quot;) animals #R&gt; # A tibble: 12 x 4 #R&gt; animal length.cm weight.kg loc #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 bear 120. 60 Bayfield #R&gt; 2 bear 130. 105 Douglas #R&gt; 3 bear 139 110 Bayfield #R&gt; 4 bear 141 95 Ashland #R&gt; 5 bear 141 100 Ashland #R&gt; 6 bear 149 85 Bayfield #R&gt; 7 bear 150 85 Douglas #R&gt; 8 bear 150 110 Douglas #R&gt; 9 bobcat 75 6.2 Douglas #R&gt; 10 bobcat 82 8.1 Douglas #R&gt; 11 bobcat 71 7.4 Bayfield #R&gt; 12 bobcat 79 7.6 Douglas Note that more than two data frames can be combined with bind_rows(). Use bind_rows() to combine two (or more) data frames that have the same variables (i.e., columns).   7.5 Examples in Context 7.5.1 NBA Players In Section 6.7.1 the players2 data frame was created that showed the starting year, ending year, total years played, and whether the player was from the modern era or not for all NBA players. players2 #R&gt; # A tibble: 4,393 x 5 #R&gt; name start end years_played modern #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 Willis, Kevin 1984 2006 22 yes #R&gt; 2 Jones, Mark 1983 2004 21 yes #R&gt; 3 Carter, Vince 1998 2018 20 yes #R&gt; 4 Garnett, Kevin 1995 2015 20 yes #R&gt; 5 Nowitzki, Dirk 1998 2018 20 yes #R&gt; 6 Parish, Robert 1976 1996 20 yes #R&gt; 7 Abdul-Jabbar, Kareem 1969 1988 19 yes #R&gt; 8 Bryant, Kobe 1996 2015 19 yes #R&gt; 9 Cousy, Bob 1950 1969 19 no #R&gt; 10 Crawford, Jamal 2000 2018 18 yes #R&gt; # ... with 4,383 more rows The graph shown in that same section was for all players with more than 18 years in the NBA. The data frame for that graph is constructed below. nba_gt18 &lt;- players2 %&gt;% filter(years_played&gt;18) nba_gt18 #R&gt; # A tibble: 9 x 5 #R&gt; name start end years_played modern #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 Willis, Kevin 1984 2006 22 yes #R&gt; 2 Jones, Mark 1983 2004 21 yes #R&gt; 3 Carter, Vince 1998 2018 20 yes #R&gt; 4 Garnett, Kevin 1995 2015 20 yes #R&gt; 5 Nowitzki, Dirk 1998 2018 20 yes #R&gt; 6 Parish, Robert 1976 1996 20 yes #R&gt; 7 Abdul-Jabbar, Kareem 1969 1988 19 yes #R&gt; 8 Bryant, Kobe 1996 2015 19 yes #R&gt; 9 Cousy, Bob 1950 1969 19 no It might be interesting to see who started in the NBA in the year of your college graduation (using mine below). nba_grad1 &lt;- players2 %&gt;% filter(start==1989) nba_grad1 #R&gt; # A tibble: 81 x 5 #R&gt; name start end years_played modern #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 Robinson, Clifford 1989 2006 17 yes #R&gt; 2 Divac, Vlade 1989 2004 15 yes #R&gt; 3 Barros, Dana 1989 2003 14 yes #R&gt; 4 Rice, Glen 1989 2003 14 yes #R&gt; 5 Anderson, Nick 1989 2002 13 yes #R&gt; 6 Hardaway, Tim 1989 2002 13 yes #R&gt; 7 Kemp, Shawn 1989 2002 13 yes #R&gt; 8 Mason, Anthony 1989 2002 13 yes #R&gt; 9 McCloud, George 1989 2002 13 yes #R&gt; 10 Robinson, David 1989 2002 13 yes #R&gt; # ... with 71 more rows Perhaps those that started in the year of your graduation and played for more than a decade. nba_grad2 &lt;- players2 %&gt;% filter(start==1989,years_played&gt;10) nba_grad2 #R&gt; # A tibble: 21 x 5 #R&gt; name start end years_played modern #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 Robinson, Clifford 1989 2006 17 yes #R&gt; 2 Divac, Vlade 1989 2004 15 yes #R&gt; 3 Barros, Dana 1989 2003 14 yes #R&gt; 4 Rice, Glen 1989 2003 14 yes #R&gt; 5 Anderson, Nick 1989 2002 13 yes #R&gt; 6 Hardaway, Tim 1989 2002 13 yes #R&gt; 7 Kemp, Shawn 1989 2002 13 yes #R&gt; 8 Mason, Anthony 1989 2002 13 yes #R&gt; 9 McCloud, George 1989 2002 13 yes #R&gt; 10 Robinson, David 1989 2002 13 yes #R&gt; # ... with 11 more rows Perhaps those that were playing during the year of your graduation. nba_grad3 &lt;- players2 %&gt;% filter(start&lt;=1985,end&gt;=1985) nba_grad3 #R&gt; # A tibble: 353 x 5 #R&gt; name start end years_played modern #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 Willis, Kevin 1984 2006 22 yes #R&gt; 2 Jones, Mark 1983 2004 21 yes #R&gt; 3 Parish, Robert 1976 1996 20 yes #R&gt; 4 Abdul-Jabbar, Kareem 1969 1988 19 yes #R&gt; 5 Edwards, James 1977 1995 18 yes #R&gt; 6 Jordan, Michael 1984 2002 18 yes #R&gt; 7 Long, John 1978 1996 18 yes #R&gt; 8 Mahorn, Rick 1980 1998 18 yes #R&gt; 9 Malone, Karl 1985 2003 18 yes #R&gt; 10 Malone, Moses 1976 1994 18 yes #R&gt; # ... with 343 more rows Perhaps those whose name was Jordan. nba_jordans &lt;- players2 %&gt;% filter(grepl(&quot;Jordan&quot;,name)) nba_jordans #R&gt; # A tibble: 20 x 5 #R&gt; name start end years_played modern #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 Jordan, Michael 1984 2002 18 yes #R&gt; 2 Farmar, Jordan 2006 2016 10 yes #R&gt; 3 Jordan, DeAndre 2008 2018 10 yes #R&gt; 4 Crawford, Jordan 2010 2017 7 yes #R&gt; 5 Hill, Jordan 2009 2016 7 yes #R&gt; 6 Jordan, Eddie 1977 1983 6 yes #R&gt; 7 Jordan, Reggie 1993 1999 6 yes #R&gt; 8 Jordan, Adonis 1993 1998 5 yes #R&gt; 9 Clarkson, Jordan 2014 2018 4 yes #R&gt; 10 Hamilton, Jordan 2011 2015 4 yes #R&gt; 11 Jordan, Jerome 2011 2014 3 yes #R&gt; 12 McRae, Jordan 2015 2018 3 yes #R&gt; 13 Mickey, Jordan 2015 2017 2 yes #R&gt; 14 Adams, Jordan 2014 2015 1 yes #R&gt; 15 Bell, Jordan 2017 2018 1 yes #R&gt; 16 Jordan, Thomas 1992 1992 0 yes #R&gt; 17 Jordan, Walter 1980 1980 0 yes #R&gt; 18 Loyd, Jordan 2018 2018 0 yes #R&gt; 19 Sibert, Jordan 2018 2018 0 yes #R&gt; 20 Williams, Jordan 2011 2011 0 yes Ahhh  need to be a little tricky to get all last names that are Jordan. nba_jordans2 &lt;- players2 %&gt;% filter(grepl(&quot;Jordan,&quot;,name)) nba_jordans2 #R&gt; # A tibble: 8 x 5 #R&gt; name start end years_played modern #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 Jordan, Michael 1984 2002 18 yes #R&gt; 2 Jordan, DeAndre 2008 2018 10 yes #R&gt; 3 Jordan, Eddie 1977 1983 6 yes #R&gt; 4 Jordan, Reggie 1993 1999 6 yes #R&gt; 5 Jordan, Adonis 1993 1998 5 yes #R&gt; 6 Jordan, Jerome 2011 2014 3 yes #R&gt; 7 Jordan, Thomas 1992 1992 0 yes #R&gt; 8 Jordan, Walter 1980 1980 0 yes Also tricky to get all first names that are Jordan. nba_jordans3 &lt;- players2 %&gt;% filter(grepl(&quot;, Jordan&quot;,name)) nba_jordans3 #R&gt; # A tibble: 12 x 5 #R&gt; name start end years_played modern #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 Farmar, Jordan 2006 2016 10 yes #R&gt; 2 Crawford, Jordan 2010 2017 7 yes #R&gt; 3 Hill, Jordan 2009 2016 7 yes #R&gt; 4 Clarkson, Jordan 2014 2018 4 yes #R&gt; 5 Hamilton, Jordan 2011 2015 4 yes #R&gt; 6 McRae, Jordan 2015 2018 3 yes #R&gt; 7 Mickey, Jordan 2015 2017 2 yes #R&gt; 8 Adams, Jordan 2014 2015 1 yes #R&gt; 9 Bell, Jordan 2017 2018 1 yes #R&gt; 10 Loyd, Jordan 2018 2018 0 yes #R&gt; 11 Sibert, Jordan 2018 2018 0 yes #R&gt; 12 Williams, Jordan 2011 2011 0 yes It is intersting that there were no players in the NBA with the first name Jordan before Michael Jordan (the greatest player of all time) retired.   7.5.2 Wolves and Moose of Isle Royale In Section 6.7.2 the irmw2 data frame was created for use in the graphing course. irmw2 #R&gt; # A tibble: 61 x 6 #R&gt; year era wolves moose winter_temp ice_bridges #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 1959 early 20 538. 1.4 no #R&gt; 2 1960 early 22 564. 8.45 no #R&gt; 3 1961 early 22 572. 9.75 yes #R&gt; 4 1962 early 23 579. 2.15 yes #R&gt; 5 1963 early 20 596. -0.35 yes #R&gt; 6 1964 early 26 620. 12.4 no #R&gt; 7 1965 early 28 634. 1.25 yes #R&gt; 8 1966 early 26 661. 1.7 yes #R&gt; 9 1967 early 22 766. 2.75 yes #R&gt; 10 1968 early 22 848. 5.85 yes #R&gt; # ... with 51 more rows One of the things we did in that class is focus on the early years of the wolf-moose time series. Such a data frame is create below. irmw_early &lt;- irmw2 %&gt;% filter(era==&quot;early&quot;) Other things that we could do with these data are  Find years where the moose population was more than 1500 animals. tmp &lt;- irmw2 %&gt;% filter(moose&gt;1500) tmp #R&gt; # A tibble: 7 x 6 #R&gt; year era wolves moose winter_temp ice_bridges #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 1992 middle 12 1697. 15.2 no #R&gt; 2 1993 middle 13 1784. 9.1 no #R&gt; 3 1994 middle 17 2017. -0.4 yes #R&gt; 4 1995 middle 16 2117. 9.5 no #R&gt; 5 1996 middle 22 2398. 2.8 yes #R&gt; 6 2017 recent 2 1600 15.4 no #R&gt; 7 2019 recent 15 2060 3.5 yes Find years where the wolf population was less than 10 animals. tmp &lt;- irmw2 %&gt;% filter(wolves&lt;10) tmp #R&gt; # A tibble: 7 x 6 #R&gt; year era wolves moose winter_temp ice_bridges #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 2012 recent 9 750 17.2 no #R&gt; 2 2013 recent 8 975 8.95 no #R&gt; 3 2014 recent 9 1050 -1.05 yes #R&gt; 4 2015 recent 3 1250 3.85 yes #R&gt; 5 2016 recent 2 1300 12.0 no #R&gt; 6 2017 recent 2 1600 15.4 no #R&gt; 7 2018 recent 2 1475 6.05 yes Find years where the wolf population was less than 10 animals and the moose population was greater than 1500 animals. tmp &lt;- irmw2 %&gt;% filter(wolves&lt;10,moose&gt;1500) tmp #R&gt; # A tibble: 1 x 6 #R&gt; year era wolves moose winter_temp ice_bridges #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 2017 recent 2 1600 15.4 no Find years where ice bridges formed. tmp &lt;- irmw2 %&gt;% filter(ice_bridges==&quot;yes&quot;) tmp #R&gt; # A tibble: 26 x 6 #R&gt; year era wolves moose winter_temp ice_bridges #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 1961 early 22 572. 9.75 yes #R&gt; 2 1962 early 23 579. 2.15 yes #R&gt; 3 1963 early 20 596. -0.35 yes #R&gt; 4 1965 early 28 634. 1.25 yes #R&gt; 5 1966 early 26 661. 1.7 yes #R&gt; 6 1967 early 22 766. 2.75 yes #R&gt; 7 1968 early 22 848. 5.85 yes #R&gt; 8 1969 early 17 1041. 7.8 yes #R&gt; 9 1970 early 18 1045. 3.35 yes #R&gt; 10 1971 early 20 1183. 3.2 yes #R&gt; # ... with 16 more rows Find years in the 1970s decade and order by the descending number of wolves. tmp &lt;- irmw2 %&gt;% filter(year&gt;=1970,year&lt;1980) %&gt;% arrange(desc(wolves)) tmp #R&gt; # A tibble: 10 x 6 #R&gt; year era wolves moose winter_temp ice_bridges #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 1976 middle 44 1070. 10.4 no #R&gt; 2 1979 middle 43 857. -1.15 yes #R&gt; 3 1975 middle 41 1139. 9.05 no #R&gt; 4 1978 middle 40 845. 3.25 no #R&gt; 5 1977 middle 34 949. 4.7 yes #R&gt; 6 1974 early 31 1203. 5.65 yes #R&gt; 7 1973 early 24 1215. 10.8 no #R&gt; 8 1972 early 23 1243. -0.05 yes #R&gt; 9 1971 early 20 1183. 3.2 yes #R&gt; 10 1970 early 18 1045. 3.35 yes Find years in the 1980s decade, order by the descending number of wolves, and show only the top three years (i.e., most wolves). tmp &lt;- irmw2 %&gt;% filter(year&gt;=1980,year&lt;1990) %&gt;% arrange(desc(wolves)) %&gt;% slice_head(n=3) tmp #R&gt; # A tibble: 3 x 6 #R&gt; year era wolves moose winter_temp ice_bridges #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 1980 middle 50 788. 7.15 no #R&gt; 2 1981 middle 30 767. 11.7 no #R&gt; 3 1984 middle 24 927. 12.5 no value should be a character, factor, or integer. value must be numeric. value must be numeric. value must be numeric. value must be numeric. Note that this or operator is a vertical line which is typed with the shift-backslash key. Some examples of arrange() are in Section 6.7. "],["groupings.html", "Module 8 Groupings 8.1 Declaring Groupings 8.2 Summarizing by Groups 8.3 Wrangling by Group 8.4 Ungrouping 8.5 Examples in Context", " Module 8 Groupings In some instances data from individual observations need to be summarized by groupings of those observations. For example, you may want to compute the total number of COVID cases by county (across all months) for the data frame shown below.26 #R&gt; # A tibble: 48 x 4 #R&gt; County Month Year Cases #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 Ashland Mar 2020 1 #R&gt; 2 Ashland Apr 2020 1 #R&gt; 3 Ashland May 2020 0 #R&gt; 4 Ashland Jun 2020 1 #R&gt; 5 Ashland Jul 2020 16 #R&gt; 6 Ashland Aug 2020 16 #R&gt; 7 Ashland Sep 2020 94 #R&gt; 8 Ashland Oct 2020 167 #R&gt; 9 Ashland Nov 2020 378 #R&gt; 10 Ashland Dec 2020 331 #R&gt; # ... with 38 more rows How to summarize and wrangle data by groups is introduced in this module. 8.1 Declaring Groupings Groups may be declared by including the grouping variable or variables in group_by(). For example the code below declares groupings based on levels in County. covid_byCO &lt;- covABD %&gt;% group_by(County) covid_byCO #R&gt; # A tibble: 48 x 4 #R&gt; # Groups: County [3] #R&gt; County Month Year Cases #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 Ashland Mar 2020 1 #R&gt; 2 Ashland Apr 2020 1 #R&gt; 3 Ashland May 2020 0 #R&gt; 4 Ashland Jun 2020 1 #R&gt; 5 Ashland Jul 2020 16 #R&gt; 6 Ashland Aug 2020 16 #R&gt; 7 Ashland Sep 2020 94 #R&gt; 8 Ashland Oct 2020 167 #R&gt; 9 Ashland Nov 2020 378 #R&gt; 10 Ashland Dec 2020 331 #R&gt; # ... with 38 more rows Simply using group_by() will not produce any immediately noticeable difference in the data frame. For example, the only perceptible difference above is the addition of the Groups: County[3] line. Using group_by() only adds a grouping declaration to a data frame. How this is useful is demonstrated in the next sections. There can be multiple levels of groupings. For example, the code below will group Year within County. Note that the subsequent variables are always nested within groups of previous variables. covid_byCOYR &lt;- covABD %&gt;% group_by(County,Year) covid_byCOYR #R&gt; # A tibble: 48 x 4 #R&gt; # Groups: County, Year [6] #R&gt; County Month Year Cases #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 Ashland Mar 2020 1 #R&gt; 2 Ashland Apr 2020 1 #R&gt; 3 Ashland May 2020 0 #R&gt; 4 Ashland Jun 2020 1 #R&gt; 5 Ashland Jul 2020 16 #R&gt; 6 Ashland Aug 2020 16 #R&gt; 7 Ashland Sep 2020 94 #R&gt; 8 Ashland Oct 2020 167 #R&gt; 9 Ashland Nov 2020 378 #R&gt; 10 Ashland Dec 2020 331 #R&gt; # ... with 38 more rows   8.2 Summarizing by Groups Adding groupings to a data frame becomes most useful when that data frame is submitted to summarize() to summarize results by groups. The summarize() function takes arguments that are a name for the summary set equal to a function that creates a summary. The summary function can be any function that returns a single numeric result (Table 8.1).   Table 8.1: Common summary functions used in summarize(), especially with group_by(). Note that x generically represents a variable in the data frame and would be replaced with a specific variable name (see examples in main text). Function Summary value returned n() Number of observations27 sum(!is.na(x)) Count of non-missing values in x sum(x) Sum values in x mean(x) Mean (average) of values in x median(x) Median of values in x sd(x) Standard deviation of values in x IQR(x) Inter-quartile range of values in x max(x) Maximum value of x min(x) Minimum value of x quantile(x,p) 100\\(\\times\\)p% quantile of values in x first(x) Value of first observation of x last(x) Value of last observation of x n_distinct(x) Number of distance (i.e., unique) values of x.   For example, the code below finds the sample size (i.e., number of months) and total number of cases of COVID by county (across all months) using the first grouped data frame created in Section 8.1. sum_covid_byCO &lt;- covid_byCO %&gt;% summarize(num_mons=n(), num_cases=sum(Cases)) sum_covid_byCO #R&gt; # A tibble: 3 x 3 #R&gt; County num_mons num_cases #R&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #R&gt; 1 Ashland 16 1291 #R&gt; 2 Bayfield 16 1169 #R&gt; 3 Douglas 16 4166 The results from applying summarize() to a grouped data frame is itself a data frame with the last level of grouping removed. In the example above, there was only one level of grouping (i.e., County) so the returned result was simply a data frame with the grouping removed. However, applying the same summaries to the data frame that had groupings by both County and Year returns a data frame with summaries by year within each county, with the returned data frame retaining the first grouping (i.e., by County) but not the last (i.e., by Year). sum_covid_byCOYR &lt;- covid_byCOYR %&gt;% summarize(num_mons=n(), num_cases=sum(Cases)) sum_covid_byCOYR #R&gt; # A tibble: 6 x 4 #R&gt; # Groups: County [3] #R&gt; County Year num_mons num_cases #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #R&gt; 1 Ashland 2020 10 1005 #R&gt; 2 Ashland 2021 6 286 #R&gt; 3 Bayfield 2020 10 903 #R&gt; 4 Bayfield 2021 6 266 #R&gt; 5 Douglas 2020 10 3081 #R&gt; 6 Douglas 2021 6 1085 Summarizing this summarized but still grouped data frame will then summarize the summarized data across the remaining groupings (i.e., by County).28 Note that these results are the same as when the summarization was just by County (i.e., compare sum_covid_byCO from above to sum_covid_byCO1 below). sum_covid_byCO1 &lt;- sum_covid_byCOYR %&gt;% summarize(num_mons=sum(num_mons), num_cases=sum(num_cases)) sum_covid_byCO1 #R&gt; # A tibble: 3 x 3 #R&gt; County num_mons num_cases #R&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #R&gt; 1 Ashland 16 1291 #R&gt; 2 Bayfield 16 1169 #R&gt; 3 Douglas 16 4166   Nested levels of groupings can be very powerful, but they should be used carefully. As a general rule, multi-level summarizations on multiple grouping variables only work properly for counts and sums. Multi-level summarizations are unlikely to give the desired results when using other summaries, such as the mean or standard deviation. For example, consider this simple data frame called trouble with two grouping variables and a single measurement variable. #R&gt; # A tibble: 11 x 3 #R&gt; group1 group2 value #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 A z 10 #R&gt; 2 A z 9 #R&gt; 3 A y 10 #R&gt; 4 A y 12 #R&gt; 5 A y 13 #R&gt; 6 A y 14 #R&gt; 7 A y 55 #R&gt; 8 B z 10 #R&gt; 9 B z 9 #R&gt; 10 B y 11 #R&gt; 11 B y 55 The code below computes the sample size, sum, and mean of value for the two groups defined by group1. sum_trouble_1 &lt;- trouble %&gt;% group_by(group1) %&gt;% summarize(n=n(), sum=sum(value), mn=mean(value)) sum_trouble_1 #R&gt; # A tibble: 2 x 4 #R&gt; group1 n sum mn #R&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 A 7 123 17.6 #R&gt; 2 B 4 85 21.2 The code below computes the same summaries for the four groups defined by group2 nested within group1. sum_trouble_2 &lt;- trouble %&gt;% group_by(group1,group2) %&gt;% summarize(n=n(), sum=sum(value), mn=mean(value)) sum_trouble_2 #R&gt; # A tibble: 4 x 5 #R&gt; # Groups: group1 [2] #R&gt; group1 group2 n sum mn #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 A y 5 104 20.8 #R&gt; 2 A z 2 19 9.5 #R&gt; 3 B y 2 66 33 #R&gt; 4 B z 2 19 9.5 This last data frame is still grouped by group1 so it is possible to use it to get summaries for the two groups defined by group1. sum_trouble_1A &lt;- sum_trouble_2 %&gt;% summarize(n=sum(n), sum=sum(sum), mn=mean(mn)) sum_trouble_1A #R&gt; # A tibble: 2 x 4 #R&gt; group1 n sum mn #R&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 A 7 123 15.2 #R&gt; 2 B 4 85 21.2 A comparison of sum_trouble_1 from further above to sum_trouble_1A here reveals that both means return identical results for both groups for the count of and sum of the values and the same mean for the B group. However the mean is different for the A group. The means for the A group differ between the two methods of summarization because there were different sample sizes among the groups of group2 nested within the A group of group1. In other words, the mean for the A group was calculated as the mean of 20.8 and 19.5 without realizing that 20.8 came from five observations in the y group and 9.5 came from only two observations in the z group.29   8.2.1 Handling Missing Values Missing values are coded in R with NA. For example, this simple data frame called trouble2 has three missing values in the value variable. #R&gt; # A tibble: 11 x 3 #R&gt; group1 group2 value #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 A z 10 #R&gt; 2 A z NA #R&gt; 3 A y 10 #R&gt; 4 A y 12 #R&gt; 5 A y 13 #R&gt; 6 A y 14 #R&gt; 7 A y 55 #R&gt; 8 B z NA #R&gt; 9 B z 9 #R&gt; 10 B y NA #R&gt; 11 B y 55 Most of the summary functions shown in Table 8.1 will return NA if the variable being summarized contains any NAs. For example, the code below attempts to count the number of values in value and compute the mean and standard deviation of value for each group in group1. tmp &lt;- trouble2 %&gt;% group_by(group1) %&gt;% summarize(n=n(), mn=mean(value), sd=sd(value)) tmp #R&gt; # A tibble: 2 x 4 #R&gt; group1 n mn sd #R&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 A 7 NA NA #R&gt; 2 B 4 NA NA There are at least two issues here. First, the count variable (n) suggests that there were 7 and 4 valid observations in the two groups, when in reality there is only 6 and 2. Second, the means and standard deviations could not be properly calculated because of the NAs in value. The first issue of counting valid observations is addressed by using the sum(!is.na(x)) code shown in Table 8.1. This code is a combination of two functions. The is.na() function returns TRUE if an element is an NA (and FALSE otherwise). The exclamation point in front of is.na() takes the complement of these values (i.e., TRUE becomes FALSE and vice versa) such that !is.na() returns TRUE if the element is not an NA. When logical values are given to sum() the TRUEs are converted to 1s and the FALSEs to 0s. Thus, the sum() of these logicals will return the number of TRUEs or, in this case, the number of elements that are not NA; i.e., the number of valid observations. The second issue of the summary function returning NA if an NA exists in the variable is addressed by including na.rm=TRUE within the summary function. This argument serves to remove the NAs from the calculations and will, thus, return the summary of all non-missing elements. Thus, the following code provides a better summary of the count, mean, and standard deviation of the value variable. tmp &lt;- trouble2 %&gt;% group_by(group1) %&gt;% summarize(n=n(), n_valid=sum(!is.na(value)), mn=mean(value,na.rm=TRUE), sd=sd(value,na.rm=TRUE)) tmp #R&gt; # A tibble: 2 x 5 #R&gt; group1 n n_valid mn sd #R&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 A 7 6 19 17.7 #R&gt; 2 B 4 2 32 32.5   8.3 Wrangling by Group Groupings can also be used with other dplyr verbs. For example, consider this simple data frame called grades that has hypothetical exam scores for students in two sections of a course. #R&gt; # A tibble: 11 x 3 #R&gt; last section grade #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 Boshwitz 1 87.2 #R&gt; 2 Lepal 1 56.9 #R&gt; 3 Smith 1 74.4 #R&gt; 4 Felix 1 92.5 #R&gt; 5 Seidel 1 88.2 #R&gt; 6 Phelps 2 71.2 #R&gt; 7 McLaughlin 2 88.4 #R&gt; 8 Robertson 2 56.5 #R&gt; 9 Jak 2 78.3 #R&gt; 10 Abel 2 67.6 #R&gt; 11 Bonham 2 80.3 The code below uses rank() and desc() to create a new variable that is the rank of the student in the course based on their grade. The desc() function must be used here to assure that the student with the highest grade is given a rank of 1 (because rank() ranks in ascending order by default). tmp &lt;- grades %&gt;% mutate(rnk=rank(desc(grade))) %&gt;% arrange(rnk) tmp #R&gt; # A tibble: 11 x 4 #R&gt; last section grade rnk #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 Felix 1 92.5 1 #R&gt; 2 McLaughlin 2 88.4 2 #R&gt; 3 Seidel 1 88.2 3 #R&gt; 4 Boshwitz 1 87.2 4 #R&gt; 5 Bonham 2 80.3 5 #R&gt; 6 Jak 2 78.3 6 #R&gt; 7 Smith 1 74.4 7 #R&gt; 8 Phelps 2 71.2 8 #R&gt; 9 Abel 2 67.6 9 #R&gt; 10 Lepal 1 56.9 10 #R&gt; 11 Robertson 2 56.5 11 However, suppose that interest is in the rank WITHIN each section. Here group_by() can be used prior to mutate() so that the methods in mutate() are applied separately to each group. grades %&lt;&gt;% group_by(section) %&gt;% mutate(rnk=rank(desc(grade))) %&gt;% arrange(section,rnk) grades #R&gt; # A tibble: 11 x 4 #R&gt; # Groups: section [2] #R&gt; last section grade rnk #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 Felix 1 92.5 1 #R&gt; 2 Seidel 1 88.2 2 #R&gt; 3 Boshwitz 1 87.2 3 #R&gt; 4 Smith 1 74.4 4 #R&gt; 5 Lepal 1 56.9 5 #R&gt; 6 McLaughlin 2 88.4 1 #R&gt; 7 Bonham 2 80.3 2 #R&gt; 8 Jak 2 78.3 3 #R&gt; 9 Phelps 2 71.2 4 #R&gt; 10 Abel 2 67.6 5 #R&gt; 11 Robertson 2 56.5 6 Note that in contrast to summarize() that the grouping is not removed from the data frame when mutate() is used. Further suppose that the data frame should be reduced to the three students with the highest grades in EACH section. Here filter() can be used to filter the data within each grouping. top3 &lt;- grades %&gt;% filter(rnk&lt;=3) top3 #R&gt; # A tibble: 6 x 4 #R&gt; # Groups: section [2] #R&gt; last section grade rnk #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 Felix 1 92.5 1 #R&gt; 2 Seidel 1 88.2 2 #R&gt; 3 Boshwitz 1 87.2 3 #R&gt; 4 McLaughlin 2 88.4 1 #R&gt; 5 Bonham 2 80.3 2 #R&gt; 6 Jak 2 78.3 3 Once again, note that the grouping is not removed from the data frame when using filter(). Thus, one could immediately calculate the mean grade for the highest three grades in each section. top3 %&gt;% summarize(n=n(), mn=mean(grade)) #R&gt; # A tibble: 2 x 3 #R&gt; section n mn #R&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #R&gt; 1 1 3 89.3 #R&gt; 2 2 3 82.3   The use of mutate() with group_by() is less common but can be very powerful. As a simple example, suppose that one wanted to find the difference between each observation and the mean of its group. In the example below, the use of mean() within mutate() will find the mean for each group because of the use of group_by(). Because this is within a mutate() rather than a summarize() it is repeated for each observation in each group. tmp &lt;- trouble2 %&gt;% group_by(group1) %&gt;% mutate(mn=mean(value,na.rm=TRUE), diff=value-mn) tmp #R&gt; # A tibble: 11 x 5 #R&gt; # Groups: group1 [2] #R&gt; group1 group2 value mn diff #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 A z 10 19 -9 #R&gt; 2 A z NA 19 NA #R&gt; 3 A y 10 19 -9 #R&gt; 4 A y 12 19 -7 #R&gt; 5 A y 13 19 -6 #R&gt; 6 A y 14 19 -5 #R&gt; 7 A y 55 19 36 #R&gt; 8 B z NA 32 NA #R&gt; 9 B z 9 32 -23 #R&gt; 10 B y NA 32 NA #R&gt; 11 B y 55 32 23   8.4 Ungrouping As a general rule-of-thumb it is best to remove the groupings from your data frame once you know you are done summarizing, filtering, etc. based on groups. There are two main reasons for this. First, as noted above, many dplyr verbs work on groupings. Thus, if your data frame maintins groupings after you are done (in your mind) with groupings then you may get unintended results. As a very simple example, suppose that you want to use slice() to retain ONLY the first row of a data frame. However, if that data frame has groupings (e.g., after a first level of summarizing) then slice() will return rows from each group. For example, suppose that you want only the first row of sum_trouble_2 created above (note below that it retained a grouping variable). sum_trouble_2 #R&gt; # A tibble: 4 x 5 #R&gt; # Groups: group1 [2] #R&gt; group1 group2 n sum mn #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 A y 5 104 20.8 #R&gt; 2 A z 2 19 9.5 #R&gt; 3 B y 2 66 33 #R&gt; 4 B z 2 19 9.5 tmp &lt;- sum_trouble_2 %&gt;% slice(1) tmp #R&gt; # A tibble: 2 x 5 #R&gt; # Groups: group1 [2] #R&gt; group1 group2 n sum mn #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 A y 5 104 20.8 #R&gt; 2 B y 2 66 33 As you can see, slice() was applied to both groups of group1 such that the first row of each group was returned, which was not the intended outcome. As another example, suppose that you wanted to change the names of the groups in group1 in sum_trouble_2. tmp &lt;- sum_trouble_2 %&gt;% mutate(group1=plyr::mapvalues(group1,from=c(&quot;A&quot;,&quot;B&quot;),to=c(&quot;Alex&quot;,&quot;Bart&quot;))) #R&gt; The following `from` values were not present in `x`: B #R&gt; The following `from` values were not present in `x`: A tmp #R&gt; # A tibble: 4 x 5 #R&gt; # Groups: group1 [2] #R&gt; group1 group2 n sum mn #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 Alex y 5 104 20.8 #R&gt; 2 Alex z 2 19 9.5 #R&gt; 3 Bart y 2 66 33 #R&gt; 4 Bart z 2 19 9.5 While this ultimately worked the messages shown in the output suggest an issue. Again the mutate() is applied by groups and when working with group A there is no group B which leads to the first message (and the second message comes from the opposite problem when working with group B). Both of these issues can be corrected by using ungroup() to remove the groupings from the data frame. tmp &lt;- sum_trouble_2 %&gt;% ungroup() %&gt;% mutate(group1=plyr::mapvalues(group1,from=c(&quot;A&quot;,&quot;B&quot;),to=c(&quot;Alex&quot;,&quot;Bart&quot;))) %&gt;% slice(1) tmp #R&gt; # A tibble: 1 x 5 #R&gt; group1 group2 n sum mn #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 Alex y 5 104 20.8 As a general rule-of-thumb, I suggest using ungroup() at the end of a piping chain where you know you are done with the groupings. For example, instead of using ungroup() as in the previous code, I would have created sum_trouble_2 as such. sum_trouble_2 &lt;- trouble %&gt;% group_by(group1,group2) %&gt;% summarize(n=n(), sum=sum(value), mn=mean(value)) %&gt;% ungroup() sum_trouble_2 #R&gt; # A tibble: 4 x 5 #R&gt; group1 group2 n sum mn #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 A y 5 104 20.8 #R&gt; 2 A z 2 19 9.5 #R&gt; 3 B y 2 66 33 #R&gt; 4 B z 2 19 9.5 Notice how the tibble does not showing any grouping structure.   8.5 Examples in Context 8.5.1 Student Data In Section 4.3.1 a data frame called schedules2 was constructued that contained a students ID number with each course they were enrolled along with the courses credits and instructor. schedules2 #R&gt; # A tibble: 20 x 4 #R&gt; studentID course credits instructor #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 34535 MTH107 4 Ogle #R&gt; 2 34535 BIO115 4 Johnson #R&gt; 3 34535 CHM110 4 Carlson #R&gt; 4 34535 IDS101 3 Goyke #R&gt; 5 45423 SCD110 3 Tochterman #R&gt; 6 45423 PSY110 4 Sneyd #R&gt; 7 45423 MTH140 4 Jensen #R&gt; 8 45423 OED212 3 Andre #R&gt; 9 45423 IDS101 3 Goyke #R&gt; 10 73424 BIO234 4 Goyke #R&gt; 11 73424 CHM220 4 Robertson #R&gt; 12 73424 BIO370 4 Anich #R&gt; 13 73424 SCD110 3 Tochterman #R&gt; 14 89874 SCD440 4 Foster #R&gt; 15 89874 PSY370 4 Sneyd #R&gt; 16 89874 IDS490 4 Hannickel #R&gt; 17 98222 SCD440 4 Foster #R&gt; 18 98222 SCD330 3 Tochterman #R&gt; 19 98222 SOC480 4 Schanning #R&gt; 20 98222 ART220 3 Duffy Additionally, recall that there was a data frame called personal that contained personal information about each student (along with the ID). personal #R&gt; studentID first_nm last_nm hometown homestate #R&gt; 1 34535 Rolando Blackman Windsor MI #R&gt; 2 45423 Catherine Johnson Eden Prairie MN #R&gt; 3 73424 James Carmichael Marion IA #R&gt; 4 89874 Rachel Brown Milwaukee WI #R&gt; 5 98222 Esteban Perez El Paso TX In this example, suppose that the registrar wants to creat a database that has the number of courses and the total number of credits taken appended to the personal information for each student. Construction of this database begins by summarizing schedules2 for each student. sum_crs &lt;- schedules2 %&gt;% group_by(studentID) %&gt;% summarize(num_courses=n(), num_credits=sum(credits)) sum_crs #R&gt; # A tibble: 5 x 3 #R&gt; studentID num_courses num_credits #R&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #R&gt; 1 34535 4 15 #R&gt; 2 45423 5 17 #R&gt; 3 73424 4 15 #R&gt; 4 89874 3 12 #R&gt; 5 98222 4 14 These results can then be left_join()ed with personal to create the desired database. personal2 &lt;- personal %&gt;% left_join(sum_crs,by=&quot;studentID&quot;) personal2 #R&gt; studentID first_nm last_nm hometown homestate num_courses num_credits #R&gt; 1 34535 Rolando Blackman Windsor MI 4 15 #R&gt; 2 45423 Catherine Johnson Eden Prairie MN 5 17 #R&gt; 3 73424 James Carmichael Marion IA 4 15 #R&gt; 4 89874 Rachel Brown Milwaukee WI 3 12 #R&gt; 5 98222 Esteban Perez El Paso TX 4 14   8.5.2 Resource Sampling Data In Section 4.3.2 a data frame called fishcatch was created that had the species and number of that species caught in each of five nets. The date and lake where the net was set was also recorded. fishcatch #R&gt; net_num lake date species number #R&gt; 1 1 Eagle 3-Jul-21 Bluegill 7 #R&gt; 2 1 Eagle 3-Jul-21 Largemouth Bass 3 #R&gt; 3 2 Hart 3-Jul-21 Bluegill 19 #R&gt; 4 2 Hart 3-Jul-21 Largemouth Bass 2 #R&gt; 5 2 Hart 3-Jul-21 Bluntnose Minnow 56 #R&gt; 6 3 Hart 5-Jul-21 &lt;NA&gt; NA #R&gt; 7 4 Eagle 6-Jul-21 Bluegill 3 #R&gt; 8 4 Eagle 6-Jul-21 Largemouth Bass 6 #R&gt; 9 5 Millicent 6-Jul-21 Largemouth Bass 3 Suppose a technician wants to summarize the number of species caught and the total catch (regardless of species) in each net. An examination of the data frame above reveals NAs for species and number for one of the nets that did not catch any fish. Because of this we cannot simply count the number of rows for each net_num to get the number of species. Instead this calculation will have to be treated as described for finding the valid number of observations. The total catch in each net_num can be found with sum() but it must include na.rm=TRUE to account for the missing data. tmp &lt;- fishcatch %&gt;% group_by(net_num) %&gt;% summarize(num_spec=sum(!is.na(species)), ttl_catch=sum(number,na.rm=TRUE)) tmp #R&gt; # A tibble: 5 x 3 #R&gt; net_num num_spec ttl_catch #R&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; #R&gt; 1 1 2 10 #R&gt; 2 2 3 77 #R&gt; 3 3 0 0 #R&gt; 4 4 2 9 #R&gt; 5 5 1 3 The resulting data frame is missing the specific information (date and lake) for each net_num. A trick for including information that is specific (and thus repeated) to the grouping variable is to include those variables as grouping variables prior to the main grouping variable. For example, there is only one net_num per lake and date combination so including lake and date prior to net_num will not alter the results but will retain the lake and date values. If you use this trick, make sure to ungroup() after the summarization so there are no unintended consequences of adding the extra grouping variables. tmp &lt;- fishcatch %&gt;% group_by(lake,date,net_num) %&gt;% summarize(num_spec=sum(!is.na(species)), ttl_catch=sum(number,na.rm=TRUE)) %&gt;% ungroup() %&gt;% arrange(net_num) %&gt;% relocate(net_num) tmp #R&gt; # A tibble: 5 x 5 #R&gt; net_num lake date num_spec ttl_catch #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; #R&gt; 1 1 Eagle 3-Jul-21 2 10 #R&gt; 2 2 Hart 3-Jul-21 3 77 #R&gt; 3 3 Hart 5-Jul-21 0 0 #R&gt; 4 4 Eagle 6-Jul-21 2 9 #R&gt; 5 5 Millicent 6-Jul-21 1 3   8.5.3 Wolves and Moose of Isle Royale In Section 6.7.2 a data frame called irmw2 was created that contained the number of wolves and moose, the winter air temperature, and whether or not an ice bridge to the mainland formed for each year from 1959-2012. In that module, an era variable was also created that categorized the years into early, middle, and late time periods. Suppose that the researchers want to compute summary statistics for the number of moose separated by era, and by era and whether an ice bridge formed. The latter is accomplished below. tmp &lt;- irmw2 %&gt;% group_by(era,ice_bridges) %&gt;% summarize(n=n(), n_valid=sum(!is.na(moose)), mean=mean(moose,na.rm=TRUE), sd=sd(moose,na.rm=TRUE), min=min(moose,na.rm=TRUE), Q1=quantile(moose,0.25,na.rm=TRUE), median=median(moose,na.rm=TRUE), Q3=quantile(moose,0.75,na.rm=TRUE), max=max(moose,na.rm=TRUE)) %&gt;% ungroup() tmp #R&gt; # A tibble: 6 x 11 #R&gt; era ice_bridges n n_valid mean sd min Q1 median Q3 max #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 early no 4 4 734. 322. 538. 557. 592. 769. 1215. #R&gt; 2 early yes 12 12 864. 264. 572. 624. 807. 1079. 1243. #R&gt; 3 middle no 17 17 1150. 381. 767. 925. 1031. 1260. 2117. #R&gt; 4 middle yes 9 9 1277. 575. 780. 900. 976. 1496. 2398. #R&gt; 5 recent no 14 14 816. 364. 385 519. 750 1069. 1600 #R&gt; 6 recent yes 5 5 1297 523. 650 1050 1250 1475 2060 Here I ungroup()ed the data frame because I want to make sure that I am not tempted to summarize the returned data frame that would have still had groupings by era. As mentioned in the main text it is inappropriate to compute most summaries on a second level of groupings after summarizing by the first level of groupings. Thus, the first goal of the researchers is then accomplished below. tmp &lt;- irmw2 %&gt;% group_by(era) %&gt;% summarize(n=n(), n_valid=sum(!is.na(moose)), mean=mean(moose,na.rm=TRUE), sd=sd(moose,na.rm=TRUE), min=min(moose,na.rm=TRUE), Q1=quantile(moose,0.25,na.rm=TRUE), median=median(moose,na.rm=TRUE), Q3=quantile(moose,0.75,na.rm=TRUE), max=max(moose,na.rm=TRUE)) %&gt;% ungroup() tmp #R&gt; # A tibble: 3 x 10 #R&gt; era n n_valid mean sd min Q1 median Q3 max #R&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 early 16 16 832. 274. 538. 592. 713. 1079. 1243. #R&gt; 2 middle 26 26 1194. 450. 767. 906. 1023. 1301. 2398. #R&gt; 3 recent 19 19 943. 452. 385 535 900 1185. 2060 This data frame was introduced in Module 5. There are no arguments to n(). Note here the use of the summarized but still grouped data frame and that the computation of numbers of months and cases had to be adjusted for the new variables in the summarized data frame. In the two-level summarize the mean of the A group is calculated as \\(\\frac{20.8+19.5}{1+1}\\) rather than \\(\\frac{104+19}{5+2}\\). "],["dates-and-times.html", "Module 9 Dates and Times 9.1 Obtaining Dates Data 9.2 Extracting Date Components 9.3 Calculations with Dates 9.4 Obtaining Time Data 9.5 Extracting Time Components 9.6 Calculations with Date-Times 9.7 Examples in Context", " Module 9 Dates and Times One of the most common and most difficult types of data to wrangle is date, time, or date and time data. Dates, for example, can be entered in a variety of formats (with different standards for different parts of the world) and there are different numbers of days in months, leap years, and starts of the week. Times have complications related to, for example, different formats (e.g., 12- versue 24-hour clock) and time zones. The most common (rather than all) difficulties with dates and times will be addressed in this module. The methods in this module depend on functions from lubridate, which must be explicitly loaded as it is not part of tidyverse.30 library(lubridate)   9.1 Obtaining Dates Data 9.1.1 Making Dates from Strings Dates are often entered as string or character class data, which can make them fairly easily to deal with. However, dates can be entered in many different formats, some of which can be ambiguous as to what date they represent. For example, July 15th in 2021 could be formatted as July 15, 2021, 15-Jul-2021, 15-Jul-21, 15-July-2021, or 2021-Jul-15, among other possibilities. Fortunately, lubridate has a suite of functions that can easily convert strings to dates as long as all dates are entered in the same format and you know what that format is. The lubridate function names are combinations of y, m, and d in order of the year, month, and day components of the date format. For example, if dates are given as year, month, and day then use ymd(). Alternatively, if dates are given as month, day, and year then use mdy(). Each lubridate function is good at deciphering the proper dates regardless of how the components are separated (dashes, slashes, commas, spaces) or whether words or numbers are used for months. For example, a data frame is created below that has dates in year-month-day format in the DSTR variable which is then converted with ymd() to the DATE variable. Note how the DATE variable is of the date data class, which is what is needed for proper graphing and calculation as shown in later sections. ex1 &lt;- tibble(DSTR=c(&quot;2021-7-15&quot;,&quot;2020-9-21&quot;,&quot;2019-3-3&quot;), DATE=ymd(DSTR)) ex1 #R&gt; # A tibble: 3 x 2 #R&gt; DSTR DATE #R&gt; &lt;chr&gt; &lt;date&gt; #R&gt; 1 2021-7-15 2021-07-15 #R&gt; 2 2020-9-21 2020-09-21 #R&gt; 3 2019-3-3 2019-03-03 The following examples are similar except that the date strings are in different formats so different lubridate functions are used. Note how the DATE variable in each example has the same year-month-day format. Thus, regardless of the original format of the date, the date class variable will be the same format. ex2 &lt;- tibble(DSTR=c(&quot;July 15, 2021&quot;,&quot;September 11, 2020&quot;,&quot;March 3, 2019&quot;), DATE=mdy(DSTR)) ex2 #R&gt; # A tibble: 3 x 2 #R&gt; DSTR DATE #R&gt; &lt;chr&gt; &lt;date&gt; #R&gt; 1 July 15, 2021 2021-07-15 #R&gt; 2 September 11, 2020 2020-09-11 #R&gt; 3 March 3, 2019 2019-03-03 ex3 &lt;- tibble(DSTR=c(&quot;Jul-15, 2021&quot;,&quot;Sep-11, 2020&quot;,&quot;Mar-3, 2019&quot;), DATE=mdy(DSTR)) ex3 #R&gt; # A tibble: 3 x 2 #R&gt; DSTR DATE #R&gt; &lt;chr&gt; &lt;date&gt; #R&gt; 1 Jul-15, 2021 2021-07-15 #R&gt; 2 Sep-11, 2020 2020-09-11 #R&gt; 3 Mar-3, 2019 2019-03-03 ex4 &lt;- tibble(DSTR=c(&quot;7/15/2021&quot;,&quot;9/11/2020&quot;,&quot;3/3/2019&quot;), DATE=mdy(DSTR)) ex4 #R&gt; # A tibble: 3 x 2 #R&gt; DSTR DATE #R&gt; &lt;chr&gt; &lt;date&gt; #R&gt; 1 7/15/2021 2021-07-15 #R&gt; 2 9/11/2020 2020-09-11 #R&gt; 3 3/3/2019 2019-03-03 ex5 &lt;- tibble(DSTR=c(&quot;15-Jul 2021&quot;,&quot;11-Sep 2020&quot;,&quot;3-Mar 2019&quot;), DATE=dmy(DSTR)) ex5 #R&gt; # A tibble: 3 x 2 #R&gt; DSTR DATE #R&gt; &lt;chr&gt; &lt;date&gt; #R&gt; 1 15-Jul 2021 2021-07-15 #R&gt; 2 11-Sep 2020 2020-09-11 #R&gt; 3 3-Mar 2019 2019-03-03   9.1.2 Making Dates from Components It is also common to need to created dates from three separate variables that contain the year, month, and day components of the date, respectively. ex6 &lt;- tibble(yr=c(2021,2020,2019), mon=c(&quot;Jul&quot;,&quot;Sep&quot;,&quot;Mar&quot;), d=c(15,11,3)) ex6 #R&gt; # A tibble: 3 x 3 #R&gt; yr mon d #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 2021 Jul 15 #R&gt; 2 2020 Sep 11 #R&gt; 3 2019 Mar 3 An easy way to deal with these date components is to first combine them into a string with paste(). ex6a &lt;- ex6 %&gt;% mutate(DSTR=paste(mon,d,yr)) ex6a #R&gt; # A tibble: 3 x 4 #R&gt; yr mon d DSTR #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; #R&gt; 1 2021 Jul 15 Jul 15 2021 #R&gt; 2 2020 Sep 11 Sep 11 2020 #R&gt; 3 2019 Mar 3 Mar 3 2019 The date class variable is then created with mdy() (in this case because of the order in which the components were pasted). ex6a %&lt;&gt;% mutate(DATE=mdy(DSTR)) ex6a #R&gt; # A tibble: 3 x 5 #R&gt; yr mon d DSTR DATE #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;date&gt; #R&gt; 1 2021 Jul 15 Jul 15 2021 2021-07-15 #R&gt; 2 2020 Sep 11 Sep 11 2020 2020-09-11 #R&gt; 3 2019 Mar 3 Mar 3 2019 2019-03-03 The paste() is often used inside of mdy() to eliminate the need to create the intermediate DSTR variable. This is shown below, along with eliminating the original component variables to make a cleaner data frame to use in the next sections. ex6a &lt;- ex6 %&gt;% mutate(DATE=mdy(paste(mon,d,yr))) %&gt;% select(DATE) ex6a #R&gt; # A tibble: 3 x 1 #R&gt; DATE #R&gt; &lt;date&gt; #R&gt; 1 2021-07-15 #R&gt; 2 2020-09-11 #R&gt; 3 2019-03-03   9.2 Extracting Date Components The year, month, and day (within the month) can be extracted from a date class variable with year(), month(), and day(), respectively. The numeric month is extracted by month() by default. The abbreviated month will be returned if label=TRUE is used and the full month name is returned by also including abbr=FALSE. ex6b &lt;- ex6a %&gt;% mutate(yr=year(DATE), mon=month(DATE), mon1=month(DATE,label=TRUE), mon2=month(DATE,label=TRUE,abbr=FALSE), d=day(DATE)) ex6b #R&gt; # A tibble: 3 x 6 #R&gt; DATE yr mon mon1 mon2 d #R&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;int&gt; #R&gt; 1 2021-07-15 2021 7 Jul July 15 #R&gt; 2 2020-09-11 2020 9 Sep September 11 #R&gt; 3 2019-03-03 2019 3 Mar March 3 Note that the two variables of month names are of the ord class, which means that the natural order of the months is maintained. This is useful for graphing and for making comparisons. For example, ex6b$mon1 &gt; &quot;Apr&quot; #R&gt; [1] TRUE TRUE FALSE There are other useful extractor functions in lubridate. Day number within the year is returned with yday().31 yday(ex6a$DATE) #R&gt; [1] 196 255 62 Numeric day of the week is returned by wday().32 The abbreviated name of the week is returned when label=TRUE is included and the full names is returned when abbr=FALSE is also included. The data type will also be ord when labels are returned. wday(ex6a$DATE) #R&gt; [1] 5 6 1 wday(ex6a$DATE,label=TRUE) #R&gt; [1] Thu Fri Sun #R&gt; Levels: Sun &lt; Mon &lt; Tue &lt; Wed &lt; Thu &lt; Fri &lt; Sat wday(ex6a$DATE,label=TRUE,abbr=FALSE) #R&gt; [1] Thursday Friday Sunday #R&gt; 7 Levels: Sunday &lt; Monday &lt; Tuesday &lt; Wednesday &lt; Thursday &lt; ... &lt; Saturday Week number within the year is returned with week().33 week(ex6a$DATE) #R&gt; [1] 28 37 9 Numeric day within a quarter is returned by qday(), whereas the actual quarter in which the day falls is returned by quarter(). quarter(ex6a$DATE) #R&gt; [1] 3 3 1 qday(ex6a$DATE) #R&gt; [1] 15 73 62 Whether or not a year is a leap year can be determined with leap_year(). leap_year(2010:2020) #R&gt; [1] FALSE FALSE TRUE FALSE FALSE FALSE TRUE FALSE FALSE FALSE TRUE Finally, the current date is found with today(). today() #R&gt; [1] &quot;2021-08-12&quot;   9.3 Calculations with Dates Performing calculations on dates introduces new data classes. The main one that we will use in this course is interval. An interval is a special date class that records the start and end date of an interval of time. Intervals are created from two dates with %--%. For example, the code below creates one interval from that date in DATE to todays date and another constant interval from January 1, 2019 to January 1, 2021. Note in the second example that the date strings must be converted to a date format first (using ymd() in this case). ex6c &lt;- ex6a %&gt;% mutate(int2now=DATE %--% today(), int2Jan20=ymd(&quot;2019-Jan-1&quot;) %--% ymd(&quot;2021-Jan-1&quot;)) ex6c #R&gt; # A tibble: 3 x 3 #R&gt; DATE int2now int2Jan20 #R&gt; &lt;date&gt; &lt;Interval&gt; &lt;Interval&gt; #R&gt; 1 2021-07-15 2021-07-15 UTC--2021-08-12 UTC 2019-01-01 UTC--2021-01-01 UTC #R&gt; 2 2020-09-11 2020-09-11 UTC--2021-08-12 UTC 2019-01-01 UTC--2021-01-01 UTC #R&gt; 3 2019-03-03 2019-03-03 UTC--2021-08-12 UTC 2019-01-01 UTC--2021-01-01 UTC Here you can see that the two new variables contain start and end dates for the interval on either side of the --. Use %within% to determine if a date is within an interval and int_overlaps() to determine if two intervals overlap. ymd(&quot;2020-Jan-1&quot;) %within% ex6c$int2now #R&gt; [1] FALSE FALSE TRUE int_overlaps(ex6c$int2now,ex6c$int2Jan20) #R&gt; [1] FALSE TRUE TRUE The amount of time within an interval is found with time_length() with units of measurement supplied to unit=. When units= \"months\" or \"years\" then time_length() will take into account that not all months and years have the same number of days.34 ex6d &lt;- ex6a %&gt;% mutate(int2now=ex1$DATE %--% today(), dur2now_days=time_length(int2now,unit=&quot;days&quot;), dur2now_yrs=time_length(int2now,unit=&quot;years&quot;), dur2now_mons=time_length(int2now,unit=&quot;months&quot;)) select(ex6d,-DATE) # only so that the new variables can be seen #R&gt; # A tibble: 3 x 4 #R&gt; int2now dur2now_days dur2now_yrs dur2now_mons #R&gt; &lt;Interval&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 2021-07-15 UTC--2021-08-12 UTC 28 0.0767 0.903 #R&gt; 2 2020-09-21 UTC--2021-08-12 UTC 325 0.890 10.7 #R&gt; 3 2019-03-03 UTC--2021-08-12 UTC 893 2.44 29.3   9.4 Obtaining Time Data 9.4.1 Just Times One can work with just time in R, but I find it easier to append a constant dummy date to the times and then work with date-time objects. For example, suppose that the data frame below with just times (as a character variable) exists. exT1 &lt;- tibble(TSTR=c(&quot;12:15:01&quot;,&quot;9:14:56&quot;,&quot;19:34:01&quot;)) exT1 #R&gt; # A tibble: 3 x 1 #R&gt; TSTR #R&gt; &lt;chr&gt; #R&gt; 1 12:15:01 #R&gt; 2 9:14:56 #R&gt; 3 19:34:01 Here, I prepend a dummy date of 1-Jan-2021 to each time. exT1 %&lt;&gt;% mutate(DTSTR=paste(&quot;1-Jan-2021&quot;,TSTR)) exT1 #R&gt; # A tibble: 3 x 2 #R&gt; TSTR DTSTR #R&gt; &lt;chr&gt; &lt;chr&gt; #R&gt; 1 12:15:01 1-Jan-2021 12:15:01 #R&gt; 2 9:14:56 1-Jan-2021 9:14:56 #R&gt; 3 19:34:01 1-Jan-2021 19:34:01 This date and time string can then be handled as shown in the Section 9.6. 9.4.2 Dates and Times Date and time strings should be in a general format that has the date first followed by the time with the two separated by a space. The date portion can be in any format as described in Section 9.1 for dates and the time should generally be in hour-minute or hour-minute-second format. The time components can be separated by nearly any character but it will usually be a : The DTSTR variable in the data frame created in the previous section is in this format, as is the same variable in the data frame below. exT2 &lt;- tibble(DTSTR=c(&quot;2021-7-15 12:15:01&quot;,&quot;2020-9-21 9:14:56&quot;,&quot;2019-3-3 19:34:01&quot;)) exT2 #R&gt; # A tibble: 3 x 1 #R&gt; DTSTR #R&gt; &lt;chr&gt; #R&gt; 1 2021-7-15 12:15:01 #R&gt; 2 2020-9-21 9:14:56 #R&gt; 3 2019-3-3 19:34:01 a character variable with date and times in these formats are converted to a date-time class variable with the lubridate functions described in Section 9.1 but with _hm or _hms appended depending on whether the time portion is hour-minute or hour-minute-second data. For example, if the dates are in year-month-day format and the times are in hours-minutes-seconds then use ymd_hms(). Another concern with converting to a date-time class is concerns about the time zone. This most likely becomes an issue if you are finding intervals of time from a base time (say, New Years at 12 am) or among times from different time zones (e.g., airline flight data). The time zone for a date-time variable can be set with tz=. The time-zone is set with so-called Olson Names. You can see all names recognized in R with OlsonNames(). Most Olson Names begin with a continentent separated by a place on that continent by a forward slash. For example, America/Chicago would use the time zone for Chicago in America (i.e., Central time). Time zones in the United States can also generally be set with US/Eastern, US/Central, US/Mountain, and US/Pacific. Note, however, that time zones are odd for some areas so there are special codes for those places. One of regional note is US/Michigan. The code below converts the DTSTR string in exT2 to a date-time class using the US/Central time zone and removes the original string (for aesthetics only). Note how the new variable is a datetime class. exT2 %&lt;&gt;% mutate(DATETIME=ymd_hms(DTSTR,tz=&quot;US/Central&quot;)) %&gt;% select(-DTSTR) exT2 #R&gt; # A tibble: 3 x 1 #R&gt; DATETIME #R&gt; &lt;dttm&gt; #R&gt; 1 2021-07-15 12:15:01 #R&gt; 2 2020-09-21 09:14:56 #R&gt; 3 2019-03-03 19:34:01 9.5 Extracting Time Components Hours, minutes, and seconds from a date-time object can be extracted with hour(), minute(), and second(). exT2 %&gt;% mutate(hr=hour(DATETIME), min=minute(DATETIME), sec=second(DATETIME)) #R&gt; # A tibble: 3 x 4 #R&gt; DATETIME hr min sec #R&gt; &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #R&gt; 1 2021-07-15 12:15:01 12 15 1 #R&gt; 2 2020-09-21 09:14:56 9 14 56 #R&gt; 3 2019-03-03 19:34:01 19 34 1 9.6 Calculations with Date-Times As shown with dates in Section 9.3, intervals of time can be found between two times. In the example below int2now contains the interval of time between the date-time in DATETIME and the current date-time as returned by now().35 The number of hours and days are then found using time_length() in the same was as shown for dates in Section 9.3. I moved the int2now variable to the end simply so that the other two variables would show in the tibble. exT2 %&lt;&gt;% mutate(int2now=DATETIME %--% now(), hrs2now=time_length(int2now,unit=&quot;hours&quot;), days2now=time_length(int2now,unit=&quot;days&quot;)) %&gt;% relocate(int2now,.after=last_col()) exT2 #R&gt; # A tibble: 3 x 4 #R&gt; DATETIME hrs2now days2now #R&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 2021-07-15 12:15:01 682. 28.4 #R&gt; 2 2020-09-21 09:14:56 7813. 326. #R&gt; 3 2019-03-03 19:34:01 21434. 893. #R&gt; # ... with 1 more variable: int2now &lt;Interval&gt;   A quick return to the data frame from Section 9.4.1. Suppose that the researcher wants to find the number of minutes between the given time (which was converted to a date-time) and dinner at 6 pm. Note that if you use the trick of adding a dummy date then you must use the same dummy date here. exT1a &lt;- exT1 %&gt;% mutate(DATETIME=dmy_hms(DTSTR,tz=&quot;US/Central&quot;), int2dinner=DATETIME %--% dmy_hms(&quot;1-Jan-2021 18:00:00&quot;,tz=&quot;US/Central&quot;), mins2dinner=time_length(int2dinner,unit=&quot;minutes&quot;)) %&gt;% select(-TSTR,-DTSTR) %&gt;% relocate(mins2dinner,.after=DATETIME) exT1a #R&gt; # A tibble: 3 x 3 #R&gt; DATETIME mins2dinner #R&gt; &lt;dttm&gt; &lt;dbl&gt; #R&gt; 1 2021-01-01 12:15:01 345. #R&gt; 2 2021-01-01 09:14:56 525. #R&gt; 3 2021-01-01 19:34:01 -94.0 #R&gt; # ... with 1 more variable: int2dinner &lt;Interval&gt; 9.7 Examples in Context 9.7.1 Sales Transactions This example examines results for a trading company as presented in an RSquared Academy blogpost. The data in transact.csv36 represent the dates that an invoice was sent, payment of the invoice was due, and payment was received. As you can see from the data frame below, read_csv() accurately determined that each column contained dates and thus automatically read those columns in as of the date class. trans &lt;- read_csv(file.path(&quot;data&quot;,&quot;transact.csv&quot;)) trans #R&gt; # A tibble: 2,466 x 3 #R&gt; Invoice Due Payment #R&gt; &lt;date&gt; &lt;date&gt; &lt;date&gt; #R&gt; 1 2013-01-02 2013-02-01 2013-01-15 #R&gt; 2 2013-01-26 2013-02-25 2013-03-03 #R&gt; 3 2013-07-03 2013-08-02 2013-07-08 #R&gt; 4 2013-02-10 2013-03-12 2013-03-17 #R&gt; 5 2012-10-25 2012-11-24 2012-11-28 #R&gt; 6 2012-01-27 2012-02-26 2012-02-22 #R&gt; 7 2013-08-13 2013-09-12 2013-09-09 #R&gt; 8 2012-12-16 2013-01-15 2013-01-12 #R&gt; 9 2012-05-14 2012-06-13 2012-07-01 #R&gt; 10 2013-07-01 2013-07-31 2013-07-26 #R&gt; # ... with 2,456 more rows Part of the analysis will require summarizing results by years, quarters, and months. Thus, these variables were added to the data frame below. trans %&lt;&gt;% mutate(yr=year(Due), mon=month(Due,label=TRUE), qrtr=quarter(Due)) %&gt;% relocate(yr:qrtr) trans #R&gt; # A tibble: 2,466 x 6 #R&gt; yr mon qrtr Invoice Due Payment #R&gt; &lt;dbl&gt; &lt;ord&gt; &lt;int&gt; &lt;date&gt; &lt;date&gt; &lt;date&gt; #R&gt; 1 2013 Feb 1 2013-01-02 2013-02-01 2013-01-15 #R&gt; 2 2013 Feb 1 2013-01-26 2013-02-25 2013-03-03 #R&gt; 3 2013 Aug 3 2013-07-03 2013-08-02 2013-07-08 #R&gt; 4 2013 Mar 1 2013-02-10 2013-03-12 2013-03-17 #R&gt; 5 2012 Nov 4 2012-10-25 2012-11-24 2012-11-28 #R&gt; 6 2012 Feb 1 2012-01-27 2012-02-26 2012-02-22 #R&gt; 7 2013 Sep 3 2013-08-13 2013-09-12 2013-09-09 #R&gt; 8 2013 Jan 1 2012-12-16 2013-01-15 2013-01-12 #R&gt; 9 2012 Jun 2 2012-05-14 2012-06-13 2012-07-01 #R&gt; 10 2013 Jul 3 2013-07-01 2013-07-31 2013-07-26 #R&gt; # ... with 2,456 more rows Two questions that the team wanted to ask from these data were (1) what is the average days it took to make payment (from when the invoice was issued and (2) the average days past due for payments that were not paid on time. Answering the first question requires making an interval of the invoice to payment time and then determining how long that interval was. trans %&lt;&gt;% mutate(settle_days=time_length(Invoice %--% Payment,unit=&quot;days&quot;)) trans #R&gt; # A tibble: 2,466 x 7 #R&gt; yr mon qrtr Invoice Due Payment settle_days #R&gt; &lt;dbl&gt; &lt;ord&gt; &lt;int&gt; &lt;date&gt; &lt;date&gt; &lt;date&gt; &lt;dbl&gt; #R&gt; 1 2013 Feb 1 2013-01-02 2013-02-01 2013-01-15 13 #R&gt; 2 2013 Feb 1 2013-01-26 2013-02-25 2013-03-03 36 #R&gt; 3 2013 Aug 3 2013-07-03 2013-08-02 2013-07-08 5 #R&gt; 4 2013 Mar 1 2013-02-10 2013-03-12 2013-03-17 35 #R&gt; 5 2012 Nov 4 2012-10-25 2012-11-24 2012-11-28 34 #R&gt; 6 2012 Feb 1 2012-01-27 2012-02-26 2012-02-22 26 #R&gt; 7 2013 Sep 3 2013-08-13 2013-09-12 2013-09-09 27 #R&gt; 8 2013 Jan 1 2012-12-16 2013-01-15 2013-01-12 27 #R&gt; 9 2012 Jun 2 2012-05-14 2012-06-13 2012-07-01 48 #R&gt; 10 2013 Jul 3 2013-07-01 2013-07-31 2013-07-26 25 #R&gt; # ... with 2,456 more rows The results are summarized by quarter within each year below. trans %&gt;% group_by(yr,qrtr) %&gt;% summarize(mean=mean(settle_days), sd=sd(settle_days), min=min(settle_days), max=max(settle_days)) #R&gt; # A tibble: 9 x 6 #R&gt; # Groups: yr [3] #R&gt; yr qrtr mean sd min max #R&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 2012 1 29.6 12.4 3 64 #R&gt; 2 2012 2 28.6 12.2 1 63 #R&gt; 3 2012 3 27.7 12.5 1 67 #R&gt; 4 2012 4 27.3 11.4 2 75 #R&gt; 5 2013 1 25.8 12.1 1 64 #R&gt; 6 2013 2 26.3 13.2 0 64 #R&gt; 7 2013 3 24.8 12.0 0 59 #R&gt; 8 2013 4 22.7 11.8 1 57 #R&gt; 9 2014 1 23 10.3 11 36 Answering the second question requires finding the length of interval between the due and payment dates and then replacing all of the negative numbers with NA because they do not represent an overdue payment. trans %&lt;&gt;% mutate(overdue_days=time_length(Due %--% Payment,unit=&quot;days&quot;), overdue_days=ifelse(overdue_days&gt;0,overdue_days,NA_real_)) trans #R&gt; # A tibble: 2,466 x 8 #R&gt; yr mon qrtr Invoice Due Payment settle_days overdue_days #R&gt; &lt;dbl&gt; &lt;ord&gt; &lt;int&gt; &lt;date&gt; &lt;date&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 2013 Feb 1 2013-01-02 2013-02-01 2013-01-15 13 NA #R&gt; 2 2013 Feb 1 2013-01-26 2013-02-25 2013-03-03 36 6 #R&gt; 3 2013 Aug 3 2013-07-03 2013-08-02 2013-07-08 5 NA #R&gt; 4 2013 Mar 1 2013-02-10 2013-03-12 2013-03-17 35 5 #R&gt; 5 2012 Nov 4 2012-10-25 2012-11-24 2012-11-28 34 4 #R&gt; 6 2012 Feb 1 2012-01-27 2012-02-26 2012-02-22 26 NA #R&gt; 7 2013 Sep 3 2013-08-13 2013-09-12 2013-09-09 27 NA #R&gt; 8 2013 Jan 1 2012-12-16 2013-01-15 2013-01-12 27 NA #R&gt; 9 2012 Jun 2 2012-05-14 2012-06-13 2012-07-01 48 18 #R&gt; 10 2013 Jul 3 2013-07-01 2013-07-31 2013-07-26 25 NA #R&gt; # ... with 2,456 more rows The results are summarized by quarter within each year below. trans %&gt;% group_by(yr,qrtr) %&gt;% summarize(total_n=n(), overdue_n=sum(!is.na(overdue_days)), mean=mean(overdue_days,na.rm=TRUE), sd=sd(overdue_days,na.rm=TRUE), min=min(overdue_days,na.rm=TRUE), max=max(overdue_days,na.rm=TRUE)) #R&gt; # A tibble: 9 x 8 #R&gt; # Groups: yr [3] #R&gt; yr qrtr total_n overdue_n mean sd min max #R&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 2012 1 189 84 10.9 7.14 1 34 #R&gt; 2 2012 2 324 129 10.6 7.43 1 33 #R&gt; 3 2012 3 309 121 10.0 7.29 1 37 #R&gt; 4 2012 4 345 124 9.20 7.37 1 45 #R&gt; 5 2013 1 327 115 9.15 6.70 1 34 #R&gt; 6 2013 2 337 121 10.3 8.05 1 34 #R&gt; 7 2013 3 309 97 8.98 6.33 1 29 #R&gt; 8 2013 4 321 85 7.89 5.79 1 27 #R&gt; 9 2014 1 5 1 6 NA 6 6   9.7.2 Stream Discharge The U.S. Geological Survey (USGS) monitors stream/river discharge at a large number of stations around the United States. These data can be accessed via the National Water Information System: Web Interface. Here I will examine provisional data available for 2021 (up to 3-Aug, the day I accessed the data). The following steps were taken on the NWIS site to produce a tab-delimited file for use below. Selected Current Conditions button. Selected Wisconsin on the US map. Carefully selected the Whittlesey Creek dot on the Wisconsin map. Selected only 00060 Discharge from Available Parameters, Tab-separated from Output format, and enter 2021-01-01 into Begin Date. Pressed GO button. Copied URL from the ensuing page into read_tsv() below. [Note that the top of the file has many lines of comments each preceded by a #, which precipates the use of comment= below.] wcd &lt;- read_tsv(&quot;https://nwis.waterdata.usgs.gov/usa/nwis/uv/?cb_00045=on&amp;cb_00060=on&amp;format=rdb&amp;site_no=040263205&amp;period=&amp;begin_date=2021-01-01&amp;end_date=2021-08-03&quot;, comment=&quot;#&quot;) wcd #R&gt; # A tibble: 61,896 x 8 #R&gt; agency_cd site_no datetime tz_cd `157029_00060` `157029_00060_cd` #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #R&gt; 1 5s 15s 20d 6s 14n 10s #R&gt; 2 USGS 040263205 2021-01-01 00:00 CST 17.7 P #R&gt; 3 USGS 040263205 2021-01-01 00:05 CST 17.7 P #R&gt; 4 USGS 040263205 2021-01-01 00:10 CST 17.7 P #R&gt; 5 USGS 040263205 2021-01-01 00:15 CST 17.7 P #R&gt; 6 USGS 040263205 2021-01-01 00:20 CST 17.8 P #R&gt; 7 USGS 040263205 2021-01-01 00:25 CST 17.8 P #R&gt; 8 USGS 040263205 2021-01-01 00:30 CST 17.8 P #R&gt; 9 USGS 040263205 2021-01-01 00:35 CST 17.7 P #R&gt; 10 USGS 040263205 2021-01-01 00:40 CST 17.7 P #R&gt; # ... with 61,886 more rows, and 2 more variables: 157030_00045 &lt;chr&gt;, #R&gt; # 157030_00045_cd &lt;chr&gt; There are several issues with the way these data load into R. The first line of the data frame is not data at all; this row is removed with slice() below. All columns with cd in the name can be removed  they either note that the data is provisional or are all constants. Do note that the time zone is CST. Thes site_no column can be removed (it is a constant). The discharge data is in the column that ends with 00060 and the precipitation data is in the column that ends with 00045. These names should be changed to be more useful. The datetime variable needs to be converted from a character to datetime class. The discharge and precip variables need to be converted from a character to a numeric class (with as.numeric() below). wcd %&lt;&gt;% slice(-1) %&gt;% select(-ends_with(&quot;cd&quot;),-site_no) %&gt;% rename(discharge=ends_with(&quot;00060&quot;), precip=ends_with(&quot;00045&quot;)) %&gt;% mutate(datetime=ymd_hm(datetime), discharge=as.numeric(discharge), precip=as.numeric(precip)) wcd #R&gt; # A tibble: 61,895 x 3 #R&gt; datetime discharge precip #R&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 2021-01-01 00:00:00 17.7 NA #R&gt; 2 2021-01-01 00:05:00 17.7 NA #R&gt; 3 2021-01-01 00:10:00 17.7 NA #R&gt; 4 2021-01-01 00:15:00 17.7 NA #R&gt; 5 2021-01-01 00:20:00 17.8 NA #R&gt; 6 2021-01-01 00:25:00 17.8 NA #R&gt; 7 2021-01-01 00:30:00 17.8 NA #R&gt; 8 2021-01-01 00:35:00 17.7 NA #R&gt; 9 2021-01-01 00:40:00 17.7 NA #R&gt; 10 2021-01-01 00:45:00 17.8 NA #R&gt; # ... with 61,885 more rows The discharge data can then be plotted as follows (note the log scale).   Suppose that the researchers want to examine discharge for various periods of time (say weekly and monthly). The data frame then needs to include variables that identify weeks and months. wcd %&lt;&gt;% mutate(wk=week(datetime), mon=month(datetime,label=TRUE)) wcd #R&gt; # A tibble: 61,895 x 5 #R&gt; datetime discharge precip wk mon #R&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;ord&gt; #R&gt; 1 2021-01-01 00:00:00 17.7 NA 1 Jan #R&gt; 2 2021-01-01 00:05:00 17.7 NA 1 Jan #R&gt; 3 2021-01-01 00:10:00 17.7 NA 1 Jan #R&gt; 4 2021-01-01 00:15:00 17.7 NA 1 Jan #R&gt; 5 2021-01-01 00:20:00 17.8 NA 1 Jan #R&gt; 6 2021-01-01 00:25:00 17.8 NA 1 Jan #R&gt; 7 2021-01-01 00:30:00 17.8 NA 1 Jan #R&gt; 8 2021-01-01 00:35:00 17.7 NA 1 Jan #R&gt; 9 2021-01-01 00:40:00 17.7 NA 1 Jan #R&gt; 10 2021-01-01 00:45:00 17.8 NA 1 Jan #R&gt; # ... with 61,885 more rows For example, statistical summaries can then be computed by, for example, month. wcd_sum_mon &lt;- wcd %&gt;% group_by(mon) %&gt;% summarize(n=n(), mean=mean(discharge), sd=sd(discharge), min=min(discharge), max=max(discharge)) wcd_sum_mon #R&gt; # A tibble: 8 x 6 #R&gt; mon n mean sd min max #R&gt; &lt;ord&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 Jan 8928 17.6 0.272 16.9 18.9 #R&gt; 2 Feb 8064 17.0 0.223 16.3 17.7 #R&gt; 3 Mar 8916 33.4 31.8 16.5 257 #R&gt; 4 Apr 8640 28.3 19.1 18.3 196 #R&gt; 5 May 8915 20.3 5.16 17.4 85.5 #R&gt; 6 Jun 8640 NA NA NA NA #R&gt; 7 Jul 8928 17.7 0.745 16.6 27.7 #R&gt; 8 Aug 864 17.9 0.257 17.2 18.4 From this it is clear that discharge was relatively constant (low SD values) with an average between 17 and 18 cfs in January, February, June, July, and August, but more variable and with greater mean discharge in March, April, and, to a lesser degree, May. For fun, it is often interesting to look at the discharge plot around a flashy event. The code below finds the datetime for the maximum discharge. wcd$datetime[which.max(wcd$discharge)] #R&gt; [1] &quot;2021-03-10 23:00:00 UTC&quot; A new data frame that is around this point of maximum discharge is then created with filter(). wcd1 &lt;- wcd %&gt;% filter(datetime&gt;=ymd_hms(&quot;2021-03-09 12:00:00&quot;), datetime&lt;=ymd_hms(&quot;2021-03-12 6:00:00&quot;)) wcd1 #R&gt; # A tibble: 793 x 5 #R&gt; datetime discharge precip wk mon #R&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;ord&gt; #R&gt; 1 2021-03-09 12:00:00 19 NA 10 Mar #R&gt; 2 2021-03-09 12:05:00 19 NA 10 Mar #R&gt; 3 2021-03-09 12:10:00 19 NA 10 Mar #R&gt; 4 2021-03-09 12:15:00 19 NA 10 Mar #R&gt; 5 2021-03-09 12:20:00 19 NA 10 Mar #R&gt; 6 2021-03-09 12:25:00 19 NA 10 Mar #R&gt; 7 2021-03-09 12:30:00 19.1 NA 10 Mar #R&gt; 8 2021-03-09 12:35:00 19.1 NA 10 Mar #R&gt; 9 2021-03-09 12:40:00 19.1 NA 10 Mar #R&gt; 10 2021-03-09 12:45:00 19.2 NA 10 Mar #R&gt; # ... with 783 more rows Which can then be plotted. Everything done in this module can also be accomplished with functions in base R. However, the functions of lubridate and their arguments are generally more consistent. For example, yday() returns a 1 for January 1st. By default the week day starts on Sunday. A week is defined here as a full seven day period and is inclusive of the current seven day period. Thus, the week for 1-Jan will always be 1 and 8-Jan will always be 2. As long as time_length() is given an interval class type. Note the use of now() with date-times, whereas as today() is used just for dates. Original data from rsquaredacadamy. "],["factors.html", "Module 10 Factors 10.1 Creating Factors 10.2 Changing Factor Order 10.3 Changing Factor Levels 10.4 Examples in Context", " Module 10 Factors Factors are a special case of character variables in R. Factors are primarily used for categorical data, especially if summaries of that data are to be displayed in other than alphabetical order. For example, a simple count of the number of observations in each loc of the bears data frame introduced in Section 3.3.1 shows that the categories of the character variable are displayed alphabetically by default. bears &lt;- read_csv(file.path(&quot;data&quot;,&quot;Bears.csv&quot;)) tmp &lt;- bears %&gt;% group_by(loc) %&gt;% summarize(n=n()) tmp #R&gt; # A tibble: 3 x 2 #R&gt; loc n #R&gt; &lt;chr&gt; &lt;int&gt; #R&gt; 1 Ashland 2 #R&gt; 2 Bayfield 3 #R&gt; 3 Douglas 3 To display these results in other than alphabetical order will require the use of factors, which will be illustrated in this module. Factors have a long and, for some, dubious history in R. The forcats package was developed to aid working with factors in R. While it is not critical to understanding the methods of this module, the stringsAsFactors: An unauthorized biography and stringsAsFactors = &lt;sigh&gt; are interesting reads about how unforeseen issues can arise when using factors. Many of these issues are addressed when using forcats, which is loaded with tidyverse.   10.1 Creating Factors A variable is converted to a factor class by including that variable in factor(). The code below creates a new data frame where loc is now a factor, as indicated by &lt;fct&gt; below loc when the tibble is printed. tmp &lt;- bears %&gt;% mutate(loc=factor(loc)) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas Nothing is changed when the data are displayed as above. However, behind-the-scenes the factor variable consists of numerical codes that are mapped to levels (i.e., the categories) of the factor variable. The order here is still alphabetical because the order of the levels was not specifically controlled when creating the factor variable. Thus, behind-the-scenes 1 is mapped to Ashland, 2 to Bayfield, and 3 to Douglas. This mapping is shown below. tmp %&gt;% mutate(loc_nums=as.numeric(loc)) #R&gt; # A tibble: 8 x 4 #R&gt; length.cm weight.kg loc loc_nums #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; #R&gt; 1 139 110 Bayfield 2 #R&gt; 2 120. 60 Bayfield 2 #R&gt; 3 149 85 Bayfield 2 #R&gt; 4 141 100 Ashland 1 #R&gt; 5 141 95 Ashland 1 #R&gt; 6 150 85 Douglas 3 #R&gt; 7 130. 105 Douglas 3 #R&gt; 8 150 110 Douglas 3 Suppose, however, that we prefer that the levels of the loc variable be ordered from West to East, as in Douglas than Bayfield and then Ashland. The specific order of the levels can be set by supplying the ordered levels in a vector given to levels= within factor(). tmp &lt;- bears %&gt;% mutate(loc=factor(loc,levels=c(&quot;Douglas&quot;,&quot;Bayfield&quot;,&quot;Ashland&quot;))) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #R&gt; 1 139 110 Bayfield #R&gt; 2 120. 60 Bayfield #R&gt; 3 149 85 Bayfield #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas Again, the data are not fundamentally altered, but the codes underlying the factor variables are.37 tmp %&gt;% mutate(loc_nums=as.numeric(loc)) #R&gt; # A tibble: 8 x 4 #R&gt; length.cm weight.kg loc loc_nums #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; #R&gt; 1 139 110 Bayfield 2 #R&gt; 2 120. 60 Bayfield 2 #R&gt; 3 149 85 Bayfield 2 #R&gt; 4 141 100 Ashland 3 #R&gt; 5 141 95 Ashland 3 #R&gt; 6 150 85 Douglas 1 #R&gt; 7 130. 105 Douglas 1 #R&gt; 8 150 110 Douglas 1 When setting the levels of a factor variable make sure that all levels are spelled exactly as they are in the original variable. For example, see the major problem created below when a level is erroneously set (i.e., bayfield is not capitalized). tmp &lt;- bears %&gt;% mutate(loc=factor(loc,levels=c(&quot;Douglas&quot;,&quot;bayfield&quot;,&quot;Ashland&quot;))) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #R&gt; 1 139 110 &lt;NA&gt; #R&gt; 2 120. 60 &lt;NA&gt; #R&gt; 3 149 85 &lt;NA&gt; #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas Additionally, make sure that you include all possible levels when creating the levels. tmp &lt;- bears %&gt;% mutate(loc=factor(loc,levels=c(&quot;Douglas&quot;,&quot;Ashland&quot;))) tmp #R&gt; # A tibble: 8 x 3 #R&gt; length.cm weight.kg loc #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #R&gt; 1 139 110 &lt;NA&gt; #R&gt; 2 120. 60 &lt;NA&gt; #R&gt; 3 149 85 &lt;NA&gt; #R&gt; 4 141 100 Ashland #R&gt; 5 141 95 Ashland #R&gt; 6 150 85 Douglas #R&gt; 7 130. 105 Douglas #R&gt; 8 150 110 Douglas Given these last two issues it is important to understand what levels exist within a variable. If the variable is a character class (and not yet a factor) then use unique() to see the list of levels. unique(bears$loc) #R&gt; [1] &quot;Bayfield&quot; &quot;Ashland&quot; &quot;Douglas&quot; However, if the variable is a factor class already then use levels() to see the list of levels along with their order. levels(tmp$loc) #R&gt; [1] &quot;Douglas&quot; &quot;Ashland&quot;   10.2 Changing Factor Order Factor levels can be manually reordered using levels= as shown in the previous section. However functions in forcats provide other methods to simplify reordering levels for common situations. Levels can be reordered based on the value of another variable with fct_reorder(). This function takes the factor variable as the first argument and a numeric variable that contains values for which to reorder the factor levels as the second argument. Optionally a third argument called .fun can be used to calculate a summary of the numeric variable to use for reordering.38 For example, the code below orders the levels in loc by the median length of the bears. tmp &lt;- bears %&gt;% mutate(loc=fct_reorder(loc,length.cm)) levels(tmp$loc) #R&gt; [1] &quot;Bayfield&quot; &quot;Ashland&quot; &quot;Douglas&quot; tmp %&gt;% group_by(loc) %&gt;% summarize(n=n(), mdn=median(length.cm)) #R&gt; # A tibble: 3 x 3 #R&gt; loc n mdn #R&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; #R&gt; 1 Bayfield 3 139 #R&gt; 2 Ashland 2 141 #R&gt; 3 Douglas 3 150 Alternatively, the code below orders the levels of loc by the minimum length of the bears. tmp &lt;- bears %&gt;% mutate(loc=fct_reorder(loc,length.cm,.fun=min)) levels(tmp$loc) #R&gt; [1] &quot;Bayfield&quot; &quot;Douglas&quot; &quot;Ashland&quot; tmp %&gt;% group_by(loc) %&gt;% summarize(n=n(), min=min(length.cm)) #R&gt; # A tibble: 3 x 3 #R&gt; loc n min #R&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; #R&gt; 1 Bayfield 3 120. #R&gt; 2 Douglas 3 130. #R&gt; 3 Ashland 2 141   Specific levels are moved to the beginning of the order of levels with fct_relevel(). The first argument to this function is the factor variable and subsequent arguments are levels to move to the beginning of the line. For example, the following code moves Bayfield to the beginning of the order. tmp &lt;- bears %&gt;% mutate(loc=fct_relevel(loc,&quot;Bayfield&quot;)) levels(tmp$loc) #R&gt; [1] &quot;Bayfield&quot; &quot;Ashland&quot; &quot;Douglas&quot; Alternatively, both Bayfield and Douglas are moved to the beginning below tmp &lt;- bears %&gt;% mutate(loc=fct_relevel(loc,&quot;Bayfield&quot;,&quot;Douglas&quot;)) levels(tmp$loc) #R&gt; [1] &quot;Bayfield&quot; &quot;Douglas&quot; &quot;Ashland&quot;   The order of levels for a factor variable are reversed with fct_rev(). tmp &lt;- bears %&gt;% mutate(loc=fct_rev(loc)) levels(tmp$loc) #R&gt; [1] &quot;Douglas&quot; &quot;Bayfield&quot; &quot;Ashland&quot; The fct_rev() function can be used with fct_reorder() to change the order from ascending to descending order. For example, the code below show the factor levels in descending order of the minimum length. tmp &lt;- bears %&gt;% mutate(loc=fct_reorder(loc,length.cm,.fun=min), loc=fct_rev(loc)) tmp %&gt;% group_by(loc) %&gt;% summarize(n=n(), min=min(length.cm)) #R&gt; # A tibble: 3 x 3 #R&gt; loc n min #R&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; #R&gt; 1 Ashland 2 141 #R&gt; 2 Douglas 3 130. #R&gt; 3 Bayfield 3 120.   The fct_infreq() function is used to order the levels by decreasing frequency of their occurrence. tmp &lt;- bears %&gt;% mutate(loc=fct_infreq(loc)) tmp %&gt;% group_by(loc) %&gt;% summarize(n=n()) #R&gt; # A tibble: 3 x 2 #R&gt; loc n #R&gt; &lt;fct&gt; &lt;int&gt; #R&gt; 1 Bayfield 3 #R&gt; 2 Douglas 3 #R&gt; 3 Ashland 2 Of course, using fct_rev() with fct_infreq() would order the levels in ascending frequency of occurrence. tmp &lt;- bears %&gt;% mutate(loc=fct_rev(fct_infreq(loc))) tmp %&gt;% group_by(loc) %&gt;% summarize(n=n()) #R&gt; # A tibble: 3 x 2 #R&gt; loc n #R&gt; &lt;fct&gt; &lt;int&gt; #R&gt; 1 Ashland 2 #R&gt; 2 Douglas 3 #R&gt; 3 Bayfield 3 10.3 Changing Factor Levels In some instances it may be beneficial to change the names of the levels or to collapse or lump levels together. Methods for performing these changes are demonstrated in this section using data on the density and basal area of tree species located on plots in the Apostle Islands that were designated as Balsam Fir plots. These data were extracted from Sanders and Grochowski (2012)39 and are stored in APIS_FirPlots.xlsx. aip &lt;- readxl::read_excel(file.path(&quot;data&quot;,&quot;APIS_FirPlots.xlsx&quot;)) aip #R&gt; # A tibble: 26 x 4 #R&gt; plot species density basal_area #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 1011 Acer rubrum 11.1 0.4 #R&gt; 2 1011 Betula alleghaniensis 156. 1.7 #R&gt; 3 1011 Betula papyrifera 44.4 0.7 #R&gt; 4 1011 Sorbus decora 22.2 0.2 #R&gt; 5 1011 unknown tree - hardwood 11.1 0.6 #R&gt; 6 1011 Abies balsamea 878. 2.5 #R&gt; 7 1011 unknown tree - softwood 122. 1.2 #R&gt; 8 1031 Acer saccharum 55.6 0.1 #R&gt; 9 1031 Acer sp. 44.4 0.3 #R&gt; 10 1031 Betula papyrifera 33.3 1.5 #R&gt; # ... with 16 more rows These data are read in and briefly summarized below. aip_sum1 &lt;- aip %&gt;% group_by(species) %&gt;% summarize(n=n(), ttl_density=sum(density), ttl_barea=sum(basal_area)) aip_sum1 #R&gt; # A tibble: 14 x 4 #R&gt; species n ttl_density ttl_barea #R&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 Abies balsamea 4 1000 2.8 #R&gt; 2 Acer rubrum 1 11.1 0.4 #R&gt; 3 Acer saccharum 3 77.8 0.2 #R&gt; 4 Acer sp. 1 44.4 0.3 #R&gt; 5 Acer spicatum 1 11.1 0 #R&gt; 6 Betula alleghaniensis 3 178. 2.3 #R&gt; 7 Betula papyrifera 2 77.7 2.2 #R&gt; 8 Betula sp. 1 11.1 0.3 #R&gt; 9 Populus tremuloides 1 22.2 1.5 #R&gt; 10 Quercus rubra 1 11.1 0 #R&gt; 11 Sorbus decora 1 22.2 0.2 #R&gt; 12 Thuja occidentalis 1 11.1 0.7 #R&gt; 13 unknown tree - hardwood 4 111 4.3 #R&gt; 14 unknown tree - softwood 2 144. 1.2 The summary above shows several species within a few genera. A research may wish to collapse these species into a one level that represents the genera. For example, one may want to collapse Acer rubrum, Acer saccharum, Acer spicatum, and Acer sp. into a single level of Acer sp. The collapsing of multiple levels into one level is accomplished with fct_collapse(). The first argument to this function is the factor variable containing the old levels. Subsequent arguments are formed by setting a new level name equal to a vector containing old level names to collapse. For example the code below uses fct_collapse() to create a new species2 variable that collapses the multiple Acer and Betula levels into two levels specific to each genera. The levels of species2 are then ordered in descending order of the sum of density (using fct_reorder() and fct_rev()).40 aip %&lt;&gt;% mutate(species2=fct_collapse(species, &quot;Acer sp.&quot;=c(&quot;Acer rubrum&quot;,&quot;Acer saccharum&quot;, &quot;Acer sp.&quot;,&quot;Acer spicatum&quot;), &quot;Betula sp.&quot;=c(&quot;Betula alleghaniensis&quot;, &quot;Betula papyrifera&quot;, &quot;Betula sp.&quot;), &quot;Unknown&quot;=c(&quot;unknown tree - hardwood&quot;, &quot;unknown tree - softwood&quot;)), species2=fct_rev(fct_reorder(species2,density,.fun=sum))) aip #R&gt; # A tibble: 26 x 5 #R&gt; plot species density basal_area species2 #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; #R&gt; 1 1011 Acer rubrum 11.1 0.4 Acer sp. #R&gt; 2 1011 Betula alleghaniensis 156. 1.7 Betula sp. #R&gt; 3 1011 Betula papyrifera 44.4 0.7 Betula sp. #R&gt; 4 1011 Sorbus decora 22.2 0.2 Sorbus decora #R&gt; 5 1011 unknown tree - hardwood 11.1 0.6 Unknown #R&gt; 6 1011 Abies balsamea 878. 2.5 Abies balsamea #R&gt; 7 1011 unknown tree - softwood 122. 1.2 Unknown #R&gt; 8 1031 Acer saccharum 55.6 0.1 Acer sp. #R&gt; 9 1031 Acer sp. 44.4 0.3 Acer sp. #R&gt; 10 1031 Betula papyrifera 33.3 1.5 Betula sp. #R&gt; # ... with 16 more rows Total density and total basal area by level of species2, where the levels of species2 are ordered in descending order of the total density is shown below. aip_sum2 &lt;- aip %&gt;% group_by(species2) %&gt;% summarize(n=n(), ttl_density=sum(density), ttl_barea=sum(basal_area)) aip_sum2 #R&gt; # A tibble: 8 x 4 #R&gt; species2 n ttl_density ttl_barea #R&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 Abies balsamea 4 1000 2.8 #R&gt; 2 Betula sp. 6 267. 4.8 #R&gt; 3 Unknown 6 255. 5.5 #R&gt; 4 Acer sp. 6 144. 0.9 #R&gt; 5 Sorbus decora 1 22.2 0.2 #R&gt; 6 Populus tremuloides 1 22.2 1.5 #R&gt; 7 Thuja occidentalis 1 11.1 0.7 #R&gt; 8 Quercus rubra 1 11.1 0 The result above indicate that four of the species dominated the results. It may be useful (especially if graphing these results) to lump the four infrequent species into an Other category. This type of lumping can be accomplished with fct_lump_n() which requires the factor variable as its first argument andn= to indicate the top n levels to not lump into an Other category. For example, the code below will lump all levels in species2 after the top four into an Other category of the new species3 variable. The summary results illustrate the lumping. aip &lt;- aip %&gt;% mutate(species3=fct_lump_n(species2,n=4)) aip_sum3 &lt;- aip %&gt;% group_by(species3) %&gt;% summarize(n=n(), ttl_density=sum(density), ttl_barea=sum(basal_area)) aip_sum3 #R&gt; # A tibble: 5 x 4 #R&gt; species3 n ttl_density ttl_barea #R&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 Abies balsamea 4 1000 2.8 #R&gt; 2 Betula sp. 6 267. 4.8 #R&gt; 3 Unknown 6 255. 5.5 #R&gt; 4 Acer sp. 6 144. 0.9 #R&gt; 5 Other 4 66.6 2.4 Other versions of fct_lump_XXX(), such as fct_lump_prop() and fct_lump_min(), can be used when ordering by frequency rather than be another variable as shown here. Finally, the names of specific levels can be changed with fct_recode(). The first argument to this function is the original factor variable. Subsequent arguments are of the form new level name equal to old level name. Any levels not listed in fct_recode() will be retained with their original names. For example, the code below creates a new species4 variable with new common names for the three species levels remaining in species3. The results are seen in the summary below. aip %&lt;&gt;% mutate(species4=fct_recode(species3, &quot;Maple&quot; = &quot;Acer sp.&quot;, &quot;Birch&quot; = &quot;Betula sp.&quot;, &quot;Balsam Fir&quot; = &quot;Abies balsamea&quot;)) aip_sum4 &lt;- aip %&gt;% group_by(species4) %&gt;% summarize(n=n(), ttl_density=sum(density), ttl_barea=sum(basal_area)) aip_sum4 #R&gt; # A tibble: 5 x 4 #R&gt; species4 n ttl_density ttl_barea #R&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 Balsam Fir 4 1000 2.8 #R&gt; 2 Birch 6 267. 4.8 #R&gt; 3 Unknown 6 255. 5.5 #R&gt; 4 Maple 6 144. 0.9 #R&gt; 5 Other 4 66.6 2.4 10.4 Examples in Context 10.4.1 Pulse of the Nation Survey Cards Against Humanity Saves America created monthly polls to assess what they called the Pulse of the Nation. Cards partnered with Survey Sampling International  a professional research firm  to contact a nationally representative sample of the American public. For the first three polls, they interrupted peoples dinners on both their cell phones and landlines, and a total of about 3000 adults did not hang up immediately. Results from the first poll are in 201709-CAH_PulseOfTheNation.csv41, which are read in below. PON &lt;- read_csv(file.path(&quot;data&quot;,&quot;201709-CAH_PulseOfTheNation.csv&quot;)) PON #R&gt; # A tibble: 1,000 x 28 #R&gt; Income Gender Age `Age Range` `Political Affiliation` `Do you approve or d~ #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #R&gt; 1 8000 Female 64 55-64 Democrat Strongly disapprove #R&gt; 2 68000 Female 56 55-64 Democrat Strongly disapprove #R&gt; 3 46000 Male 63 55-64 Independent Somewhat Approve #R&gt; 4 51000 Male 48 45-54 Republican Strongly Approve #R&gt; 5 100000 Female 32 25-34 Democrat Somewhat Approve #R&gt; 6 54000 Female 64 55-64 Democrat Strongly disapprove #R&gt; 7 83000 Male 61 55-64 Independent Somewhat Approve #R&gt; 8 114000 Female 64 55-64 Republican Somewhat disapprove #R&gt; 9 90000 Female 64 55-64 Republican Somewhat Approve #R&gt; 10 5000 Female 68 65+ Democrat Somewhat disapprove #R&gt; # ... with 990 more rows, and 22 more variables: #R&gt; # What is your highest level of education? &lt;chr&gt;, Q5OTH1 &lt;chr&gt;, #R&gt; # What is your race? &lt;chr&gt;, Q6OTH1 &lt;chr&gt;, What is your marital status? &lt;chr&gt;, #R&gt; # Q7OTH1 &lt;chr&gt;, q8x &lt;chr&gt;, #R&gt; # What would you say is the likelihood that your current job will be entirely performed by robots or computers within the next decade? &lt;chr&gt;, #R&gt; # Do you believe that climate change is real and caused by people, real but not caused by people, or not real at all? &lt;chr&gt;, #R&gt; # How many Transformers movies have you seen? &lt;dbl&gt;, q11x &lt;chr&gt;, ... The variables in the data frame are generally the actual questions asked in the survey. These are both difficult to read and to work with. To get a better look at these variables I used names(), which when given a data frame returns all the variable names of that data frame. names(PON) #R&gt; [1] &quot;Income&quot; #R&gt; [2] &quot;Gender&quot; #R&gt; [3] &quot;Age&quot; #R&gt; [4] &quot;Age Range&quot; #R&gt; [5] &quot;Political Affiliation&quot; #R&gt; [6] &quot;Do you approve or disapprove of how Donald Trump is handling his job as president?&quot; #R&gt; [7] &quot;What is your highest level of education?&quot; #R&gt; [8] &quot;Q5OTH1&quot; #R&gt; [9] &quot;What is your race?&quot; #R&gt; [10] &quot;Q6OTH1&quot; #R&gt; [11] &quot;What is your marital status?&quot; #R&gt; [12] &quot;Q7OTH1&quot; #R&gt; [13] &quot;q8x&quot; #R&gt; [14] &quot;What would you say is the likelihood that your current job will be entirely performed by robots or computers within the next decade?&quot; #R&gt; [15] &quot;Do you believe that climate change is real and caused by people, real but not caused by people, or not real at all?&quot; #R&gt; [16] &quot;How many Transformers movies have you seen?&quot; #R&gt; [17] &quot;q11x&quot; #R&gt; [18] &quot;Do you agree or disagree with the following statement: scientists are generally honest and are serving the public good.&quot; #R&gt; [19] &quot;Do you agree or disagree with the following statement: vaccines are safe and protect children from disease.&quot; #R&gt; [20] &quot;How many books, if any, have you read in the past year?&quot; #R&gt; [21] &quot;q14x&quot; #R&gt; [22] &quot;Do you believe in ghosts?&quot; #R&gt; [23] &quot;What percentage of the federal budget would you estimate is spent on scientific research?&quot; #R&gt; [24] &quot;q16x&quot; #R&gt; [25] &quot;Is federal funding of scientific research too high, too low, or about right?&quot; #R&gt; [26] &quot;True or false: the earth is always farther away from the sun in the winter than in the summer.&quot; #R&gt; [27] &quot;If you had to choose: would you rather be smart and sad, or dumb and happy?&quot; #R&gt; [28] &quot;Do you think it is acceptable or unacceptable to urinate in the shower?&quot; For this analysis I want to focus on the Political Affiliation, Age Range, and the three variable related to education, opinion about climate change, and opinion about the honesty of scientists. These last three variables have very long names so it will be easier to refer to them by their column number. From above, it is noted that the education variable is column 7, the climate change variable is in column 15, and the scientists honesty question is in column 18. In the code below, I rename each of the columns (and Age Range) and then reduce the data frame to just those variables. PON %&lt;&gt;% rename(polit_aff=`Political Affiliation`,age_range=`Age Range`, education=7,climate=15,scihon=18) %&gt;% select(polit_aff,age_range,education,climate,scihon) PON #R&gt; # A tibble: 1,000 x 5 #R&gt; polit_aff age_range education climate scihon #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #R&gt; 1 Democrat 55-64 College degree Real and Caused by People Strongly ~ #R&gt; 2 Democrat 55-64 High school DK/REF Somewhat ~ #R&gt; 3 Independent 55-64 Some college Real but not Caused by People Somewhat ~ #R&gt; 4 Republican 45-54 High school Not Real At All Somewhat ~ #R&gt; 5 Democrat 25-34 Some college Real and Caused by People Strongly ~ #R&gt; 6 Democrat 55-64 Some college Real and Caused by People Strongly ~ #R&gt; 7 Independent 55-64 College degree Real but not Caused by People Strongly ~ #R&gt; 8 Republican 55-64 College degree Real and Caused by People Somewhat ~ #R&gt; 9 Republican 55-64 High school Real and Caused by People Somewhat ~ #R&gt; 10 Democrat 65+ Some college Real and Caused by People Somewhat ~ #R&gt; # ... with 990 more rows All remaining variables are categorical and for my analysis purposes I want each to be a factor. Before converting these variables to factors I will examine the levels that appear in each. unique(PON$polit_aff) #R&gt; [1] &quot;Democrat&quot; &quot;Independent&quot; &quot;Republican&quot; &quot;DK/REF&quot; unique(PON$age_range) #R&gt; [1] &quot;55-64&quot; &quot;45-54&quot; &quot;25-34&quot; &quot;65+&quot; &quot;35-44&quot; &quot;18-24&quot; unique(PON$education) #R&gt; [1] &quot;College degree&quot; &quot;High school&quot; &quot;Some college&quot; &quot;Graduate degree&quot; #R&gt; [5] &quot;DK/REF&quot; &quot;Other&quot; unique(PON$climate) #R&gt; [1] &quot;Real and Caused by People&quot; &quot;DK/REF&quot; #R&gt; [3] &quot;Real but not Caused by People&quot; &quot;Not Real At All&quot; unique(PON$scihon) #R&gt; [1] &quot;Strongly Agree&quot; &quot;Somewhat Agree&quot; #R&gt; [3] &quot;Somewhat Disagree&quot; &quot;Strongly Disagree&quot; #R&gt; [5] &quot;DK/REF&quot; &quot;Neither Agree nor Disagree&quot; From this examination of levels, I made the following notes: Respondents were allowed to answer Dont Know or refuse to answer which were coded as DK/REF. My general preference is to have DK/REF answers be the last level. The levels for age_range will not need to be controlled because the numbers will naturally alphabetically order (as the numbers are all two digits; the order might not be natural if there were some one digit (say 1-17) or three digit (say 100+) numbers). Levels in education and scihon need to be ordered according to their natural order (i.e., increasing education and increasing level of agreement). I will order the levels for climate based on my understanding of what the correct answer is (i.e., I will order the answers from correct to less correct). I will order the levels of polit_aff so that Independent is in the middle (which will happen alphabetically) and DK/REF is last. Creation of these factors is below. Note that to move DK/REF to the end of polit_aff I used fct_relevel() with after=Inf to move the level to the last position. PON %&lt;&gt;% mutate(polit_aff=factor(polit_aff), polit_aff=fct_relevel(polit_aff,&quot;DK/REF&quot;,after=Inf), age_range=factor(age_range), education=factor(education,levels=c(&quot;High school&quot;,&quot;Some college&quot;, &quot;College degree&quot;,&quot;Graduate degree&quot;, &quot;Other&quot;,&quot;DK/REF&quot;)), climate=factor(climate,levels=c(&quot;Real and Caused by People&quot;, &quot;Real but not Caused by People&quot;, &quot;Not Real At All&quot;, &quot;DK/REF&quot;)), scihon=factor(scihon,levels=c(&quot;Strongly Disagree&quot;,&quot;Somewhat Disagree&quot;, &quot;Neither Agree nor Disagree&quot;, &quot;Somewhat Agree&quot;,&quot;Strongly Agree&quot;, &quot;DK/REF&quot;))) I then used levels() to double-check that each factor has the levels and the order of levels that I expected. levels(PON$polit_aff) #R&gt; [1] &quot;Democrat&quot; &quot;Independent&quot; &quot;Republican&quot; &quot;DK/REF&quot; levels(PON$age_range) #R&gt; [1] &quot;18-24&quot; &quot;25-34&quot; &quot;35-44&quot; &quot;45-54&quot; &quot;55-64&quot; &quot;65+&quot; levels(PON$education) #R&gt; [1] &quot;High school&quot; &quot;Some college&quot; &quot;College degree&quot; &quot;Graduate degree&quot; #R&gt; [5] &quot;Other&quot; &quot;DK/REF&quot; levels(PON$climate) #R&gt; [1] &quot;Real and Caused by People&quot; &quot;Real but not Caused by People&quot; #R&gt; [3] &quot;Not Real At All&quot; &quot;DK/REF&quot; levels(PON$scihon) #R&gt; [1] &quot;Strongly Disagree&quot; &quot;Somewhat Disagree&quot; #R&gt; [3] &quot;Neither Agree nor Disagree&quot; &quot;Somewhat Agree&quot; #R&gt; [5] &quot;Strongly Agree&quot; &quot;DK/REF&quot; Suppose the first analysis of interest is examining responses to the scientists are generally honest and are serving the public good question. sci_sum1 &lt;- PON %&gt;% group_by(scihon) %&gt;% summarize(freq=n()) sci_sum1 #R&gt; # A tibble: 6 x 2 #R&gt; scihon freq #R&gt; &lt;fct&gt; &lt;int&gt; #R&gt; 1 Strongly Disagree 104 #R&gt; 2 Somewhat Disagree 133 #R&gt; 3 Neither Agree nor Disagree 19 #R&gt; 4 Somewhat Agree 335 #R&gt; 5 Strongly Agree 349 #R&gt; 6 DK/REF 60 Suppose that the analysts want to simplify this result for their audience by ignoring the Dont know or refused to answer responses and collapsing all disagree answers to one level and all agree answers to one level. tmp &lt;- PON %&gt;% filter(scihon!=&quot;DK/REF&quot;) %&gt;% mutate(scihon=fct_collapse(scihon, &quot;Disagree&quot;=c(&quot;Strongly Disagree&quot;,&quot;Somewhat Disagree&quot;), &quot;Agree&quot;=c(&quot;Strongly Agree&quot;,&quot;Somewhat Agree&quot;))) sci_sum2 &lt;- tmp %&gt;% group_by(scihon) %&gt;% summarize(freq=n()) sci_sum2 #R&gt; # A tibble: 3 x 2 #R&gt; scihon freq #R&gt; &lt;fct&gt; &lt;int&gt; #R&gt; 1 Disagree 237 #R&gt; 2 Neither Agree nor Disagree 19 #R&gt; 3 Agree 684 For fun, a graph of this summary is below. Further suppose that the analysts want to summarize the question about climate change separately by political affiliation (for which an answer was provided). polclim_sum1 &lt;- PON %&gt;% filter(polit_aff != &quot;DK/REF&quot;) %&gt;% group_by(polit_aff,climate) %&gt;% summarize(freq=n()) %&gt;% mutate(perc=freq/sum(freq)*100) polclim_sum1 #R&gt; # A tibble: 12 x 4 #R&gt; # Groups: polit_aff [3] #R&gt; polit_aff climate freq perc #R&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; #R&gt; 1 Democrat Real and Caused by People 221 80.7 #R&gt; 2 Democrat Real but not Caused by People 28 10.2 #R&gt; 3 Democrat Not Real At All 15 5.47 #R&gt; 4 Democrat DK/REF 10 3.65 #R&gt; 5 Independent Real and Caused by People 234 63.6 #R&gt; 6 Independent Real but not Caused by People 69 18.8 #R&gt; 7 Independent Not Real At All 49 13.3 #R&gt; 8 Independent DK/REF 16 4.35 #R&gt; 9 Republican Real and Caused by People 71 34.1 #R&gt; 10 Republican Real but not Caused by People 61 29.3 #R&gt; 11 Republican Not Real At All 61 29.3 #R&gt; 12 Republican DK/REF 15 7.21 Suppose that the researchers want to compute a percentage of respondents that thought climate change was real, whether they had the cause correct or not. Further suppose that they wish to include the DK/REF answers with the Not Real At All answers under the assumption that if they though climate change was real they would have responded as such. tmp &lt;- PON %&gt;% filter(polit_aff != &quot;DK/REF&quot;) %&gt;% mutate(climate=fct_collapse(climate, &quot;Real&quot;=c(&quot;Real and Caused by People&quot;, &quot;Real but not Caused by People&quot;), &quot;Not Real&quot;=c(&quot;Not Real At All&quot;, &quot;DK/REF&quot;))) polclim_sum2 &lt;- tmp %&gt;% group_by(polit_aff,climate) %&gt;% summarize(freq=n()) %&gt;% mutate(perc=freq/sum(freq)*100) %&gt;% ungroup() polclim_sum2 #R&gt; # A tibble: 6 x 4 #R&gt; polit_aff climate freq perc #R&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; #R&gt; 1 Democrat Real 249 90.9 #R&gt; 2 Democrat Not Real 25 9.12 #R&gt; 3 Independent Real 303 82.3 #R&gt; 4 Independent Not Real 65 17.7 #R&gt; 5 Republican Real 132 63.5 #R&gt; 6 Republican Not Real 76 36.5 And a graphic of the results for fun.   10.4.2 Enterococci on Sydney Beaches The Beachwatch Water Quality Program of Sydney, Australia measured the density (in colony forming units per 100 ml of water) of Enterococci on Sydney beaches. The data from 2013 to 2018 was made available by the R-Ladies Sydney group and is in sydneybeaches.csv.42 The data are loaded below. sb &lt;- read_csv(&quot;https://raw.githubusercontent.com/rladiessydney/RYouWithMe/master/sydneybeaches.csv&quot;) sb #R&gt; # A tibble: 3,690 x 8 #R&gt; BeachId Region Council Site Longitude Latitude Date `Enterococci (cf~ #R&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 25 Sydney C~ Randwick~ Clove~ 151. -33.9 02/0~ 19 #R&gt; 2 25 Sydney C~ Randwick~ Clove~ 151. -33.9 06/0~ 3 #R&gt; 3 25 Sydney C~ Randwick~ Clove~ 151. -33.9 12/0~ 2 #R&gt; 4 25 Sydney C~ Randwick~ Clove~ 151. -33.9 18/0~ 13 #R&gt; 5 25 Sydney C~ Randwick~ Clove~ 151. -33.9 30/0~ 8 #R&gt; 6 25 Sydney C~ Randwick~ Clove~ 151. -33.9 05/0~ 7 #R&gt; 7 25 Sydney C~ Randwick~ Clove~ 151. -33.9 11/0~ 11 #R&gt; 8 25 Sydney C~ Randwick~ Clove~ 151. -33.9 23/0~ 97 #R&gt; 9 25 Sydney C~ Randwick~ Clove~ 151. -33.9 07/0~ 3 #R&gt; 10 25 Sydney C~ Randwick~ Clove~ 151. -33.9 25/0~ 0 #R&gt; # ... with 3,680 more rows For the demonstration here the BeachId, Council, and Region variables are not needed. The density of Enterococci is the last variable but its name is difficult to work with and will be renamed. sb %&lt;&gt;% select(-BeachId,-Council,-Region) %&gt;% rename(density=last_col()) sb #R&gt; # A tibble: 3,690 x 5 #R&gt; Site Longitude Latitude Date density #R&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; #R&gt; 1 Clovelly Beach 151. -33.9 02/01/2013 19 #R&gt; 2 Clovelly Beach 151. -33.9 06/01/2013 3 #R&gt; 3 Clovelly Beach 151. -33.9 12/01/2013 2 #R&gt; 4 Clovelly Beach 151. -33.9 18/01/2013 13 #R&gt; 5 Clovelly Beach 151. -33.9 30/01/2013 8 #R&gt; 6 Clovelly Beach 151. -33.9 05/02/2013 7 #R&gt; 7 Clovelly Beach 151. -33.9 11/02/2013 11 #R&gt; 8 Clovelly Beach 151. -33.9 23/02/2013 97 #R&gt; 9 Clovelly Beach 151. -33.9 07/03/2013 3 #R&gt; 10 Clovelly Beach 151. -33.9 25/03/2013 0 #R&gt; # ... with 3,680 more rows In one part of their analysis the researchers wanted to produce a plot of the mean and range of densities of Enterococci by beach. To aid understand, however, they wanted the beaches ordered from south to north. The summary statistics below are calculated by Site converted to a factor class based on Latitude. The latitudes are list with negative numbers (because Australia is in the southern hemisphere) so that more negative numbers are further south. sb_sum1 &lt;- sb %&gt;% mutate(Site=fct_reorder(Site,Latitude)) %&gt;% group_by(Longitude,Latitude,Site) %&gt;% summarize(n=n(), valid_n=sum(!is.na(density)), mn_density=mean(density,na.rm=TRUE), sd_density=sd(density,na.rm=TRUE), min_density=min(density,na.rm=TRUE), max_density=max(density,na.rm=TRUE)) %&gt;% ungroup() sb_sum1 #R&gt; # A tibble: 11 x 9 #R&gt; Longitude Latitude Site n valid_n mn_density sd_density min_density #R&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 151. -34.0 Little Ba~ 338 336 45.6 297. 0 #R&gt; 2 151. -34.0 Malabar B~ 343 341 68.1 214. 0 #R&gt; 3 151. -34.0 South Mar~ 338 336 15.7 77.0 0 #R&gt; 4 151. -33.9 Maroubra ~ 338 335 20.2 123. 0 #R&gt; 5 151. -33.9 Coogee Be~ 342 339 39.4 109. 0 #R&gt; 6 151. -34.0 South Mar~ 316 314 63.9 210. 0 #R&gt; 7 151. -33.9 Gordons B~ 324 322 24.9 120. 0 #R&gt; 8 151. -33.9 Clovelly ~ 338 334 10.2 26.4 0 #R&gt; 9 151. -33.9 Bronte Be~ 338 335 31.4 126. 0 #R&gt; 10 151. -33.9 Tamarama ~ 337 335 35.7 129. 0 #R&gt; 11 151. -33.9 Bondi Bea~ 338 334 18.8 51.9 0 #R&gt; # ... with 1 more variable: max_density &lt;dbl&gt; The desired plot is shown below (with the southern-most beach at the bottom of the y-axis). Other researchers would prefer that the beaches are ordered from lowest to highest density of Enterococci. The code below creates a summary by Sites ordered by the mean density. Note the use of na.rm=TRUE in fct_reorder() because of the missing values at some sites. sb_sum2 &lt;- sb %&gt;% mutate(Site=fct_reorder(Site,density,.fun=mean,na.rm=TRUE)) %&gt;% group_by(Site,Longitude,Latitude) %&gt;% summarize(n=n(), valid_n=sum(!is.na(density)), mn_density=mean(density,na.rm=TRUE), sd_density=sd(density,na.rm=TRUE), min_density=min(density,na.rm=TRUE), max_density=max(density,na.rm=TRUE)) %&gt;% ungroup() sb_sum2 #R&gt; # A tibble: 11 x 9 #R&gt; Site Longitude Latitude n valid_n mn_density sd_density min_density #R&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #R&gt; 1 Clovelly ~ 151. -33.9 338 334 10.2 26.4 0 #R&gt; 2 South Mar~ 151. -34.0 338 336 15.7 77.0 0 #R&gt; 3 Bondi Bea~ 151. -33.9 338 334 18.8 51.9 0 #R&gt; 4 Maroubra ~ 151. -33.9 338 335 20.2 123. 0 #R&gt; 5 Gordons B~ 151. -33.9 324 322 24.9 120. 0 #R&gt; 6 Bronte Be~ 151. -33.9 338 335 31.4 126. 0 #R&gt; 7 Tamarama ~ 151. -33.9 337 335 35.7 129. 0 #R&gt; 8 Coogee Be~ 151. -33.9 342 339 39.4 109. 0 #R&gt; 9 Little Ba~ 151. -34.0 338 336 45.6 297. 0 #R&gt; 10 South Mar~ 151. -34.0 316 314 63.9 210. 0 #R&gt; 11 Malabar B~ 151. -34.0 343 341 68.1 214. 0 #R&gt; # ... with 1 more variable: max_density &lt;dbl&gt; See that 1 is now mapped to Douglas, 2 to Bayfield, and 3 to Ashland. Note that .fun is only useful if multiple observations of the factor variable are present and it defaults to using the median. Note that Jessica Grochowski, now Jessica Kirschbaum, is a Northland alum. Compare the species to species2 columns below to confirm how the refactoring worked. These data are from Kaggle Data from this online book. "],["strings.html", "Module 11 Strings", " Module 11 Strings ex1 &lt;- c(&quot;Ashland&quot;,&quot;Bayfield&quot;,&quot;Douglas&quot;,&quot;Adams&quot;,&quot;Buffalo&quot;,&quot;Jefferson&quot;) ex2 &lt;- c(&quot;Chinook Salmon&quot;,&quot;Coho Salmon&quot;,&quot;Chum Salmon&quot;, &quot;Pink Salmon&quot;,&quot;Sockeye Salmon&quot;,&quot;Salmon&quot;) ex3 &lt;- c(&quot;WD40&quot;,&quot;JB80&quot;,&quot;R2D2&quot;,&quot;C3PO&quot;,&quot;Run DMC&quot;,&quot;AC/DC&quot;) str_view(ex1,&quot;l&quot;) str_view(ex1,&quot;la&quot;) str_view(ex1,&quot;.l.&quot;) str_view(ex1,&quot;.la.&quot;) str_view(ex1,&quot;^A&quot;) str_view(ex1,&quot;^A.&quot;) str_view(ex1,&quot;s$&quot;) str_view(ex1,&quot;.s$&quot;) str_view(ex2,&quot;Salmon&quot;) str_view(ex2,&quot;^Salmon$&quot;) str_view(ex3,&quot;\\\\d&quot;) str_view(ex3,&quot;\\\\s&quot;) str_view(ex1,&quot;[sl]&quot;) str_view(ex1,&quot;[^sl]&quot;) str_view(ex1,&quot;a|l&quot;) str_view_all(ex1,&quot;a|l&quot;) str_view(ex1,&quot;[AEIOU]&quot;) str_view(ex1,&quot;[^AEIOU]&quot;) str_view(ex1,&quot;[aeiou]&quot;) str_view(ex1,&quot;ff?&quot;) str_view(ex1,&quot;ff+&quot;) str_view(ex1,&quot;ff*&quot;) str_view(ex1,&quot;ff{1}&quot;) str_view(ex1,&quot;l&quot;) str_detect(ex1,&quot;l&quot;) #R&gt; [1] TRUE TRUE TRUE FALSE TRUE FALSE ex1[str_detect(ex1,&quot;l&quot;)] #R&gt; [1] &quot;Ashland&quot; &quot;Bayfield&quot; &quot;Douglas&quot; &quot;Buffalo&quot; str_count(ex1,&quot;l&quot;) #R&gt; [1] 1 1 1 0 1 0 str_replace(ex1,&quot;f&quot;,&quot;-&quot;) #R&gt; [1] &quot;Ashland&quot; &quot;Bay-ield&quot; &quot;Douglas&quot; &quot;Adams&quot; &quot;Bu-falo&quot; &quot;Je-ferson&quot; str_replace_all(ex1,&quot;f&quot;,&quot;-&quot;) #R&gt; [1] &quot;Ashland&quot; &quot;Bay-ield&quot; &quot;Douglas&quot; &quot;Adams&quot; &quot;Bu--alo&quot; &quot;Je--erson&quot; str_replace(ex1,&quot;[a|f]&quot;,&quot;-&quot;) #R&gt; [1] &quot;Ashl-nd&quot; &quot;B-yfield&quot; &quot;Dougl-s&quot; &quot;Ad-ms&quot; &quot;Bu-falo&quot; &quot;Je-ferson&quot; str_replace_all(ex1,&quot;[a|f]&quot;,&quot;-&quot;) #R&gt; [1] &quot;Ashl-nd&quot; &quot;B-y-ield&quot; &quot;Dougl-s&quot; &quot;Ad-ms&quot; &quot;Bu---lo&quot; &quot;Je--erson&quot; str_replace_all(ex1,c(&quot;a&quot;=&quot;-&quot;,&quot;f&quot;=&quot;*&quot;)) #R&gt; [1] &quot;Ashl-nd&quot; &quot;B-y*ield&quot; &quot;Dougl-s&quot; &quot;Ad-ms&quot; &quot;Bu**-lo&quot; &quot;Je**erson&quot; str_split(ex2,&quot;\\\\s&quot;) #R&gt; [[1]] #R&gt; [1] &quot;Chinook&quot; &quot;Salmon&quot; #R&gt; #R&gt; [[2]] #R&gt; [1] &quot;Coho&quot; &quot;Salmon&quot; #R&gt; #R&gt; [[3]] #R&gt; [1] &quot;Chum&quot; &quot;Salmon&quot; #R&gt; #R&gt; [[4]] #R&gt; [1] &quot;Pink&quot; &quot;Salmon&quot; #R&gt; #R&gt; [[5]] #R&gt; [1] &quot;Sockeye&quot; &quot;Salmon&quot; #R&gt; #R&gt; [[6]] #R&gt; [1] &quot;Salmon&quot; str_split(ex2,&quot;\\\\s&quot;,simplify=TRUE) #R&gt; [,1] [,2] #R&gt; [1,] &quot;Chinook&quot; &quot;Salmon&quot; #R&gt; [2,] &quot;Coho&quot; &quot;Salmon&quot; #R&gt; [3,] &quot;Chum&quot; &quot;Salmon&quot; #R&gt; [4,] &quot;Pink&quot; &quot;Salmon&quot; #R&gt; [5,] &quot;Sockeye&quot; &quot;Salmon&quot; #R&gt; [6,] &quot;Salmon&quot; &quot;&quot; str_split(ex2,&quot;\\\\s&quot;,simplify=TRUE,n=1) #R&gt; [,1] #R&gt; [1,] &quot;Chinook Salmon&quot; #R&gt; [2,] &quot;Coho Salmon&quot; #R&gt; [3,] &quot;Chum Salmon&quot; #R&gt; [4,] &quot;Pink Salmon&quot; #R&gt; [5,] &quot;Sockeye Salmon&quot; #R&gt; [6,] &quot;Salmon&quot; str_view_all(ex2,boundary(&quot;word&quot;)) str_view_all(ex2,boundary(&quot;character&quot;)) str_view_all(ex2,boundary(&quot;line&quot;)) el &lt;- readxl::read_excel(file.path(&quot;data&quot;,&quot;EcoLeague.xlsx&quot;)) el #R&gt; # A tibble: 6 x 3 #R&gt; Institution Address City_State_ZIP #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #R&gt; 1 Alaska Pacific University 4101 University Drive Anchorage, AK 99508 #R&gt; 2 College of the Atlantic 105 Eden Street Bar Harbor, ME 04609 #R&gt; 3 Dickinson College P.O. Box 1773 Carlisle, PA 17013 #R&gt; 4 New College of Florida 5800 Bay Shore Road Sarasota, FL 34243 #R&gt; 5 Northland College 1411 Ellis Avenue Ashland, WI 54806 #R&gt; 6 Prescott College 220 Grove Avenue Prescott, AZ 86301 str_view(el$Institution,&quot;a&quot;) str_view_all(el$Institution,&quot;a&quot;) str_view(el$Institution,&quot;.College.&quot;) str_view(el$Institution,&quot;College.&quot;) str_view(el$Institution,&quot;.College&quot;) str_view(el$Institution,&quot;.College.|.College|College.&quot;) sum(str_detect(el$Institution,&quot;.College.|.College|College.&quot;)) #R&gt; [1] 5 str_view(el$Institution,&quot;[col]&quot;) str_view_all(el$Institution,&quot;[col]&quot;) str_view_all(el$Institution,boundary(&quot;word&quot;)) str_extract_all(el$Institution,boundary(&quot;word&quot;),simplify=TRUE) #R&gt; [,1] [,2] [,3] [,4] #R&gt; [1,] &quot;Alaska&quot; &quot;Pacific&quot; &quot;University&quot; &quot;&quot; #R&gt; [2,] &quot;College&quot; &quot;of&quot; &quot;the&quot; &quot;Atlantic&quot; #R&gt; [3,] &quot;Dickinson&quot; &quot;College&quot; &quot;&quot; &quot;&quot; #R&gt; [4,] &quot;New&quot; &quot;College&quot; &quot;of&quot; &quot;Florida&quot; #R&gt; [5,] &quot;Northland&quot; &quot;College&quot; &quot;&quot; &quot;&quot; #R&gt; [6,] &quot;Prescott&quot; &quot;College&quot; &quot;&quot; &quot;&quot; el %&gt;% separate(City_State_ZIP,into=c(&quot;City&quot;,&quot;State_ZIP&quot;),sep=&quot;, &quot;) %&gt;% separate(State_ZIP,into=c(&quot;State&quot;,&quot;ZIP&quot;)) #R&gt; # A tibble: 6 x 5 #R&gt; Institution Address City State ZIP #R&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #R&gt; 1 Alaska Pacific University 4101 University Drive Anchorage AK 99508 #R&gt; 2 College of the Atlantic 105 Eden Street Bar Harbor ME 04609 #R&gt; 3 Dickinson College P.O. Box 1773 Carlisle PA 17013 #R&gt; 4 New College of Florida 5800 Bay Shore Road Sarasota FL 34243 #R&gt; 5 Northland College 1411 Ellis Avenue Ashland WI 54806 #R&gt; 6 Prescott College 220 Grove Avenue Prescott AZ 86301 "],["references.html", "References", " References "]]
